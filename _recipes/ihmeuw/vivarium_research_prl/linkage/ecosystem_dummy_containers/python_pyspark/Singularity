Bootstrap: docker
From: apache/spark-py@sha256:489f904a77f21134df4840de5f8bd9f110925e7b439ca6a04b7c033813edfebc
Stage: spython-base

%files
dummy_step.py /code/
%post

su -  root # USER root
# pandas is used to write out a single file
pip3 install pandas==2.1.2 pyarrow pyyaml
# NOTE: I don't understand why, but in the base image, it has pyspark installed somewhere
# that isn't on PYTHONPATH by default
# I looked in /opt/spark/bin/pyspark to find this
PYTHONPATH="${SPARK_HOME}/python/:${SPARK_HOME}/python/lib/py4j-0.10.9.7-src.zip:${PYTHONPATH}"
mkdir -p /input_data
mkdir -p /results
mkdir -p /diagnostics
mkdir -p /workdir
mkdir -p /code
# VOLUME /results
# VOLUME /diagnostics
# VOLUME /input_data
# Annoyingly, Spark _requires_ write access to the working directory, to write a file called java_opts.txt
mkdir -p /workdir
cd /workdir

# NOTE: Usually 185 (spark) is the user for this base image.
# However, that doesn't seem to work with Singularity.
# USER 185

%environment
export PYTHONPATH="${SPARK_HOME}/python/:${SPARK_HOME}/python/lib/py4j-0.10.9.7-src.zip:${PYTHONPATH}"
%runscript
cd /workdir
exec /usr/bin/python3 /code/dummy_step.py "$@"
%startscript
cd /workdir
exec /usr/bin/python3 /code/dummy_step.py "$@"