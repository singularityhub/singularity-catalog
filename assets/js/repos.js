var data =
[
  {
    "data_format": 2,
    "description": "A Statistical Framework for Modeling and Identifying Differential Distributions in Single-cell RNA-sequencing Data",
    "filenames": [
      "inst/Singularity"
    ],
    "full_name": "Malindrie/scShapes",
    "latest_release": null,
    "readme": "\n\u003ch1\u003e\n\u003ca id=\"user-content-scshapes\" class=\"anchor\" href=\"#scshapes\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003escShapes\u003c/h1\u003e\n\n\u003cp\u003e\u003ca href=\"https://travis-ci.com/Malindrie/scShapes\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f46be69a2babf0d92348a4d2abbc1834186998fa8fb4d023c1e85bc5f9405e8a/68747470733a2f2f7472617669732d63692e636f6d2f4d616c696e647269652f73635368617065732e7376673f6272616e63683d6d6173746572\" alt=\"Travis build status\" data-canonical-src=\"https://travis-ci.com/Malindrie/scShapes.svg?branch=master\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://ci.appveyor.com/project/Malindrie/scShapes\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9b16a84bf2877273e52d87887ce418eb0fff59cd1066cca77a8700f6bae73d6b/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f4d616c696e647269652f73635368617065733f6272616e63683d6d6173746572267376673d74727565\" alt=\"AppVeyor build status\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/github/Malindrie/scShapes?branch=master\u0026amp;svg=true\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eWe present a novel statistical framework for identifying differential\ndistributions in single-cell RNA-sequencing (scRNA-seq) data between\ntreatment conditions by modeling gene expression read counts using\ngeneralized linear models (GLMs). We model each gene independently under\neach treatment condition using the error distributions Poisson (P),\nNegative Binomial (NB), Zero-inflated Poisson (ZIP) and Zero-inflated\nNegative Binomial (ZINB) with log link function and model based\nnormalization for differences in sequencing depth. Since all four\ndistributions considered in our framework belong to the same family of\ndistributions, we first perform a Kolmogorov-Smirnov (KS) test to select\ngenes belonging to the family of ZINB distributions. Genes passing the\nKS test will be then modeled using GLMs. Model selection is done by\ncalculating the Bayesian Information Criterion and likelihood ratio test\nstatistic.\u003c/p\u003e\n\u003cp\u003eWhile most methods for differential gene expression analysis aim to\ndetect a shift in the mean of expressed values, single cell data are\ndriven by over-dispersion and dropouts requiring statistical\ndistributions that can handle the excess zeros. By modeling gene\nexpression distributions, our framework can identify subtle variations\nthat do not involve the change in mean. It also has the flexibility to\nadjust for covariates and perform multiple comparisons while explicitly\nmodeling the variability between samples.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-installation\" class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eYou can install the released version of scShapes with:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-r\"\u003e\u003cpre\u003e\u003cspan class=\"pl-e\"\u003edevtools\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e::\u003c/span\u003einstall_github(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003eMalindrie/scShapes\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e)\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-source-r\"\u003e\u003cpre\u003elibrary(\u003cspan class=\"pl-smi\"\u003escShapes\u003c/span\u003e)\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-example\" class=\"anchor\" href=\"#example\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eExample\u003c/h2\u003e\n\u003cp\u003eThis is a basic example which shows how you can use scShapes for\nidentifying differential distributions in single-cell RNA-seq data. For\nthis example data we use the human immune cells (PBMC) dataset\ndistributed through the\n\u003ca href=\"https://github.com/satijalab/seurat-data\"\u003eSeuratData\u003c/a\u003e package.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-r\"\u003e\u003cpre\u003elibrary(\u003cspan class=\"pl-smi\"\u003escShapes\u003c/span\u003e)\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eLoading and preparing data for input \u003c/span\u003e\nlibrary(\u003cspan class=\"pl-smi\"\u003eSeurat\u003c/span\u003e)\nlibrary(\u003cspan class=\"pl-smi\"\u003eSeuratData\u003c/span\u003e)\nlibrary(\u003cspan class=\"pl-smi\"\u003edplyr\u003c/span\u003e)\nlibrary(\u003cspan class=\"pl-smi\"\u003eBiocParallel\u003c/span\u003e)\nset.seed(\u003cspan class=\"pl-c1\"\u003e0xBEEF\u003c/span\u003e)\n\nInstallData(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eifnb\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e)\nLoadData(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eifnb\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e)\n\u003cspan class=\"pl-smi\"\u003eifnb.list\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e SplitObject(\u003cspan class=\"pl-smi\"\u003eifnb\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003esplit.by\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003estim\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e)\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWe first filter the genes to keep only genes expressed in at least 10%\nof cells:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-r\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eFirst extract the RNA-seq counts from the \u0027RNA\u0027 assay of the seurat object\u003c/span\u003e\n\u003cspan class=\"pl-smi\"\u003eifnb.obj\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e lapply(\u003cspan class=\"pl-smi\"\u003eifnb.list\u003c/span\u003e, \u003cspan class=\"pl-k\"\u003efunction\u003c/span\u003e (\u003cspan class=\"pl-smi\"\u003ex\u003c/span\u003e) as.matrix(\u003cspan class=\"pl-smi\"\u003ex\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e@\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eassays\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eRNA\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e@\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003ecounts\u003c/span\u003e))\n\u003cspan class=\"pl-smi\"\u003eifnb.filtered\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e lapply(\u003cspan class=\"pl-smi\"\u003eifnb.obj\u003c/span\u003e, \u003cspan class=\"pl-k\"\u003efunction\u003c/span\u003e (\u003cspan class=\"pl-smi\"\u003ex\u003c/span\u003e) filter_counts(\u003cspan class=\"pl-smi\"\u003ex\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003eperc.zero\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e0.1\u003c/span\u003e))\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e\u0026gt; Removing 527 rows of genes with all zero counts\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e\u0026gt; Removing 778 rows of genes with all zero counts\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIn order to normalize for differences in sequencing depth, the log of\nthe total UMI counts assigned per cell will be used as an offset in the\nGLM. This function is inbuilt in the algorithm; however the user is\nrequired to input the library sizes. We can calculate the library sizes\nfor the two treatment conditions as;\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-r\"\u003e\u003cpre\u003e\u003cspan class=\"pl-smi\"\u003eifnb.lib.size\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e lapply(\u003cspan class=\"pl-smi\"\u003eifnb.filtered\u003c/span\u003e, \u003cspan class=\"pl-k\"\u003efunction\u003c/span\u003e (\u003cspan class=\"pl-smi\"\u003ex\u003c/span\u003e) apply(\u003cspan class=\"pl-smi\"\u003ex\u003c/span\u003e,\u003cspan class=\"pl-c1\"\u003e2\u003c/span\u003e, \u003cspan class=\"pl-k\"\u003efunction\u003c/span\u003e(\u003cspan class=\"pl-smi\"\u003ey\u003c/span\u003e) sum(\u003cspan class=\"pl-smi\"\u003ey\u003c/span\u003e)))\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe \u2018meta.data\u2019 slot of the Seurat object also contains information on\nthe cell-types, which will be used as a covariate in the GLM model to\naccount for known biological variation in the data.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-r\"\u003e\u003cpre\u003e\u003cspan class=\"pl-smi\"\u003eifnb.variables\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e lapply(\u003cspan class=\"pl-smi\"\u003eifnb.list\u003c/span\u003e, \u003cspan class=\"pl-k\"\u003efunction\u003c/span\u003e (\u003cspan class=\"pl-smi\"\u003ex\u003c/span\u003e) \u003cspan class=\"pl-k\"\u003edata.frame\u003c/span\u003e(\n                        \u003cspan class=\"pl-v\"\u003ecell.type\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-k\"\u003efactor\u003c/span\u003e(\u003cspan class=\"pl-smi\"\u003ex\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e@\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003emeta.data\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eseurat_annotations\u003c/span\u003e),\n                        \u003cspan class=\"pl-v\"\u003erow.names\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e colnames(\u003cspan class=\"pl-smi\"\u003ex\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e@\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eassays\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eRNA\u003c/span\u003e)))\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFor the purpose of this example we only run the pipeline for randomly\nselected 20 common genes under both treatment conditions \u2018CTRL\u2019 and\n\u2018STIM\u2019.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-r\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eRandomly select 20 genes among common genes between the two treatment conditions\u003c/span\u003e\n\u003cspan class=\"pl-smi\"\u003ecomm.genes\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e intersect(rownames(\u003cspan class=\"pl-smi\"\u003eifnb.filtered\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eCTRL\u003c/span\u003e), rownames(\u003cspan class=\"pl-smi\"\u003eifnb.filtered\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eSTIM\u003c/span\u003e))\n\u003cspan class=\"pl-smi\"\u003ecomm.20.genes\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e sample(\u003cspan class=\"pl-smi\"\u003ecomm.genes\u003c/span\u003e, \u003cspan class=\"pl-c1\"\u003e20\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003ereplace\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003eFALSE\u003c/span\u003e)\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eSubset the randomly selected 20 genes\u003c/span\u003e\n\u003cspan class=\"pl-smi\"\u003eifnb.ctrl\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003eifnb.filtered\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eCTRL\u003c/span\u003e[rownames(\u003cspan class=\"pl-smi\"\u003eifnb.filtered\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eCTRL\u003c/span\u003e) \u003cspan class=\"pl-k\"\u003e%in%\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003ecomm.20.genes\u003c/span\u003e,]\n\u003cspan class=\"pl-smi\"\u003eifnb.stim\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003eifnb.filtered\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eSTIM\u003c/span\u003e[rownames(\u003cspan class=\"pl-smi\"\u003eifnb.filtered\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eSTIM\u003c/span\u003e) \u003cspan class=\"pl-k\"\u003e%in%\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003ecomm.20.genes\u003c/span\u003e,]\n\u003cspan class=\"pl-smi\"\u003eifnb.subset\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e \u003cspan class=\"pl-k\"\u003elist\u003c/span\u003e(\u003cspan class=\"pl-v\"\u003eCTRL\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003eifnb.ctrl\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003eSTIM\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003eifnb.stim\u003c/span\u003e)\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003ePerform Kolmogorov-Smirnov test to select genes belonging to the family\nof ZINB distributions.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-r\"\u003e\u003cpre\u003e\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.KS\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e ks_test(\u003cspan class=\"pl-smi\"\u003eifnb.subset\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eCTRL\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003ecexpr\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eifnb.variables\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eCTRL\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003elib.size\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eifnb.lib.size\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eCTRL\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003eBPPARAM\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003eSnowParam(\u003cspan class=\"pl-v\"\u003eworkers\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003e4\u003c/span\u003e,\u003cspan class=\"pl-v\"\u003etype\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eSOCK\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e))\n\u003cspan class=\"pl-smi\"\u003eifnb.stim.KS\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e ks_test(\u003cspan class=\"pl-smi\"\u003eifnb.subset\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eSTIM\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003ecexpr\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eifnb.variables\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eSTIM\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003elib.size\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eifnb.lib.size\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eSTIM\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003eBPPARAM\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003eSnowParam(\u003cspan class=\"pl-v\"\u003eworkers\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003e4\u003c/span\u003e,\u003cspan class=\"pl-v\"\u003etype\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eSOCK\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e))\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eSelect genes significant from the KS test.\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eBy default the \u0027ks_sig\u0027 function performs Benjamini-Hochberg correction for multiple hypothese testing\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eand selects genes significant at p-value of 0.01\u003c/span\u003e\n\n\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.sig.KS\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e ks_sig(\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.KS\u003c/span\u003e)\n\u003cspan class=\"pl-smi\"\u003eifnb.stim.sig.KS\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e ks_sig(\u003cspan class=\"pl-smi\"\u003eifnb.stim.KS\u003c/span\u003e)\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eSubset UMI counts corresponding to the genes significant from the KS test\u003c/span\u003e\n\u003cspan class=\"pl-smi\"\u003eifnb.sig.genes\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e \u003cspan class=\"pl-k\"\u003elist\u003c/span\u003e(\u003cspan class=\"pl-v\"\u003eCTRL\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e as.data.frame(\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.sig.KS\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003egenes\u003c/span\u003e),\n                       \u003cspan class=\"pl-v\"\u003eSTIM\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e as.data.frame(\u003cspan class=\"pl-smi\"\u003eifnb.stim.sig.KS\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003egenes\u003c/span\u003e))\n\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.KS\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003eifnb.filtered\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eCTRL\u003c/span\u003e[rownames(\u003cspan class=\"pl-smi\"\u003eifnb.filtered\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eCTRL\u003c/span\u003e) \u003cspan class=\"pl-k\"\u003e%in%\u003c/span\u003e rownames(\u003cspan class=\"pl-smi\"\u003eifnb.sig.genes\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eCTRL\u003c/span\u003e),]\n  \u003cspan class=\"pl-smi\"\u003eifnb.stim.KS\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003eifnb.filtered\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eSTIM\u003c/span\u003e[rownames(\u003cspan class=\"pl-smi\"\u003eifnb.filtered\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eSTIM\u003c/span\u003e) \u003cspan class=\"pl-k\"\u003e%in%\u003c/span\u003e rownames(\u003cspan class=\"pl-smi\"\u003eifnb.sig.genes\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eSTIM\u003c/span\u003e),]\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFit the 4 distributions P,NB,ZIP,ZINB for genes that belong to the ZINB\nfamily of distributions by fitting GLM with log of the library sizes as\nan offset and cell types as a covariate in the GLM.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-r\"\u003e\u003cpre\u003e\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.fit\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e fit_models(\u003cspan class=\"pl-v\"\u003ecounts\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.KS\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003ecexpr\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eifnb.variables\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eCTRL\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003elib.size\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eifnb.lib.size\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eCTRL\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003eBPPARAM\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003eSnowParam(\u003cspan class=\"pl-v\"\u003eworkers\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003e4\u003c/span\u003e,\u003cspan class=\"pl-v\"\u003etype\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eSOCK\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e))\n\u003cspan class=\"pl-smi\"\u003eifnb.stim.fit\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e fit_models(\u003cspan class=\"pl-v\"\u003ecounts\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eifnb.stim.KS\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003ecexpr\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eifnb.variables\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eSTIM\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003elib.size\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eifnb.lib.size\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eSTIM\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003eBPPARAM\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003eSnowParam(\u003cspan class=\"pl-v\"\u003eworkers\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003e4\u003c/span\u003e,\u003cspan class=\"pl-v\"\u003etype\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eSOCK\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e))\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOnce the 4 distributions are fitted, we next calculate the BIC value for\neach model and select the model with the least BIC value.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-r\"\u003e\u003cpre\u003e\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.bic.val\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e model_bic(\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.fit\u003c/span\u003e)\n\u003cspan class=\"pl-smi\"\u003eifnb.stim.bic.val\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e model_bic(\u003cspan class=\"pl-smi\"\u003eifnb.stim.fit\u003c/span\u003e)\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eselect model with least bic value\u003c/span\u003e\n\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.lbic\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e lbic_model(\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.bic.val\u003c/span\u003e, \u003cspan class=\"pl-smi\"\u003eifnb.ctrl.KS\u003c/span\u003e)\n\u003cspan class=\"pl-smi\"\u003eifnb.stim.lbic\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e lbic_model(\u003cspan class=\"pl-smi\"\u003eifnb.stim.bic.val\u003c/span\u003e, \u003cspan class=\"pl-smi\"\u003eifnb.stim.KS\u003c/span\u003e)\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTo ensure the fit of the models selected based on the least BIC value,\nadditionally we perform LRT to test for model adequacy and presence of\nzero-inflation.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-r\"\u003e\u003cpre\u003e\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.gof\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e gof_model(\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.lbic\u003c/span\u003e, \u003cspan class=\"pl-smi\"\u003eifnb.variables\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eCTRL\u003c/span\u003e, \u003cspan class=\"pl-smi\"\u003eifnb.lib.size\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eCTRL\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003eBPPARAM\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003eSerialParam())\n\u003cspan class=\"pl-smi\"\u003eifnb.stim.gof\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e gof_model(\u003cspan class=\"pl-smi\"\u003eifnb.stim.lbic\u003c/span\u003e, \u003cspan class=\"pl-smi\"\u003eifnb.variables\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eSTIM\u003c/span\u003e, \u003cspan class=\"pl-smi\"\u003eifnb.lib.size\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eSTIM\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003eBPPARAM\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003eSerialParam())\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFinally based on the results of the model adequacy tests, we can\nidentify the distribution of best fit for each gene.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-r\"\u003e\u003cpre\u003e\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.dist.fit\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e select_model(\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.gof\u003c/span\u003e)\n\u003cspan class=\"pl-smi\"\u003eifnb.stim.dist.fit\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e select_model(\u003cspan class=\"pl-smi\"\u003eifnb.stim.gof\u003c/span\u003e)\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOnce the distribution of best fit is identified for genes of interest,\nit is also possible to extract parameters of interest for the models.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-r\"\u003e\u003cpre\u003e\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.params\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e model_param (\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.fit\u003c/span\u003e, \u003cspan class=\"pl-smi\"\u003eifnb.ctrl.dist.fit\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003emodel\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003eNULL\u003c/span\u003e)\n\u003cspan class=\"pl-smi\"\u003eifnb.stim.params\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e model_param (\u003cspan class=\"pl-smi\"\u003eifnb.stim.fit\u003c/span\u003e, \u003cspan class=\"pl-smi\"\u003eifnb.stim.dist.fit\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003emodel\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003eNULL\u003c/span\u003e)\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eUsing above results we can now identify the differentially distributed\ngenes between \u2018CTRL\u2019 and \u2018STIM\u2019. First we need to subset genes that is\nsignificant in the KS test in both conditions.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-r\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eSubset the common genes between the two groups, that pass the GOF test\u003c/span\u003e\n\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.fit\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e unlist(\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.dist.fit\u003c/span\u003e)\n\u003cspan class=\"pl-smi\"\u003eifnb.stim.fit\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e unlist(\u003cspan class=\"pl-smi\"\u003eifnb.stim.dist.fit\u003c/span\u003e)\n\u003cspan class=\"pl-smi\"\u003eifnb.gof.sig\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e intersect(\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.fit\u003c/span\u003e, \u003cspan class=\"pl-smi\"\u003eifnb.stim.fit\u003c/span\u003e)\n\n\u003cspan class=\"pl-smi\"\u003eifnb.dist.ctrl\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e \u003cspan class=\"pl-k\"\u003edata.frame\u003c/span\u003e(\u003cspan class=\"pl-v\"\u003egene\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e c(\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.dist.fit\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eP_genes\u003c/span\u003e, \u003cspan class=\"pl-smi\"\u003eifnb.ctrl.dist.fit\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eNB_genes\u003c/span\u003e, \u003cspan class=\"pl-smi\"\u003eifnb.ctrl.dist.fit\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eZIP_genes\u003c/span\u003e, \u003cspan class=\"pl-smi\"\u003eifnb.ctrl.dist.fit\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eZINB_genes\u003c/span\u003e))\n\u003cspan class=\"pl-smi\"\u003eifnb.dist.ctrl\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003edist\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e c(rep(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ePo\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, length(\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.dist.fit\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eP_genes\u003c/span\u003e)), rep(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eNB\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, length(\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.dist.fit\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eNB_genes\u003c/span\u003e)), rep(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eZIP\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, length(\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.dist.fit\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eZIP_genes\u003c/span\u003e)), rep(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eZINB\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, length(\u003cspan class=\"pl-smi\"\u003eifnb.ctrl.dist.fit\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eZINB_genes\u003c/span\u003e)))\n\n\u003cspan class=\"pl-smi\"\u003eifnb.dist.stim\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e \u003cspan class=\"pl-k\"\u003edata.frame\u003c/span\u003e(\u003cspan class=\"pl-v\"\u003egene\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e c(\u003cspan class=\"pl-smi\"\u003eifnb.stim.dist.fit\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eP_genes\u003c/span\u003e, \u003cspan class=\"pl-smi\"\u003eifnb.stim.dist.fit\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eNB_genes\u003c/span\u003e, \u003cspan class=\"pl-smi\"\u003eifnb.stim.dist.fit\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eZIP_genes\u003c/span\u003e, \u003cspan class=\"pl-smi\"\u003eifnb.stim.dist.fit\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eZINB_genes\u003c/span\u003e))\n\u003cspan class=\"pl-smi\"\u003eifnb.dist.stim\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003edist\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e c(rep(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ePo\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, length(\u003cspan class=\"pl-smi\"\u003eifnb.stim.dist.fit\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eP_genes\u003c/span\u003e)), rep(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eNB\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, length(\u003cspan class=\"pl-smi\"\u003eifnb.stim.dist.fit\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eNB_genes\u003c/span\u003e)), rep(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eZIP\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, length(\u003cspan class=\"pl-smi\"\u003eifnb.stim.dist.fit\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eZIP_genes\u003c/span\u003e)), rep(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eZINB\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, length(\u003cspan class=\"pl-smi\"\u003eifnb.stim.dist.fit\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003eZINB_genes\u003c/span\u003e)))\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eDataframe consisting of distributions followed by each gene passing the KS test\u003c/span\u003e\n\u003cspan class=\"pl-smi\"\u003eifnb.gof.ctrl\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003eifnb.dist.ctrl\u003c/span\u003e[\u003cspan class=\"pl-smi\"\u003eifnb.dist.ctrl\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003egene\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e%in%\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003eifnb.gof.sig\u003c/span\u003e,]\n\u003cspan class=\"pl-smi\"\u003eifnb.gof.stim\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003eifnb.dist.stim\u003c/span\u003e[\u003cspan class=\"pl-smi\"\u003eifnb.dist.stim\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003egene\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e%in%\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003eifnb.gof.sig\u003c/span\u003e,]\n\n\u003cspan class=\"pl-smi\"\u003eifnb.distr\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e \u003cspan class=\"pl-k\"\u003edata.frame\u003c/span\u003e(\u003cspan class=\"pl-v\"\u003ectrl\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003eifnb.gof.ctrl\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003edist\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003erow.names\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003eifnb.gof.ctrl\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003egene\u003c/span\u003e)\n\u003cspan class=\"pl-smi\"\u003eifnb.distr\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003estim\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003eifnb.gof.stim\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003edist\u003c/span\u003e[match(rownames(\u003cspan class=\"pl-smi\"\u003eifnb.distr\u003c/span\u003e), \u003cspan class=\"pl-smi\"\u003eifnb.gof.stim\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e$\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003egene\u003c/span\u003e)]\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eUsing the dataframe of genes and distribution followed under each\ncondition now we can identify genes changing distribution between \u2018CTRL\u2019\nand \u2018STIM\u2019\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-r\"\u003e\u003cpre\u003e\u003cspan class=\"pl-smi\"\u003eifnb.DD.genes\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;-\u003c/span\u003e change_shape(\u003cspan class=\"pl-smi\"\u003eifnb.distr\u003c/span\u003e)\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis will give a list of two lists with genes changing distribution\nbetween condition and genes changing distribution from unimodal in one\ncondition to zero-inflated in the other condition.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1622620929.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "Singularity_fastqc",
      "Singularity_multiqc",
      "Singularity_trimmomatic"
    ],
    "full_name": "uf-icbr-bioinformatics/biocontainers",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-biocontainers\" class=\"anchor\" href=\"#biocontainers\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ebiocontainers\u003c/h1\u003e\n\u003cp\u003eThis repository contains recipes for containers used to perform QC, summary statistics, and pre-processing on NGS datasets.\u003c/p\u003e\n\u003cp\u003eIn the future, we may provide the containers themselves. Stay tuned. Work in progress.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1622592653.0
  },
  {
    "data_format": 2,
    "description": "Singularity images and recipes",
    "filenames": [
      "clease/Singularity.clease",
      "deal.II/Singularity.deal",
      "graphics/Singularity.gnuplot_5.4a",
      "graphics/Singularity.gnuplot_4.6a",
      "graphics/Singularity.gnuplot_5.4",
      "graphics/Singularity.gnuplot_4.6",
      "graphics/Singularity.graphics",
      "graphics/Singularity.gnuplot_alpine",
      "Atom/Singularity.atom",
      "xcrysden/Singularity.xcrysden_1.5.60",
      "xcrysden/Singularity.xcrysden",
      "ase-twistd/Singularity.ase-twistd",
      "tesseract/Singularity.tesseract",
      "gromacs/Singularity.gromacs",
      "jupyter/Singularity.jupyter",
      "gdis/Singularity.gdis",
      "rstudio-server/Singularity.rstudio-server",
      "mongodb/Singularity.mongodb",
      "MD2-lab/Singularity.md2-lab",
      "pp/Singularity.pp2",
      "tools/Singularity.vim",
      "tools/Singularity.mc",
      "tools/Singularity.gawk",
      "tools/Singularity.gnuplot",
      "tools/Singularity.meld",
      "jmol/Singularity.jmol",
      "ubuntu/Singularity.2004",
      "ubuntu/Singularity.1804",
      "texlive/Singularity.texlive",
      "AMPE/Singularity.ampe",
      "kmos/Singularity.kmos",
      "kmos/Singularity.kmos3_9",
      "lammps/Singularity.lammps",
      "lammps/Singularity.lammps_ase",
      "lammps/Singularity.lammps_prophet",
      "lammps/Singularity.lammps_ase_kim",
      "cuda/Singularity.u18.04_cuda9.2",
      "VESTA/Singularity.vesta",
      "obabel/Singularity.obabel",
      "acroread/Singularity.acroread"
    ],
    "full_name": "pmitev/Teoroo-singularity",
    "latest_release": null,
    "readme": "\u003cp\u003e\u003ca href=\"https://singularity-hub.org/collections/2338\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a07b23d4880320ac89cdc93bbbb603fa84c215d135e05dd227ba8633a9ff34be/68747470733a2f2f7777772e73696e67756c61726974792d6875622e6f72672f7374617469632f696d672f686f737465642d73696e67756c61726974792d2d6875622d2532336533323932392e737667\" alt=\"https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg\" data-canonical-src=\"https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-teoroo-singularity\" class=\"anchor\" href=\"#teoroo-singularity\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTeoroo-singularity\u003c/h1\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [
      "singularity",
      "singularity-containers"
    ],
    "updated_at": 1622557404.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "container/Singularity"
    ],
    "full_name": "Genomic-Medicine-Linkoping/nextflow_rnaseqfus",
    "latest_release": null,
    "readme": "\u003cp\u003e\u003ca href=\"https://singularity-hub.org/collections/2338\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a07b23d4880320ac89cdc93bbbb603fa84c215d135e05dd227ba8633a9ff34be/68747470733a2f2f7777772e73696e67756c61726974792d6875622e6f72672f7374617469632f696d672f686f737465642d73696e67756c61726974792d2d6875622d2532336533323932392e737667\" alt=\"https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg\" data-canonical-src=\"https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-teoroo-singularity\" class=\"anchor\" href=\"#teoroo-singularity\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTeoroo-singularity\u003c/h1\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 0,
    "topics": [],
    "updated_at": 1622550367.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "environments/illumina/Singularity",
      "environments/nanopore/Singularity"
    ],
    "full_name": "Genomic-Medicine-Linkoping/gms-artic",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-gms-artic-ncov2019-artic-nf\" class=\"anchor\" href=\"#gms-artic-ncov2019-artic-nf\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGMS-artic (ncov2019-artic-nf)\u003c/h1\u003e\n\u003cp\u003eA Nextflow pipeline for running the ARTIC network\u0027s fieldbioinformatics tools (\u003ca href=\"https://github.com/artic-network/fieldbioinformatics\"\u003ehttps://github.com/artic-network/fieldbioinformatics\u003c/a\u003e), with a focus on ncov2019\u003c/p\u003e\n\u003cp\u003eWARNING - THIS REPO IS UNDER ACTIVE DEVELOPMENT AND ITS BEHAVIOUR MAY CHANGE AT \u003cstrong\u003eANY\u003c/strong\u003e TIME.\u003c/p\u003e\n\u003cp\u003ePLEASE ENSURE THAT YOU READ BOTH THE README AND THE CONFIG FILE AND UNDERSTAND THE EFFECT OF THE OPTIONS ON YOUR DATA!\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-introduction\" class=\"anchor\" href=\"#introduction\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eIntroduction\u003c/h4\u003e\n\u003chr\u003e\n\u003cp\u003eThis Nextflow pipeline automates the ARTIC network \u003ca href=\"https://artic.network/ncov-2019/ncov2019-bioinformatics-sop.html\" title=\"nCoV-2019 novel coronavirus bioinformatics protocol\" rel=\"nofollow\"\u003enCoV-2019 novel coronavirus bioinformatics protocol\u003c/a\u003e. It is being developed to aid the harmonisation of the analysis of sequencing data generated by the \u003ca href=\"https://github.com/COG-UK\"\u003eCOG-UK\u003c/a\u003e project. It will turn SARS-COV2 sequencing data (Illumina or Nanopore) into consensus sequences and provide other helpful outputs to assist the project\u0027s sequencing centres with submitting data.\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-quick-start\" class=\"anchor\" href=\"#quick-start\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eQuick-start\u003c/h4\u003e\n\u003ch5\u003e\n\u003ca id=\"user-content-illumina\" class=\"anchor\" href=\"#illumina\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eIllumina\u003c/h5\u003e\n\u003cp\u003e\u003ccode\u003enextflow run connor-lab/ncov2019-artic-nf [-profile conda,singularity,docker,slurm,lsf] --illumina --prefix \"output_file_prefix\" --directory /path/to/reads\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eYou can also use cram file input by passing the --cram flag.\nYou can also specify cram file output by passing the --outCram flag.\u003c/p\u003e\n\u003cp\u003eFor production use at large scale, where you will run the workflow many times, you can avoid cloning the scheme repository, creating an ivar bed file and indexing the reference every time by supplying both --ivarBed /path/to/ivar-compatible.bed and --alignerRefPrefix /path/to/bwa-indexed/ref.fa.\u003c/p\u003e\n\u003cp\u003eAlternatively you can avoid just the cloning of the scheme repository to remain on a fixed revision of it over time by passing --schemeRepoURL /path/to/own/clone/of/github.com/artic-network/artic-ncov2019. This removes any internet access from the workflow except for the optional upload steps.\u003c/p\u003e\n\u003ch5\u003e\n\u003ca id=\"user-content-nanopore\" class=\"anchor\" href=\"#nanopore\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eNanopore\u003c/h5\u003e\n\u003ch6\u003e\n\u003ca id=\"user-content-nanopolish\" class=\"anchor\" href=\"#nanopolish\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eNanopolish\u003c/h6\u003e\n\u003cp\u003e\u003ccode\u003enextflow run connor-lab/ncov2019-artic-nf [-profile conda,singularity,docker,slurm,lsf] --nanopolish --prefix \"output_file_prefix\" --basecalled_fastq /path/to/directory --fast5_pass /path/to/directory --sequencing_summary /path/to/sequencing_summary.txt\u003c/code\u003e\u003c/p\u003e\n\u003ch6\u003e\n\u003ca id=\"user-content-medaka\" class=\"anchor\" href=\"#medaka\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMedaka\u003c/h6\u003e\n\u003cp\u003e\u003ccode\u003enextflow run connor-lab/ncov2019-artic-nf [-profile conda,singularity,docker,slurm,lsf] --medaka --prefix \"output_file_prefix\" --basecalled_fastq /path/to/directory --fast5_pass /path/to/directory --sequencing_summary /path/to/sequencing_summary.txt\u003c/code\u003e\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-installation\" class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation\u003c/h4\u003e\n\u003cp\u003eAn up-to-date version of Nextflow is required because the pipeline is written in DSL2. Following the instructions at \u003ca href=\"https://www.nextflow.io/\" rel=\"nofollow\"\u003ehttps://www.nextflow.io/\u003c/a\u003e to download and install Nextflow should get you a recent-enough version.\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-containers\" class=\"anchor\" href=\"#containers\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContainers\u003c/h4\u003e\n\u003cp\u003eThis repo contains both Singularity and Dockerfiles. You can build the Singularity containers locally by running \u003ccode\u003escripts/build_singularity_containers.sh\u003c/code\u003e and use them with \u003ccode\u003e-profile singularity\u003c/code\u003e The containers will be available from Docker/Singularityhub shortly.\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-conda\" class=\"anchor\" href=\"#conda\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eConda\u003c/h4\u003e\n\u003cp\u003eThe repo contains a environment.yml files which automatically build the correct conda env if \u003ccode\u003e-profile conda\u003c/code\u003e is specifed in the command. Although you\u0027ll need \u003ccode\u003econda\u003c/code\u003e installed, this is probably the easiest way to run this pipeline.\u003c/p\u003e\n\u003cp\u003e--cache /some/dir can be specified to have a fixed, shared location to store the conda build for use by multiple runs of the workflow.\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-executors\" class=\"anchor\" href=\"#executors\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eExecutors\u003c/h4\u003e\n\u003cp\u003eBy default, the pipeline just runs on the local machine. You can specify \u003ccode\u003e-profile slurm\u003c/code\u003e to use a SLURM cluster, or \u003ccode\u003e-profile lsf\u003c/code\u003e to use an LSF cluster. In either case you may need to also use one of the COG-UK institutional config profiles (phw or sanger), or provide queue names to use in your own config file.\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-profiles\" class=\"anchor\" href=\"#profiles\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eProfiles\u003c/h4\u003e\n\u003cp\u003eYou can use multiple profiles at once, separating them with a comma. This is described in the Nextflow \u003ca href=\"https://www.nextflow.io/docs/latest/config.html#config-profiles\" rel=\"nofollow\"\u003edocumentation\u003c/a\u003e\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-config\" class=\"anchor\" href=\"#config\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eConfig\u003c/h4\u003e\n\u003cp\u003eCommon configuration options are set in \u003ccode\u003econf/base.config\u003c/code\u003e. Workflow specific configuration options are set in \u003ccode\u003econf/nanopore.config\u003c/code\u003e and \u003ccode\u003econf/illumina.config\u003c/code\u003e They are described and set to sensible defaults (as suggested in the \u003ca href=\"https://artic.network/ncov-2019/ncov2019-bioinformatics-sop.html\" title=\"nCoV-2019 novel coronavirus bioinformatics protocol\" rel=\"nofollow\"\u003enCoV-2019 novel coronavirus bioinformatics protocol\u003c/a\u003e)\u003c/p\u003e\n\u003ch5\u003e\n\u003ca id=\"user-content-options\" class=\"anchor\" href=\"#options\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eOptions\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003e--outdir\u003c/code\u003e sets the output directory.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e--bwa\u003c/code\u003e to swap to bwa for mapping (nanopore only).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5\u003e\n\u003ca id=\"user-content-workflows\" class=\"anchor\" href=\"#workflows\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWorkflows\u003c/h5\u003e\n\u003ch6\u003e\n\u003ca id=\"user-content-nanopore-1\" class=\"anchor\" href=\"#nanopore-1\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eNanopore\u003c/h6\u003e\n\u003cp\u003eUse \u003ccode\u003e--nanopolish\u003c/code\u003e or \u003ccode\u003e--medaka\u003c/code\u003e to run these workflows. \u003ccode\u003e--basecalled_fastq\u003c/code\u003e should point to a directory created by \u003ccode\u003eguppy_basecaller\u003c/code\u003e (if you ran with no barcodes), or \u003ccode\u003eguppy_barcoder\u003c/code\u003e (if you ran with barcodes). It is imperative that the following \u003ccode\u003eguppy_barcoder\u003c/code\u003e command be used for demultiplexing:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eguppy_barcoder --require_barcodes_both_ends -i run_name -s output_directory --arrangements_files \"barcode_arrs_nb12.cfg barcode_arrs_nb24.cfg\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch6\u003e\n\u003ca id=\"user-content-illumina-1\" class=\"anchor\" href=\"#illumina-1\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eIllumina\u003c/h6\u003e\n\u003cp\u003eThe Illumina workflow leans heavily on the excellent \u003ca href=\"https://github.com/andersen-lab/ivar\"\u003eivar\u003c/a\u003e for primer trimming and consensus making. This workflow will be updated to follow ivar, as its also in very active development! Use \u003ccode\u003e--illumina\u003c/code\u003e to run the Illumina workflow. Use \u003ccode\u003e--directory\u003c/code\u003e to point to an Illumina output directory usually coded something like: \u003ccode\u003e\u0026lt;date\u0026gt;_\u0026lt;machine_id\u0026gt;_\u0026lt;run_no\u0026gt;_\u0026lt;some_zeros\u0026gt;_\u0026lt;flowcell\u0026gt;\u003c/code\u003e. The workflow will recursively grab all fastq files under this directory, so be sure that what you want is in there, and what you don\u0027t, isn\u0027t!\u003c/p\u003e\n\u003cp\u003eImportant config options are:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth align=\"left\"\u003eOption\u003c/th\u003e\n\u003cth align=\"right\"\u003eDescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eallowNoprimer\u003c/td\u003e\n\u003ctd align=\"right\"\u003eAllow reads that don\u0027t have primer sequence? Ligation prep = false, nextera = true\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eilluminaKeepLen\u003c/td\u003e\n\u003ctd align=\"right\"\u003eLength of illumina reads to keep after primer trimming\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eilluminaQualThreshold\u003c/td\u003e\n\u003ctd align=\"right\"\u003eSliding window quality threshold for keeping reads after primer trimming (illumina)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003empileupDepth\u003c/td\u003e\n\u003ctd align=\"right\"\u003eMpileup depth for ivar\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eivarFreqThreshold\u003c/td\u003e\n\u003ctd align=\"right\"\u003eivar frequency threshold for variant\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eivarMinDepth\u003c/td\u003e\n\u003ctd align=\"right\"\u003eMinimum coverage depth to call variant\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-qc\" class=\"anchor\" href=\"#qc\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eQC\u003c/h4\u003e\n\u003cp\u003eA script to do some basic COG-UK QC is provided in \u003ccode\u003ebin/qc.py\u003c/code\u003e. This currently tests if \u0026gt;50% of reference bases are covered by \u0026gt;10 reads (Illumina) or \u0026gt;20 reads (Nanopore), OR if there is a stretch of more than 10 Kb of sequence without N - setting qc_pass in \u003ccode\u003e\u0026lt;outdir\u0026gt;/\u0026lt;prefix\u0026gt;.qc.csv\u003c/code\u003e to TRUE. \u003ccode\u003ebin/qc.py\u003c/code\u003e can be extended to incorporate any QC test, as long as the script outputs a csv file a \"qc_pass\" last column, with samples TRUE or FALSE.\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-output\" class=\"anchor\" href=\"#output\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eOutput\u003c/h4\u003e\n\u003cp\u003eA subdirectory for each process in the workflow is created in \u003ccode\u003e--outdir\u003c/code\u003e. A \u003ccode\u003eqc_pass_climb_upload\u003c/code\u003e subdirectory containing files important for \u003ca href=\"https://github.com/COG-UK\"\u003eCOG-UK\u003c/a\u003e is created.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 0,
    "topics": [],
    "updated_at": 1622550303.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "container/Singularity_madeline2",
      "container/Singularity"
    ],
    "full_name": "Genomic-Medicine-Linkoping/nextflow_wgs",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-gms-artic-ncov2019-artic-nf\" class=\"anchor\" href=\"#gms-artic-ncov2019-artic-nf\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGMS-artic (ncov2019-artic-nf)\u003c/h1\u003e\n\u003cp\u003eA Nextflow pipeline for running the ARTIC network\u0027s fieldbioinformatics tools (\u003ca href=\"https://github.com/artic-network/fieldbioinformatics\"\u003ehttps://github.com/artic-network/fieldbioinformatics\u003c/a\u003e), with a focus on ncov2019\u003c/p\u003e\n\u003cp\u003eWARNING - THIS REPO IS UNDER ACTIVE DEVELOPMENT AND ITS BEHAVIOUR MAY CHANGE AT \u003cstrong\u003eANY\u003c/strong\u003e TIME.\u003c/p\u003e\n\u003cp\u003ePLEASE ENSURE THAT YOU READ BOTH THE README AND THE CONFIG FILE AND UNDERSTAND THE EFFECT OF THE OPTIONS ON YOUR DATA!\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-introduction\" class=\"anchor\" href=\"#introduction\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eIntroduction\u003c/h4\u003e\n\u003chr\u003e\n\u003cp\u003eThis Nextflow pipeline automates the ARTIC network \u003ca href=\"https://artic.network/ncov-2019/ncov2019-bioinformatics-sop.html\" title=\"nCoV-2019 novel coronavirus bioinformatics protocol\" rel=\"nofollow\"\u003enCoV-2019 novel coronavirus bioinformatics protocol\u003c/a\u003e. It is being developed to aid the harmonisation of the analysis of sequencing data generated by the \u003ca href=\"https://github.com/COG-UK\"\u003eCOG-UK\u003c/a\u003e project. It will turn SARS-COV2 sequencing data (Illumina or Nanopore) into consensus sequences and provide other helpful outputs to assist the project\u0027s sequencing centres with submitting data.\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-quick-start\" class=\"anchor\" href=\"#quick-start\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eQuick-start\u003c/h4\u003e\n\u003ch5\u003e\n\u003ca id=\"user-content-illumina\" class=\"anchor\" href=\"#illumina\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eIllumina\u003c/h5\u003e\n\u003cp\u003e\u003ccode\u003enextflow run connor-lab/ncov2019-artic-nf [-profile conda,singularity,docker,slurm,lsf] --illumina --prefix \"output_file_prefix\" --directory /path/to/reads\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eYou can also use cram file input by passing the --cram flag.\nYou can also specify cram file output by passing the --outCram flag.\u003c/p\u003e\n\u003cp\u003eFor production use at large scale, where you will run the workflow many times, you can avoid cloning the scheme repository, creating an ivar bed file and indexing the reference every time by supplying both --ivarBed /path/to/ivar-compatible.bed and --alignerRefPrefix /path/to/bwa-indexed/ref.fa.\u003c/p\u003e\n\u003cp\u003eAlternatively you can avoid just the cloning of the scheme repository to remain on a fixed revision of it over time by passing --schemeRepoURL /path/to/own/clone/of/github.com/artic-network/artic-ncov2019. This removes any internet access from the workflow except for the optional upload steps.\u003c/p\u003e\n\u003ch5\u003e\n\u003ca id=\"user-content-nanopore\" class=\"anchor\" href=\"#nanopore\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eNanopore\u003c/h5\u003e\n\u003ch6\u003e\n\u003ca id=\"user-content-nanopolish\" class=\"anchor\" href=\"#nanopolish\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eNanopolish\u003c/h6\u003e\n\u003cp\u003e\u003ccode\u003enextflow run connor-lab/ncov2019-artic-nf [-profile conda,singularity,docker,slurm,lsf] --nanopolish --prefix \"output_file_prefix\" --basecalled_fastq /path/to/directory --fast5_pass /path/to/directory --sequencing_summary /path/to/sequencing_summary.txt\u003c/code\u003e\u003c/p\u003e\n\u003ch6\u003e\n\u003ca id=\"user-content-medaka\" class=\"anchor\" href=\"#medaka\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMedaka\u003c/h6\u003e\n\u003cp\u003e\u003ccode\u003enextflow run connor-lab/ncov2019-artic-nf [-profile conda,singularity,docker,slurm,lsf] --medaka --prefix \"output_file_prefix\" --basecalled_fastq /path/to/directory --fast5_pass /path/to/directory --sequencing_summary /path/to/sequencing_summary.txt\u003c/code\u003e\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-installation\" class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation\u003c/h4\u003e\n\u003cp\u003eAn up-to-date version of Nextflow is required because the pipeline is written in DSL2. Following the instructions at \u003ca href=\"https://www.nextflow.io/\" rel=\"nofollow\"\u003ehttps://www.nextflow.io/\u003c/a\u003e to download and install Nextflow should get you a recent-enough version.\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-containers\" class=\"anchor\" href=\"#containers\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContainers\u003c/h4\u003e\n\u003cp\u003eThis repo contains both Singularity and Dockerfiles. You can build the Singularity containers locally by running \u003ccode\u003escripts/build_singularity_containers.sh\u003c/code\u003e and use them with \u003ccode\u003e-profile singularity\u003c/code\u003e The containers will be available from Docker/Singularityhub shortly.\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-conda\" class=\"anchor\" href=\"#conda\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eConda\u003c/h4\u003e\n\u003cp\u003eThe repo contains a environment.yml files which automatically build the correct conda env if \u003ccode\u003e-profile conda\u003c/code\u003e is specifed in the command. Although you\u0027ll need \u003ccode\u003econda\u003c/code\u003e installed, this is probably the easiest way to run this pipeline.\u003c/p\u003e\n\u003cp\u003e--cache /some/dir can be specified to have a fixed, shared location to store the conda build for use by multiple runs of the workflow.\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-executors\" class=\"anchor\" href=\"#executors\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eExecutors\u003c/h4\u003e\n\u003cp\u003eBy default, the pipeline just runs on the local machine. You can specify \u003ccode\u003e-profile slurm\u003c/code\u003e to use a SLURM cluster, or \u003ccode\u003e-profile lsf\u003c/code\u003e to use an LSF cluster. In either case you may need to also use one of the COG-UK institutional config profiles (phw or sanger), or provide queue names to use in your own config file.\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-profiles\" class=\"anchor\" href=\"#profiles\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eProfiles\u003c/h4\u003e\n\u003cp\u003eYou can use multiple profiles at once, separating them with a comma. This is described in the Nextflow \u003ca href=\"https://www.nextflow.io/docs/latest/config.html#config-profiles\" rel=\"nofollow\"\u003edocumentation\u003c/a\u003e\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-config\" class=\"anchor\" href=\"#config\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eConfig\u003c/h4\u003e\n\u003cp\u003eCommon configuration options are set in \u003ccode\u003econf/base.config\u003c/code\u003e. Workflow specific configuration options are set in \u003ccode\u003econf/nanopore.config\u003c/code\u003e and \u003ccode\u003econf/illumina.config\u003c/code\u003e They are described and set to sensible defaults (as suggested in the \u003ca href=\"https://artic.network/ncov-2019/ncov2019-bioinformatics-sop.html\" title=\"nCoV-2019 novel coronavirus bioinformatics protocol\" rel=\"nofollow\"\u003enCoV-2019 novel coronavirus bioinformatics protocol\u003c/a\u003e)\u003c/p\u003e\n\u003ch5\u003e\n\u003ca id=\"user-content-options\" class=\"anchor\" href=\"#options\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eOptions\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003e--outdir\u003c/code\u003e sets the output directory.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e--bwa\u003c/code\u003e to swap to bwa for mapping (nanopore only).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5\u003e\n\u003ca id=\"user-content-workflows\" class=\"anchor\" href=\"#workflows\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWorkflows\u003c/h5\u003e\n\u003ch6\u003e\n\u003ca id=\"user-content-nanopore-1\" class=\"anchor\" href=\"#nanopore-1\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eNanopore\u003c/h6\u003e\n\u003cp\u003eUse \u003ccode\u003e--nanopolish\u003c/code\u003e or \u003ccode\u003e--medaka\u003c/code\u003e to run these workflows. \u003ccode\u003e--basecalled_fastq\u003c/code\u003e should point to a directory created by \u003ccode\u003eguppy_basecaller\u003c/code\u003e (if you ran with no barcodes), or \u003ccode\u003eguppy_barcoder\u003c/code\u003e (if you ran with barcodes). It is imperative that the following \u003ccode\u003eguppy_barcoder\u003c/code\u003e command be used for demultiplexing:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eguppy_barcoder --require_barcodes_both_ends -i run_name -s output_directory --arrangements_files \"barcode_arrs_nb12.cfg barcode_arrs_nb24.cfg\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch6\u003e\n\u003ca id=\"user-content-illumina-1\" class=\"anchor\" href=\"#illumina-1\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eIllumina\u003c/h6\u003e\n\u003cp\u003eThe Illumina workflow leans heavily on the excellent \u003ca href=\"https://github.com/andersen-lab/ivar\"\u003eivar\u003c/a\u003e for primer trimming and consensus making. This workflow will be updated to follow ivar, as its also in very active development! Use \u003ccode\u003e--illumina\u003c/code\u003e to run the Illumina workflow. Use \u003ccode\u003e--directory\u003c/code\u003e to point to an Illumina output directory usually coded something like: \u003ccode\u003e\u0026lt;date\u0026gt;_\u0026lt;machine_id\u0026gt;_\u0026lt;run_no\u0026gt;_\u0026lt;some_zeros\u0026gt;_\u0026lt;flowcell\u0026gt;\u003c/code\u003e. The workflow will recursively grab all fastq files under this directory, so be sure that what you want is in there, and what you don\u0027t, isn\u0027t!\u003c/p\u003e\n\u003cp\u003eImportant config options are:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth align=\"left\"\u003eOption\u003c/th\u003e\n\u003cth align=\"right\"\u003eDescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eallowNoprimer\u003c/td\u003e\n\u003ctd align=\"right\"\u003eAllow reads that don\u0027t have primer sequence? Ligation prep = false, nextera = true\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eilluminaKeepLen\u003c/td\u003e\n\u003ctd align=\"right\"\u003eLength of illumina reads to keep after primer trimming\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eilluminaQualThreshold\u003c/td\u003e\n\u003ctd align=\"right\"\u003eSliding window quality threshold for keeping reads after primer trimming (illumina)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003empileupDepth\u003c/td\u003e\n\u003ctd align=\"right\"\u003eMpileup depth for ivar\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eivarFreqThreshold\u003c/td\u003e\n\u003ctd align=\"right\"\u003eivar frequency threshold for variant\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eivarMinDepth\u003c/td\u003e\n\u003ctd align=\"right\"\u003eMinimum coverage depth to call variant\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-qc\" class=\"anchor\" href=\"#qc\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eQC\u003c/h4\u003e\n\u003cp\u003eA script to do some basic COG-UK QC is provided in \u003ccode\u003ebin/qc.py\u003c/code\u003e. This currently tests if \u0026gt;50% of reference bases are covered by \u0026gt;10 reads (Illumina) or \u0026gt;20 reads (Nanopore), OR if there is a stretch of more than 10 Kb of sequence without N - setting qc_pass in \u003ccode\u003e\u0026lt;outdir\u0026gt;/\u0026lt;prefix\u0026gt;.qc.csv\u003c/code\u003e to TRUE. \u003ccode\u003ebin/qc.py\u003c/code\u003e can be extended to incorporate any QC test, as long as the script outputs a csv file a \"qc_pass\" last column, with samples TRUE or FALSE.\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-output\" class=\"anchor\" href=\"#output\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eOutput\u003c/h4\u003e\n\u003cp\u003eA subdirectory for each process in the workflow is created in \u003ccode\u003e--outdir\u003c/code\u003e. A \u003ccode\u003eqc_pass_climb_upload\u003c/code\u003e subdirectory containing files important for \u003ca href=\"https://github.com/COG-UK\"\u003eCOG-UK\u003c/a\u003e is created.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 0,
    "topics": [],
    "updated_at": 1622549895.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "container/Singularity"
    ],
    "full_name": "Genomic-Medicine-Linkoping/gms-JASEN",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-jasen\" class=\"anchor\" href=\"#jasen\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eJASEN\u003c/h1\u003e\n\u003cp\u003e\u003cem\u003eJson producing Assembly driven microbial Sequence analysis pipeline to support Epitypification and Normalize classification decisions\u003c/em\u003e\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-setup\" class=\"anchor\" href=\"#setup\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSetup\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003egit clone --recurse-submodules --single-branch --branch master  https://github.com/genomic-medicine-sweden/JASEN.git\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eEdit \u003ccode\u003eJASEN/nextflow.config\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cem\u003e\u003ccode\u003eOptionally run: bash JASEN/container/safety_exports.sh USER PREFIX\u003c/code\u003e\u003c/em\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-singularity-implementation\" class=\"anchor\" href=\"#singularity-implementation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSingularity implementation\u003c/h2\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-image-creation\" class=\"anchor\" href=\"#image-creation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eImage creation\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eInstall Singularity (through conda or whatever)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecd JASEN/container \u0026amp;\u0026amp; bash build_container.sh\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-image-execution\" class=\"anchor\" href=\"#image-execution\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eImage execution\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003esingularity exec -B JASEN_INSTALL_DIR:/external -B WORKDIR:/out IMAGE nextflow -C /external/nextflow.config run /JASEN/main.nf -profile local,singularity\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-conda-implementation\" class=\"anchor\" href=\"#conda-implementation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eConda implementation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eInstall Conda ( \u003ca href=\"https://www.anaconda.com/distribution\" rel=\"nofollow\"\u003ehttps://www.anaconda.com/distribution\u003c/a\u003e )\u003c/li\u003e\n\u003cli\u003eInstall nextFlow ( \u003ccode\u003ecurl -s https://get.nextflow.io | bash\u003c/code\u003e )\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ebash JASEN/setup.sh\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003enextflow run JASEN/main.nf -profile -local,conda\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 0,
    "topics": [],
    "updated_at": 1622549694.0
  },
  {
    "data_format": 2,
    "description": "Collection of dockerfile/singularity setups",
    "filenames": [
      "ants/Singularity.libadjoint-2017-2_ants",
      "meshtool/Singularity.meshtool",
      "fenics/2017.2.0_libadjoint_ants/Singularity.libadjoint-2017-2_ants",
      "fenics/2017.2.0_libadjoint/Singularity.libadjoint-2017-2",
      "fenics/2017.2.0_libadjoint_ants_meshtool/Singularity.libadjoint-2017-2_ants_meshtool"
    ],
    "full_name": "danielabler/dockerfiles",
    "latest_release": null,
    "readme": "\u003cp\u003e\u003ca href=\"https://singularity-hub.org/collections/2950\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a07b23d4880320ac89cdc93bbbb603fa84c215d135e05dd227ba8633a9ff34be/68747470733a2f2f7777772e73696e67756c61726974792d6875622e6f72672f7374617469632f696d672f686f737465642d73696e67756c61726974792d2d6875622d2532336533323932392e737667\" alt=\"https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg\" data-canonical-src=\"https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 0,
    "topics": [],
    "updated_at": 1622531520.0
  },
  {
    "data_format": 2,
    "description": "Singularity recipe files for bonito (https://github.com/nanoporetech/bonito)",
    "filenames": [
      "Singularity.0.4.0",
      "Singularity",
      "Singularity.0.3.6"
    ],
    "full_name": "powerPlant/bonito-srf",
    "latest_release": null,
    "readme": "\u003cp\u003eSingularity recipe files for bonito, a PyTorch Basecaller for Oxford Nanopore Reads\n\u003ca href=\"https://github.com/nanoporetech/bonito\"\u003ehttps://github.com/nanoporetech/bonito\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 0,
    "topics": [],
    "updated_at": 1622585462.0
  },
  {
    "data_format": 2,
    "description": "Singlularity containers",
    "filenames": [
      "singularity/Singularity"
    ],
    "full_name": "kb2623/singularity-builds",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularity-builds\" class=\"anchor\" href=\"#singularity-builds\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003esingularity-builds\u003c/h1\u003e\n\u003cp\u003eSinglularity containers\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1622472468.0
  },
  {
    "data_format": 2,
    "description": "Singularity image for a deep learning (pytorch) environment + GPU support",
    "filenames": [
      "Singularity.1.0.0"
    ],
    "full_name": "manuel-munoz-aguirre/singularity-pytorch-gpu",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularity-pytorch-gpu\" class=\"anchor\" href=\"#singularity-pytorch-gpu\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003esingularity-pytorch-gpu\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://singularity-hub.org/collections/4969\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a07b23d4880320ac89cdc93bbbb603fa84c215d135e05dd227ba8633a9ff34be/68747470733a2f2f7777772e73696e67756c61726974792d6875622e6f72672f7374617469632f696d672f686f737465642d73696e67756c61726974792d2d6875622d2532336533323932392e737667\" alt=\"https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg\" data-canonical-src=\"https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSingularity image for a deep learning (pytorch) environment + GPU support (cuda-10.2). Contains libraries to perform common ML tasks. \u003ccode\u003eOpenslide\u003c/code\u003e is included to manipulate whole-slide histology images, \u003ccode\u003eimagemagick\u003c/code\u003e for general image manipulation. \u003ccode\u003eJupyterLab\u003c/code\u003e and \u003ccode\u003ecode-server\u003c/code\u003e (VS Code) are also included in the image. This image has been tested in an HPC (SGE) with distributed pytorch applications.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-installing-singularity\" class=\"anchor\" href=\"#installing-singularity\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstalling singularity\u003c/h2\u003e\n\u003cp\u003eTo install singularity, see the \u003ca href=\"https://sylabs.io/guides/3.6/admin-guide/installation.html#installation-on-linux\" rel=\"nofollow\"\u003eofficial docs\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-buildingdownloading-the-image\" class=\"anchor\" href=\"#buildingdownloading-the-image\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding/downloading the image\u003c/h2\u003e\n\u003cp\u003eTo build an image called \u003ccode\u003etorchenv.sif\u003c/code\u003e based on the definition file \u003ccode\u003eSingularity.1.0.0\u003c/code\u003e, an NVIDIA GPU and \u003ccode\u003ecuda-10.2\u003c/code\u003e drivers must be available on the host system. Clone this repository, move into it and run the singularity build command.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone https://github.com/manuel-munoz-aguirre/singularity-pytorch-gpu.git \u0026amp;\u0026amp; \\\ncd singularity-pytorch-gpu \u0026amp;\u0026amp; \\\nsudo singularity build torchenv.sif Singularity.1.0.0\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOtherwise, the image can be pulled directly from singularity hub:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esingularity pull torchenv.sif shub://manuel-munoz-aguirre/singularity-pytorch-gpu:1.0.0\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-using-the-container\" class=\"anchor\" href=\"#using-the-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsing the container\u003c/h2\u003e\n\u003cp\u003eTo spawn an interactive shell within the container, use the command below. The \u003ccode\u003e--nv\u003c/code\u003e flag setups the container to use NVIDIA GPUs (read more \u003ca href=\"https://sylabs.io/guides/3.6/user-guide/gpu.html\" rel=\"nofollow\"\u003ehere\u003c/a\u003e).\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esingularity shell --nv torchenv.sif\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo run a script (for example, \u003ccode\u003escript.py\u003c/code\u003e) using the container without starting an interactive shell:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esingularity exec --nv torchenv.sif python3 script.py\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe container can also be launched and used on a system without a GPU, but upon startup it will display a warning about missing NVIDIA binaries on the host.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [
      "singularity",
      "pytorch",
      "deep-learning",
      "machine-learning",
      "environment"
    ],
    "updated_at": 1622471136.0
  },
  {
    "data_format": 2,
    "description": "A quick reference repository for using the robots in the COR lab",
    "filenames": [
      "containers/singularity/Singularity.ros_melodic-bionic",
      "containers/singularity/Singularity.ros_noetic-focal",
      "real_panda_moveit_control/containers/singularity/Singularity.ros_noetic-focal"
    ],
    "full_name": "rickstaa/COR-robotics-lab-reference",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-cor-robotics-lab-reference\" class=\"anchor\" href=\"#cor-robotics-lab-reference\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCOR-robotics-lab-reference\u003c/h1\u003e\n\u003cp\u003eA quick reference repository for using the robots in the COR lab. This repository contains several code examples, a \u003ca href=\"https://github.com/rickstaa/COR-robotics-lab-reference/discussions\"\u003ediscussion forum\u003c/a\u003e with FAQ that you might have while working with the robot and a \u003ca href=\"https://github.com/rickstaa/COR-robotics-lab-reference/wiki\"\u003ewiki\u003c/a\u003e with several helpfull documents\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-how-to-reserve-the-robots\" class=\"anchor\" href=\"#how-to-reserve-the-robots\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow to reserve the robots\u003c/h2\u003e\n\u003cp\u003ePlease check the \u003cg-emoji class=\"g-emoji\" alias=\"spiral_calendar\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f5d3.png\"\u003e\ud83d\uddd3\ufe0f\u003c/g-emoji\u003e \u003ca href=\"https://github.com/rickstaa/COR-robotics-lab-reference/wiki/%F0%9F%97%93%EF%B8%8F-Robot-reservation-forum\"\u003erobot reservation form\u003c/a\u003e wiki page for more information.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-how-to-work-with-the-robots\" class=\"anchor\" href=\"#how-to-work-with-the-robots\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow to work with the robots\u003c/h2\u003e\n\u003cp\u003ePlease check \u003cg-emoji class=\"g-emoji\" alias=\"safety_vest\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f9ba.png\"\u003e\ud83e\uddba\u003c/g-emoji\u003e \u003ca href=\"https://github.com/rickstaa/COR-robotics-lab-reference/wiki/Panda-safety-guidelines\"\u003esafety-guidelines\u003c/a\u003e in the wiki before working with the robot.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1622205744.0
  },
  {
    "data_format": 2,
    "description": "UPPMAX Singularity builds",
    "filenames": [
      "MitoZ/Singularity.v2.3-pm",
      "gapseq/Singularity.gapseq",
      "UniteM/Singularity.UniteM",
      "bonito/Singularity.bonito",
      "metaWRAP/Singularity.metaWRAP-deps-only-ubuntu",
      "metaWRAP/Singularity.metaWRAP",
      "metaWRAP/Singularity.metaWRAP-deps-only"
    ],
    "full_name": "pmitev/UPPMAX-Singularity",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-uppmax-singularity\" class=\"anchor\" href=\"#uppmax-singularity\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUPPMAX-Singularity\u003c/h1\u003e\n\u003cp\u003eUPPMAX Singularity builds\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1622469290.0
  },
  {
    "data_format": 2,
    "description": "nextflow pipeline to automate analysis using ALE (https://github.com/ssolo/ALE)",
    "filenames": [
      "Singularity"
    ],
    "full_name": "maxemil/ALE-pipeline",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-ale-pipeline\" class=\"anchor\" href=\"#ale-pipeline\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eALE-pipeline\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003ethis is supposed to be a nice pipeline for running ALE on several gene clusters and collecting the results\u003c/li\u003e\n\u003cli\u003eit can also test several species trees at the same time\u003c/li\u003e\n\u003cli\u003eall parameters in the nextflow.config file can be changed on the command line, e.g. the name of the outgroup taxa\u003c/li\u003e\n\u003cli\u003eyou need to add the Python_lib repo to your Pythonpath\u003c/li\u003e\n\u003cli\u003eFor typical usage and a small tutorial, see TUTORIAL.md\u003c/li\u003e\n\u003cli\u003eI use to code the names for species both in the species and in the gene tree to avoid that source of errors\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-troubleshooting\" class=\"anchor\" href=\"#troubleshooting\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTroubleshooting\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eIf you get an Error \u0027Can\u0027t root with myself\u0027 or similar, this usually means that the outgroup you specified for the species tree is not monophyletic in that tree. Try rerooting by hand first...\u003c/li\u003e\n\u003cli\u003eALE sometime simply crashes, then the pipeline can be resumed by adding \u003ccode\u003e-resume\u003c/code\u003e to the invocation\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [
      "nextflow",
      "evolution",
      "bioinformatics",
      "singularity-container",
      "pipeline"
    ],
    "updated_at": 1622468753.0
  },
  {
    "data_format": 2,
    "description": "Simulating, Reconstructing and Analysing Data for FEL IDI Experiments",
    "filenames": [
      "Singularity.simple",
      "Singularity.py38",
      "Singularity"
    ],
    "full_name": "fzimmermann89/idi",
    "latest_release": "210531",
    "readme": "\u003cp\u003eCAVE: Hic sunt dracones\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eThe code is a mess, undocumented and only certain code paths are tested.\u003c/em\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-idi---incoherent-diffraction-imaging\" class=\"anchor\" href=\"#idi---incoherent-diffraction-imaging\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eIDI - INCOHERENT DIFFRACTION IMAGING\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://singularity-hub.org/collections/4824\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a07b23d4880320ac89cdc93bbbb603fa84c215d135e05dd227ba8633a9ff34be/68747470733a2f2f7777772e73696e67756c61726974792d6875622e6f72672f7374617469632f696d672f686f737465642d73696e67756c61726974792d2d6875622d2532336533323932392e737667\" alt=\"https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg\" data-canonical-src=\"https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/fzimmermann89/idi/actions/workflows/test.yml/badge.svg\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://github.com/fzimmermann89/idi/actions/workflows/test.yml/badge.svg\" alt=\"tests\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://camo.githubusercontent.com/a1aa13bc475e383774716a28c54db51e680a438815882cb99e8443eb94a873db/68747470733a2f2f7777772e7472617669732d63692e636f6d2f667a696d6d65726d616e6e38392f6964692e7376673f6272616e63683d6d6173746572\" target=\"_blank\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a1aa13bc475e383774716a28c54db51e680a438815882cb99e8443eb94a873db/68747470733a2f2f7777772e7472617669732d63692e636f6d2f667a696d6d65726d616e6e38392f6964692e7376673f6272616e63683d6d6173746572\" alt=\"Build Status\" data-canonical-src=\"https://www.travis-ci.com/fzimmermann89/idi.svg?branch=master\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSingularity Image now at \u003ca href=\"https://cloud.sylabs.io/library/_container/607b669a4ad4aa1fdea0c43c\" rel=\"nofollow\"\u003elibrary://fzimmermann89/idi/idi\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eConda Pacakges at \u003ca href=\"https://anaconda.org/zimmf/idi\" rel=\"nofollow\"\u003ezimmf/idi\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePIP Source at \u003ca href=\"https://pypi.org/project/idi/\" rel=\"nofollow\"\u003eidi\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eWheels at \u003ca href=\"https://github.com/fzimmermann89/idi/releases/latest\"\u003eReleases\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-content-of-the-repo\" class=\"anchor\" href=\"#content-of-the-repo\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003econtent of the repo\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eipynb: example notebooks\u003c/li\u003e\n\u003cli\u003esimulation: simulation of incoherent images\u003c/li\u003e\n\u003cli\u003ereconstruction: direct and ft based reconstruction\u003c/li\u003e\n\u003cli\u003eutil: some small utilities for data analysis, geometry and random distributions, etc.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-preparation-for-slac-sdf\" class=\"anchor\" href=\"#preparation-for-slac-sdf\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003epreparation for slac sdf:\u003c/h2\u003e\n\u003cp\u003eUse Singulariy, if using OOD launcher, use the following to start a jupyterhub\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e    function jupyter() { singularity run --app jupyter --nv -B /sdf,/gpfs,/scratch,/lscratch library://fzimmermann89/idi/idi $@; }\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-preparation-for-sacla\" class=\"anchor\" href=\"#preparation-for-sacla\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003epreparation for sacla:\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eDownload and install miniconda, setup ssh tunnel for web access.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003econda create -n local3 python=3.7 numpy mkl mkl-dev ipython ipykernel cython jinja2 numba numexpr matplotlib six scipy jupyterlab\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003econda activate local3\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003epip install https://github.com/fzimmermann89/idi/\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003epython -m ipykernel install --user --name local-simulation-env3 --display-name \"local simulation(py37)\"\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(C) Felix Zimmermann\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [
      "idi",
      "reconstruction",
      "simulation",
      "xray",
      "incoherent-images",
      "fel"
    ],
    "updated_at": 1622507797.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "Singularity"
    ],
    "full_name": "oogasawa/singularity_ubuntu20",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularity-ubuntu20\" class=\"anchor\" href=\"#singularity-ubuntu20\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003esingularity-ubuntu20\u003c/h1\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1622347084.0
  },
  {
    "data_format": 2,
    "description": "Benchmark kallisto against HISAT2 + featureCounts in eQTL mapping ",
    "filenames": [
      "qtlmap/Singularity"
    ],
    "full_name": "aleks96n/BioInfoKallisto",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-bioinfokallisto\" class=\"anchor\" href=\"#bioinfokallisto\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBioInfoKallisto\u003c/h1\u003e\n\u003cp\u003eBenchmark kallisto against HISAT2 + featureCounts in eQTL mapping\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-step-1---installing-kallisto\" class=\"anchor\" href=\"#step-1---installing-kallisto\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eStep 1 - installing kallisto\u003c/h1\u003e\n\u003cp\u003eIt is highly encouraged to use \u003ca href=\"https://hpc.ut.ee/en/guides/slurm/\" rel=\"nofollow\"\u003eHPC\u003c/a\u003e. Not only will this speed up the analysis, but will also give access to some important files that you cannot get easily without the use of HPC.\u003c/p\u003e\n\u003cp\u003eInstall \u003ca href=\"https://docs.conda.io/en/latest/miniconda.html\" rel=\"nofollow\"\u003eminiconda\u003c/a\u003e for Linux, newest Python version (version 3.9 as of this edit).\u003c/p\u003e\n\u003cp\u003ePut it in your HCP using the following bash command (alternatively, use FileZilla). Once it is in place, run the second command to install miniconda\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003escp \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003efilename\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e user@rocket.hpc.ut.ee:directoy\nbash \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003econda file\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eRestart HPC before doing executing any more commands. After restarting, run the following command to install kallisto.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003econda install -c bioconda kallisto\u003c/pre\u003e\u003c/div\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-step-2---creating-the-transcript-file-for-kallisto\" class=\"anchor\" href=\"#step-2---creating-the-transcript-file-for-kallisto\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eStep 2 - creating the transcript file for kallisto\u003c/h1\u003e\n\u003cp\u003eCopy the genotype transcripts file to your work directory (where the makeTranscript.sh is located). Note that you can change the name of the transcripts.fa file, however, you will have to modify bash script for parallezation.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ecp /gpfs/hpc/projects/genomic_references/annotations/eQTLCatalogue/v0.1/gencode.v30.transcripts.fa gencode.v30.transcripts.fa\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eCreate a separate stage for your HPC\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003essh stage1\nscreen\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you want to be notified when the transcript file is created, modify the makeTranscript.sh file by adding the following two lines right after #SBATCH --mem=32G\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eSBATCH --mail-type=END\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eSBATCH --mail-user=\u0026lt;YOUR_EMAIL@EMAIL.DOMAIN\u0026gt;\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eRun the bash script for parallelization, which is provided in the github repository. This process takes about 15 minutes. After it is finished, you should see a transcript.idx file in your work directory.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003esbatch makeTranscript.sh\u003c/pre\u003e\u003c/div\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-step-3---creating-fastq-somethings-jens-you-got-this\" class=\"anchor\" href=\"#step-3---creating-fastq-somethings-jens-you-got-this\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eStep 3 - Creating fastQ somethings (Jens you got this)\u003c/h1\u003e\n\u003cp\u003eIt is recommended to get acquainted with \u003ca href=\"https://github.com/AlasooLab/onboarding/blob/main/resources/nextflow.md\"\u003enextflow\u003c/a\u003e before moving further. However, it is optional.\u003c/p\u003e\n\u003cp\u003eRun the following two commands (hopefully still on a separate stage) to create fastQ somethings. This takes approximately 3 and a half hours.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003emodule load java-1.8.0_40\n./nextflow makeFastq.nf --studyFile study_file.txt\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eRun the python script to create an out.tsv somethings and move it to the qtlmap testdata folder.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003emodule load python\npython makeMatrix.py ResultsQ\nmv out.tsv qtlmap/testdata/out.tsv\u003c/pre\u003e\u003c/div\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-step-4---running-the-eqtl-analysis\" class=\"anchor\" href=\"#step-4---running-the-eqtl-analysis\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eStep 4 - Running the eQTL analysis\u003c/h1\u003e\n\u003cp\u003eNavigate to the qtlmap directory\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e qtlmap\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFinally, run the eQTL analysis using the following command (still on a separate stage). Note the end of the command asks for your email - this is for notifying when the work is done.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003emodule load java-1.8.0_40\nmodule load singularity/3.5.3\n\nnextflow run main.nf -resume --run_permutation -profile tartu_hpc   --studyFile testdata/multi_test.tsv --vcf_has_R2_field FALSE    --varid_rsid_map_file testdata/varid_rsid_map.tsv.gz --n_batches 200 --run_nominal \u003cspan class=\"pl-c1\"\u003efalse\u003c/span\u003e --email \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003esinu@email.com\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis should create a \"results\" folder. Most notable file is results/sumstats/GEUVADIS_test_ge.permuted.tsv.\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-step-5---comparing-with-other-results\" class=\"anchor\" href=\"#step-5---comparing-with-other-results\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eStep 5 - comparing with other results\u003c/h1\u003e\n\u003cp\u003eNote that you require the kallisto file that you got from Step 4 and another .tsv file for comparison. In order to create the comparison, modify the \"eQTLcomparison.r\" script by adding appropriate file paths.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ehisat \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003e-  read.csv(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u0026lt;comparison_file.tsv\u0026gt;\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, sep = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\\t\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e, header = TRUE)\nkallista \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003e- read.csv(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u0026lt;kallisto.tsv\u0026gt;\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, sep = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\\t\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e, header = TRUE)\u003c/pre\u003e\u003c/div\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1622297189.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "Singularity"
    ],
    "full_name": "Samip1211/flaskrestful_mongo",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularity-cudaxgboost\" class=\"anchor\" href=\"#singularity-cudaxgboost\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003esingularity-cudaxgboost\u003c/h1\u003e\n\u003cp\u003eSingularity container definition for XGBoost/hipe4ml environment\u003c/p\u003e\n\u003cp\u003eThis is a minimal container for running Hipe4ML (\u003ca href=\"https://github.com/hipe4ml/hipe4ml\"\u003ehttps://github.com/hipe4ml/hipe4ml\u003c/a\u003e) with XGBoost, including NVidia GPU support with CUDA 11.0. Based on the official CUDA image from NVidia, \u003ca href=\"https://hub.docker.com/r/nvidia/cuda\" rel=\"nofollow\"\u003ehttps://hub.docker.com/r/nvidia/cuda\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eNOTE: If using a GPU method in XGBoost such as \"gpu_tree\", the container must be run with the --nv switch (e.g. \"singularity exec --nv [COMMAND]\") in order to access the driver binaries on the host machine.\u003c/p\u003e\n\u003cp\u003eThis environment is also compatible with CPU-only running of Hipe4ML on any host machine, without any additional setup.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1502317691.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "Singularity"
    ],
    "full_name": "Samip1211/MongoImage",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularity-cudaxgboost\" class=\"anchor\" href=\"#singularity-cudaxgboost\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003esingularity-cudaxgboost\u003c/h1\u003e\n\u003cp\u003eSingularity container definition for XGBoost/hipe4ml environment\u003c/p\u003e\n\u003cp\u003eThis is a minimal container for running Hipe4ML (\u003ca href=\"https://github.com/hipe4ml/hipe4ml\"\u003ehttps://github.com/hipe4ml/hipe4ml\u003c/a\u003e) with XGBoost, including NVidia GPU support with CUDA 11.0. Based on the official CUDA image from NVidia, \u003ca href=\"https://hub.docker.com/r/nvidia/cuda\" rel=\"nofollow\"\u003ehttps://hub.docker.com/r/nvidia/cuda\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eNOTE: If using a GPU method in XGBoost such as \"gpu_tree\", the container must be run with the --nv switch (e.g. \"singularity exec --nv [COMMAND]\") in order to access the driver binaries on the host machine.\u003c/p\u003e\n\u003cp\u003eThis environment is also compatible with CPU-only running of Hipe4ML on any host machine, without any additional setup.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1565456485.0
  },
  {
    "data_format": 2,
    "description": "Regularization is all you Need: Simple Neural Nets can Excel on Tabular Data",
    "filenames": [
      "AutoPyTorch/scripts/Singularity"
    ],
    "full_name": "ConferencePaperSubmission/RegularizationCocktail",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-regularization-is-all-you-need-simple-neural-nets-can-excel-on-tabular-data\" class=\"anchor\" href=\"#regularization-is-all-you-need-simple-neural-nets-can-excel-on-tabular-data\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRegularization is all you Need: Simple Neural Nets can Excel on Tabular Data\u003c/h1\u003e\n\u003cp\u003eTabular datasets are the last \"unconquered castle\" by deep learning and traditional ML methods like Gradient-Boosted Decision Trees still perform strongly even against recent specialized neural architectures. In this paper, we hypothesize that the key to boosting the performance of neural networks lies in rethinking the joint and simultaneous application of a large set of modern regularization techniques. As a result, we propose regularizing plain Multilayer Perceptron (MLP) networks by searching for the optimal combination/cocktail of 13 regularization techniques for each dataset as a Combined Algorithm Selection and Hyperparameter Optimization. To validate our hypothesis we empirically assess the impact of the regularization cocktails for MLPs on a large-scale empirical study comprising 40 datasets and demonstrate that (i) well-regularized plain MLPs significantly outperform recent state-of-the-art specialized neural network architectures, and that (ii) our well-regularized networks even outperform strong traditional ML methods such as XGBoost on tabular datasets.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSource code for NeurIPS submission 2133\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOur implementation of regularization cocktails is based on a fork of AutoPyTorch and this fork is part of the submission to ensure full reproducibility.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eThe code for the experiments with the baselines (AutoGluon, XGBoost, auto-sklearn, NODE and TabNet) can be found under the baselines folder.\u003c/strong\u003e\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1622167921.0
  },
  {
    "data_format": 2,
    "description": "Singularity recipe for vm",
    "filenames": [
      "Singularity"
    ],
    "full_name": "halbakri/singularity-vim",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularity-vim\" class=\"anchor\" href=\"#singularity-vim\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003esingularity-vim\u003c/h1\u003e\n\u003cp\u003eVim is a clone, with additions, of Bill Joy\u0027s vi text editor program for Unix.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003ca href=\"http://www.psc.edu\" rel=\"nofollow\"\u003ePittsburgh Supercomputing Center\u003c/a\u003e in the \u003ca href=\"https://www.cmu.edu/mcs/\" rel=\"nofollow\"\u003eMellon College of Science\u003c/a\u003e at \u003ca href=\"http://www.cmu.edu\" rel=\"nofollow\"\u003eCarnegie Mellon University\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1622145600.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "singularity/Singularity.align_dedup.v1.0",
      "singularity/Singularity.bcftools.v1.10.2",
      "singularity/Singularity.sv_call.v1.0",
      "singularity/Singularity.expansion_hunter.v3.2.2",
      "singularity/Singularity.vcf_processing.v1.0",
      "singularity/Singularity.qcbam.v1.0",
      "singularity/Singularity.sv_processing.v1.0"
    ],
    "full_name": "edg1983/WGS_pipeline",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-wgs-analysis-pipeline\" class=\"anchor\" href=\"#wgs-analysis-pipeline\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWGS analysis pipeline\u003c/h1\u003e\n\u003cp\u003eWGS analysis pipeline. Can handle both WGS and WES data.\u003c/p\u003e\n\u003cp\u003eThe whole pipeline use singularity images and will pull images from singularity libraries when needed\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-how-to-run\" class=\"anchor\" href=\"#how-to-run\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow to run\u003c/h2\u003e\n\u003cp\u003eThe pipeline can be run directly using Nextflow \u0026gt;= v20.10.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003enextflow WGS_analysis.nf -profile cluster --operation align --input input_file.txt --mode WGS --ped ped_file.ped --cohort_id cohort_name --outdir results\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe pipeline automatically infer the number of samples in the cohort from your input file. When more than one sample is present, small variants and structural variants from all samples are merged in cohort wide VCF files.\u003c/p\u003e\n\u003cp\u003eEventually update \u003ccode\u003esingularity_cachedir\u003c/code\u003e variable in \u003ccode\u003enextflow.config\u003c/code\u003e to point to a proper folder where singularity images are stored / will be downloaded\u003c/p\u003e\n\u003cp\u003eA bash script \u003ccode\u003eRun_pipeline.sh\u003c/code\u003e is provided for convenience to set environmental variables for singularity cache and temp directories. The \u003ccode\u003esingularity_dir\u003c/code\u003e variable in the script must match \u003ccode\u003esingularity_cachedir\u003c/code\u003e variable in \u003ccode\u003enextflow.config\u003c/code\u003e.\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-arguments\" class=\"anchor\" href=\"#arguments\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eArguments\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003eoperation   :   align or call_variants\nmode        :   WGS or WES\ninput       :   tab-separated file describing input files. \n                The exact format depends on operation requested (see below)\nped         :   standard PED file containing all samples\ncohort_id   :   a arbitrary name for the cohort files generated\noutdir      :   output folder for results\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-input-files-format\" class=\"anchor\" href=\"#input-files-format\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInput files format\u003c/h2\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-ped-file\" class=\"anchor\" href=\"#ped-file\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePED file\u003c/h3\u003e\n\u003cp\u003eA standard tab-separated PED file without header, describing all samples provided in the input file. All sample IDs must match between ped and input file. All samples must have sex defined.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efamily_ID   individual_ID   father_ID   mother_ID   sex(1=M,2=F)    status(1=unaff,2=aff,0=unknown)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-input-file\" class=\"anchor\" href=\"#input-file\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003einput file\u003c/h3\u003e\n\u003cp\u003eNote that all files need to be specified using \u003cstrong\u003eabsolute paths\u003c/strong\u003e\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-operation-align\" class=\"anchor\" href=\"#operation-align\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eOperation: align\u003c/h4\u003e\n\u003cp\u003eA 3 columns tab-separated file without header\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esampleID1   s1_lane1_R1.fastq.gz    s1_lane1_R2.fastq.gz\nsampleID1   s1_lane2_R1.fastq.gz    s1_lane2_R2.fastq.gz\nsampleID2   s2_lane2_R1.fastq.gz    s2_lane2_R2.fastq.gz\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNote that if a sample has been sequenced with multiple pairs of fastq files you need to add multiple lines for each pair of fastq files using the same sampleID. The pipeline will take care of the merge.\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-operation-call_variants\" class=\"anchor\" href=\"#operation-call_variants\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eOperation: call_variants\u003c/h4\u003e\n\u003cp\u003eA 5 columns tab-separated file without header.\nThis file is automatically generated when using \u003ccode\u003e--operation align\u003c/code\u003e (bam_files.txt)\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esampleID1   main_bam.bam    disc.bam    split.bam\nsampleID2   main_bam.bam    disc.bam    split.bam\nsampleID3   main_bam.bam    disc.bam    split.bam\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-pipeline-components\" class=\"anchor\" href=\"#pipeline-components\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePipeline components\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eAlignement and duplicate marking\n\u003cul\u003e\n\u003cli\u003eBWA + samblaster + samtools\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eQC and coverage from BAM files\n\u003cul\u003e\n\u003cli\u003efastqc: reads stats\u003c/li\u003e\n\u003cli\u003emosdepth: coverage\u003c/li\u003e\n\u003cli\u003esamtools flagstat / mapstat: alignment stats\u003c/li\u003e\n\u003cli\u003esomalier: ancestry, relatedness, sex check reports\u003c/li\u003e\n\u003cli\u003emultiqc: interactive report\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003esmall variants\n\u003cul\u003e\n\u003cli\u003edeepvariant: single sample calls\u003c/li\u003e\n\u003cli\u003eglnexus: gvcf merge\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003estructural variants\n\u003cul\u003e\n\u003cli\u003elumpy: structural variants events\u003c/li\u003e\n\u003cli\u003eCNVnator: CNV estimation\u003c/li\u003e\n\u003cli\u003esvtools: combine, merge and classify\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003erepeat expansion detection\n\u003cul\u003e\n\u003cli\u003eexpansion hunter\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eROH regions\n\u003cul\u003e\n\u003cli\u003ebcftools ROH\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1622127855.0
  },
  {
    "data_format": 2,
    "description": "A small example repository that contains examples for controlling the real Panda robot.",
    "filenames": [
      "real_panda_moveit_control/containers/singularity/Singularity.ros_noetic-focal"
    ],
    "full_name": "rickstaa/real-panda-control-examples",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-real-panda-control-examples\" class=\"anchor\" href=\"#real-panda-control-examples\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eReal panda control examples\u003c/h1\u003e\n\u003cp\u003eThis repository contains several examples for controlling the real panda robot. It was created as a supliment to the official \u003ca href=\"https://frankaemika.github.io/docs/installation_linux.html\" rel=\"nofollow\"\u003epanda documentation\u003c/a\u003e. Further it serves as a storage place for several problems I encountered while working with the panda robot (see the \u003ca href=\"https://github.com/rickstaa/real-panda-control-examples/discussions\"\u003ediscussions section\u003c/a\u003e).\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-clone-instructions\" class=\"anchor\" href=\"#clone-instructions\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eClone instructions\u003c/h2\u003e\n\u003cp\u003eTo clone the respository use the following command:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003emkdir real_catkin_ws\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e real_catkin_ws\ngit clone --recurse-submodules https://github.com/rickstaa/real_panda_moveit_control.git src\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-build-instructions\" class=\"anchor\" href=\"#build-instructions\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuild instructions\u003c/h2\u003e\n\u003cp\u003eInstall the ROS package dependencies using the following command:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003erosdep install --from-paths src --ignore-src --rosdistro melodic -y\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe catkin package can be build by executing one of the following commands:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ecatkin build -j4 -DCMAKE_BUILD_TYPE=Release -DFranka_DIR:PATH=\u003cspan class=\"pl-k\"\u003e~\u003c/span\u003e/libfranka/build\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-franka-ros-examples\" class=\"anchor\" href=\"#franka-ros-examples\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFranka ros examples\u003c/h2\u003e\n\u003cp\u003ePlease see \u003ca href=\"https://github.com/rickstaa/real-panda-control-examples/discussions/4\"\u003ethis discussion post\u003c/a\u003e that explains how to run the example launch files provided by Emika Franka.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-moveit-example-launch-instructions\" class=\"anchor\" href=\"#moveit-example-launch-instructions\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMoveit example launch instructions\u003c/h2\u003e\n\u003cp\u003eTo test out Moveit control, after you build and sourced the catkin workspace, you can launch the example included in the \u003ccode\u003epanda_moveit_config\u003c/code\u003e using the following command:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eroslaunch panda_moveit_config panda_control_moveit_rviz.launch load_gripper:=true robot_ip:=172.16.0.2\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAdditionally the \u003ccode\u003ereal_panda_moveit_control\u003c/code\u003e contains a slightly modified version of this example:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eroslaunch real_panda_moveit_control real_panda_moveit_control.launch\u003c/pre\u003e\u003c/div\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [
      "franka-emika",
      "control",
      "moveit"
    ],
    "updated_at": 1622116155.0
  },
  {
    "data_format": 2,
    "description": "A definition file for building TAMA singularity container",
    "filenames": [
      "Singularity"
    ],
    "full_name": "sguizard/TAMA-singularity",
    "latest_release": "v1.0",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-tama-singularity\" class=\"anchor\" href=\"#tama-singularity\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTAMA-singularity\u003c/h1\u003e\n\u003cp\u003eA definition file for building TAMA singularity container\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-building-container\" class=\"anchor\" href=\"#building-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding container\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003esudo singularity build TAMA.{sif, def}\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-using-tama\" class=\"anchor\" href=\"#using-tama\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsing TAMA\u003c/h2\u003e\n\u003cp\u003eThere are two main Python scripts in TAMA:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003etama_collapse.py\u003c/li\u003e\n\u003cli\u003etama_merge.py\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThey can be run as follows:\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-tama_collapsepy\" class=\"anchor\" href=\"#tama_collapsepy\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"https://github.com/GenomeRIK/tama/wiki/Tama-Collapse\"\u003etama_collapse.py\u003c/a\u003e\n\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003esingularity exec TAMA.sif tama_collapse.py -h\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-tama_mergepy\" class=\"anchor\" href=\"#tama_mergepy\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"https://github.com/GenomeRIK/tama/wiki/Tama-Merge\"\u003etama_merge.py\u003c/a\u003e\n\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003esingularity exec TAMA.sif tama_merge.py -h\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1622110219.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "Singularity"
    ],
    "full_name": "deepakagg123/singularity_test",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularity_test\" class=\"anchor\" href=\"#singularity_test\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003esingularity_test\u003c/h1\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1622100688.0
  },
  {
    "data_format": 2,
    "description": "The Bachelor project of group .... at Aalborg University ",
    "filenames": [
      "Singularity"
    ],
    "full_name": "AdrianPlesner/Probabalistic-Multivariate-Timeseries-Forecasting",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-p6-bachelor-project\" class=\"anchor\" href=\"#p6-bachelor-project\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eP6-Bachelor-Project\u003c/h1\u003e\n\u003cp\u003eThe Bachelor project of group SW617F21 at Aalborg University.\u003c/p\u003e\n\u003cp\u003eThis project implemnts the Gaussian Process, DeepFactor, DeepAR using \u003ca href=\"https://github.com/awslabs/gluon-ts\"\u003ehttps://github.com/awslabs/gluon-ts\u003c/a\u003e and Conditioned Normalizong Flows models using \u003ca href=\"https://github.com/zalandoresearch/pytorch-ts\"\u003ehttps://github.com/zalandoresearch/pytorch-ts\u003c/a\u003e. We also implement our own model LSTM-SCH.\u003c/p\u003e\n\u003cp\u003eThis guide provides a working example of how to reproduce our results.\u003c/p\u003e\n\u003cp\u003eWe use the data sets PEMS-BAY and METR-LA available as zip archives in /data. Unpack these to pems-bay.h5 and metr-la.h5.\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-baselines\" class=\"anchor\" href=\"#baselines\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBaselines\u003c/h1\u003e\n\u003cp\u003eGP, DeepAR, DeepFactor and CNFlows make use of metadata json files to control hyper parameters, serialization and data location. Examples of these are made for the default implementations of each model and the optimal combination of hyper parameters for each model according to our experiments. They are located in the /resuts directory. Here are also serialized instances of the resulting models.\u003c/p\u003e\n\u003cp\u003eTo train one of these models, make sure that the corresponding metadata file has \u003ccode\u003e\"train\": true \u003c/code\u003e and the correct path to the location of the data file.\u003c/p\u003e\n\u003cp\u003eRun src/main.py with the path to the metadata file as program argument or provide the path when prompted. When it is done, the predictor object will be serialized to the path provided by the \"serilaize_path\" in the metadata, and the program will evaluate the predictor on the validation set.\u003c/p\u003e\n\u003cp\u003eIf the metadata has the key \"params\" containing a list of hyper parameters, as well as \"start\", \"end\" and \"step\" containing lists of values for the corresponding parameters, the program will train a model for each combination of the parameters given and write the best combination back to the metadata file.\u003c/p\u003e\n\u003cp\u003eTo use an serilazed model make sure that the metadata file has \u003ccode\u003e\"train\": false \u003c/code\u003e and serialize path to the directory that contains the serialization files.\u003c/p\u003e\n\u003cp\u003eTo evaluate a model on the test set, run src/validate.py with the path to the metadata file as program argument, or provide the path when prompted. Make sure that the metadata file has the right path the the data file and the right path to the serilaization directory containing the serialization files.\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-lst-sch\" class=\"anchor\" href=\"#lst-sch\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLST-SCH\u003c/h1\u003e\n\u003cp\u003eThe LST-SCH generates a xlsx file containing the MSE and CRPS result for all the sensors within a batch run. Do note, that this file is overwritten each time the code is runned. The first column contain the CRPS results and the second the MSE results. Note that the xlsx file is 1 index, and not zero, which gives a offset in the indexing compared to the python code.\u003c/p\u003e\n\u003cp\u003eTraining and testing are done sequentially, changes need to be made to the code, if the trained model needs to be saved.\u003c/p\u003e\n\u003cp\u003eRun src/LSTM-SCH/main.py to run a batch.\u003c/p\u003e\n\u003cp\u003eUse the src/LSTM-SCH/conf.py file to configure a run.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efilepath: is used to specify the data set to use\u003c/li\u003e\n\u003cli\u003estart_sensor \u0026amp; end_sensor: is used to specify the range of sensor to run in the batch\u003c/li\u003e\n\u003cli\u003emax_threads: the maximum number of threads to run simulatenly\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1622020298.0
  },
  {
    "data_format": 2,
    "description": "A powerful toolset for genome arithmetic",
    "filenames": [
      "Singularity"
    ],
    "full_name": "icaoberg/singularity-bedtools",
    "latest_release": "v2.29.2",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularity-bedtools\" class=\"anchor\" href=\"#singularity-bedtools\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003esingularity-bedtools\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://cloud.sylabs.io/library/icaoberg/default/bedtools\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2747e70595bc577024d908f158c1c8b1d458085960e3bdd70770858769cdf396/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f686f737465642d73796c6162732e696f2d677265656e2e737667\" alt=\"Hosted\" data-canonical-src=\"https://img.shields.io/badge/hosted-sylabs.io-green.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://camo.githubusercontent.com/8025f5254ec80610d1aa2daad722b5f63139d443fc969f0e566b87230d2519c5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d76322e32392e322d677265656e2e737667\" target=\"_blank\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8025f5254ec80610d1aa2daad722b5f63139d443fc969f0e566b87230d2519c5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d76322e32392e322d677265656e2e737667\" alt=\"Release\" data-canonical-src=\"https://img.shields.io/badge/release-v2.29.2-green.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://travis-ci.org/icaoberg/singularity-bedtools\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4bd5a5797e0eea5576a22f0d6438bb219e7e9d1165583a395f84114bcdf8d56e/68747470733a2f2f7472617669732d63692e6f72672f6963616f626572672f73696e67756c61726974792d626564746f6f6c732e7376673f6272616e63683d6d6173746572\" alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/icaoberg/singularity-bedtools.svg?branch=master\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/icaoberg/singularity-bedtools/issues\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8daa37ea52a8b910d7804b0dea5e36dc1ea51550f4d4d7e83fa044b7785964a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f6963616f626572672f73696e67756c61726974792d626564746f6f6c732e737667\" alt=\"GitHub issues\" data-canonical-src=\"https://img.shields.io/github/issues/icaoberg/singularity-bedtools.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/icaoberg/singularity-bedtools/network\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ea5237be05f56a481118a0905c976d88658d70a95b16af6c060101aea4e73a98/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f6963616f626572672f73696e67756c61726974792d626564746f6f6c732e737667\" alt=\"GitHub forks\" data-canonical-src=\"https://img.shields.io/github/forks/icaoberg/singularity-bedtools.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/icaoberg/singularity-bedtools/stargazers\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/192b2d7fbd67aa10f3c8f5535205f7be9d07653cb29eb16d34176d9dc6b541a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6963616f626572672f73696e67756c61726974792d626564746f6f6c732e737667\" alt=\"GitHub stars\" data-canonical-src=\"https://img.shields.io/github/stars/icaoberg/singularity-bedtools.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.gnu.org/licenses/quick-guide-gplv3.en.html\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0b6758422f85bc2599288b346c7de30c6b7b217112c0a877ae4b25a7009722e4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d47504c76332d626c75652e737667\" alt=\"GitHub license\" data-canonical-src=\"https://img.shields.io/badge/license-GPLv3-blue.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"images/logo.png\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"images/logo.png\" alt=\"Logo\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eCollectively, the \u003ca href=\"https://bedtools.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003ebedtools\u003c/a\u003e utilities are a swiss-army knife of tools for a wide-range of genomics analysis tasks. The most widely-used tools enable genome arithmetic: that is, set theory on the genome. For example, bedtools allows one to intersect, merge, count, complement, and shuffle genomic intervals from multiple files in widely-used genomic file formats such as BAM, BED, GFF/GTF, VCF. While each individual tool is designed to do a relatively simple task (e.g., intersect two interval files), quite sophisticated analyses can be conducted by combining multiple bedtools operations on the UNIX command line.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-pre-requisites\" class=\"anchor\" href=\"#pre-requisites\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePre-requisites\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://sylabs.io/docs/\" rel=\"nofollow\"\u003eSingularity v3.5.+\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-building-the-image-using-the-recipe\" class=\"anchor\" href=\"#building-the-image-using-the-recipe\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding the image using the recipe\u003c/h2\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-to-build-the-image-locally\" class=\"anchor\" href=\"#to-build-the-image-locally\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTo build the image locally\u003c/h3\u003e\n\u003cp\u003eRun the script \u003ccode\u003ebuild.sh\u003c/code\u003e to build image locally.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebash ./build.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-to-build-the-image-remotely-remotely\" class=\"anchor\" href=\"#to-build-the-image-remotely-remotely\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTo build the image remotely remotely\u003c/h3\u003e\n\u003cp\u003eRun the script \u003ccode\u003erbuild.sh\u003c/code\u003e to build image remotely.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebash ./rbuild.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou will need to edit the script above to match your account on \u003ca href=\"https://sylabs.io/\" rel=\"nofollow\"\u003eSyLabs.io\u003c/a\u003e.\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-pulling-from-the-repository\" class=\"anchor\" href=\"#pulling-from-the-repository\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePulling from the repository\u003c/h3\u003e\n\u003cp\u003eIf you have the client installed and cannot build the image locally nor remotely, simply run\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esingularity pull --arch amd64 library://icaoberg/default/bedtools:v2.29.2\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-disclaimer\" class=\"anchor\" href=\"#disclaimer\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDisclaimer\u003c/h2\u003e\n\u003cp\u003eI am nothing but a humble programmer creating the container for this wonderful app. \u003ca href=\"https://bedtools.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003ebedtools\u003c/a\u003e is developed in the \u003ca href=\"http://quinlanlab.org/\" rel=\"nofollow\"\u003eQuinlan laboratory\u003c/a\u003e at the \u003ca href=\"https://www.utah.edu/\" rel=\"nofollow\"\u003eUniversity of Utah\u003c/a\u003e and benefits from fantastic contributions made by scientists worldwide.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003ca href=\"http://www.cbd.cmu.edu\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/47fafd631a30ef553735a724705fea74cb02d1bb0b9eab22c64aca8c41885f3d/687474703a2f2f7777772e6362642e636d752e6564752f77702d636f6e74656e742f75706c6f6164732f323031372f30372f776f726470726573732d64656661756c742e706e67\" alt=\"CBD\" data-canonical-src=\"http://www.cbd.cmu.edu/wp-content/uploads/2017/07/wordpress-default.png\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eCopyleft \u00a9 2019-2020 \u003ca href=\"http://www.andrew.cmu.edu/~icaoberg\" rel=\"nofollow\"\u003eicaoberg\u003c/a\u003e at the \u003ca href=\"http://www.cbd.cmu.edu\" rel=\"nofollow\"\u003eComputational Biology Department\u003c/a\u003e in \u003ca href=\"http://www.cmu.edu\" rel=\"nofollow\"\u003eCarnegie Mellon University\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [
      "singularity",
      "singularity-container",
      "bedtools"
    ],
    "updated_at": 1584374962.0
  },
  {
    "data_format": 2,
    "description": "Singularity recipe for vim",
    "filenames": [
      "Singularity"
    ],
    "full_name": "icaoberg/singularity-vim",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularity-vim\" class=\"anchor\" href=\"#singularity-vim\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003esingularity-vim\u003c/h1\u003e\n\u003cp\u003eVim is a clone, with additions, of Bill Joy\u0027s vi text editor program for Unix.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003ca href=\"http://www.psc.edu\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ee7cb50ef5a31fe25a8e149b0a09b50a8523d5e11a27311af8e63f22a8c915b2/687474703a2f2f7777772e616e647265772e636d752e6564752f757365722f6963616f626572672f696d616765732f6c6f676f732f7073632e706e67\" alt=\"PSC\" data-canonical-src=\"http://www.andrew.cmu.edu/user/icaoberg/images/logos/psc.png\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eicaoberg at the \u003ca href=\"http://www.psc.edu\" rel=\"nofollow\"\u003ePittsburgh Supercomputing Center\u003c/a\u003e in the \u003ca href=\"https://www.cmu.edu/mcs/\" rel=\"nofollow\"\u003eMellon College of Science\u003c/a\u003e at \u003ca href=\"http://www.cmu.edu\" rel=\"nofollow\"\u003eCarnegie Mellon University\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1621975845.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "Singularity"
    ],
    "full_name": "MontrealSergiy/deformation",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-deformation-field\" class=\"anchor\" href=\"#deformation-field\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDeformation field\u003c/h1\u003e\n\u003cp\u003eThis PERL script is a wrapper that is calling sequence of commands for generating deformation fields scrips\n\u003ca href=\"https://wiki.mouseimaging.ca/display/MICePub/Generating+deformation+fields\" rel=\"nofollow\"\u003ehttps://wiki.mouseimaging.ca/display/MICePub/Generating+deformation+fields\u003c/a\u003e\nSource code for deformation pipeline and dependencies (MINC):\n\u003ca href=\"https://github.com/Mouse-Imaging-Centre/generate_deformation_fields\"\u003ehttps://github.com/Mouse-Imaging-Centre/generate_deformation_fields\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eUsage\u003c/p\u003e\n\u003cp\u003e./deformation.pl -input ICBM_00100_t1_final.mnc \u0026lt;\u0026lt;this could be any anatomical minc file, for a collection of minc files\u0026gt;\u0026gt; -output dummy_hoho -deformation_ratio 0.6 -coordinate 70 100 70 10 10 10 -tolerance_space 4 \u0026lt;\u0026gt; -blur_determinant 0.25 \u0026lt;\u0026gt; -error 0.00001 \u0026lt;\u0026gt; -iteration 100\u003c/p\u003e\n\u003cp\u003eThe output of running this command looks like this:\nICBM_00100_t1_final_deformed_by_0.4atROIx70-y100-z70dimx10.dimy10.dimz10.mnc. \u003c/p\u003e\n\u003cp\u003eWe will also have a directory dummy_hoho/TMP that will contain the in-between-files.\u003c/p\u003e\n\u003cp\u003e$:/dummy_hoho/TMP$ ls\u003c/p\u003e\n\u003cp\u003eblock.mnc\u003c/p\u003e\n\u003cp\u003eblurred0.25determinant_r_0.4x70-y100-z70dimx10.dimy10.dimz10.mnc\u003c/p\u003e\n\u003cp\u003eDDDDdilated.mnc\u003c/p\u003e\n\u003cp\u003eDDDDring.mnc\u003c/p\u003e\n\u003cp\u003edeterminant_r_0.4_grid.mnc\u003c/p\u003e\n\u003cp\u003edeterminant_r_0.4x70-y100-z70dimx10.dimy10.dimz10.mnc\u003c/p\u003e\n\u003cp\u003edeterminant_r_0.4.xfm\u003c/p\u003e\n\u003cp\u003emask.mnc\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1621950177.0
  },
  {
    "data_format": 2,
    "description": "Singularity recipe files for dvc (https://github.com/iterative/dvc)",
    "filenames": [
      "Singularity.2.1.0",
      "Singularity",
      "Singularity.1.6.1"
    ],
    "full_name": "powerPlant/dvc-srf",
    "latest_release": null,
    "readme": "\u003cp\u003eSingularity recipe files for the DVC tool for Data Version Control\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 0,
    "topics": [],
    "updated_at": 1621917326.0
  },
  {
    "data_format": 2,
    "description": "Bayesian Inference and Optimisation for the Monash Electrochemical Simulator",
    "filenames": [
      "Singularity.def"
    ],
    "full_name": "lukegun/BIOMEC",
    "latest_release": null,
    "readme": "\u003cp\u003e\u003ca href=\"https://singularity-hub.org/collections/4983\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a07b23d4880320ac89cdc93bbbb603fa84c215d135e05dd227ba8633a9ff34be/68747470733a2f2f7777772e73696e67756c61726974792d6875622e6f72672f7374617469632f696d672f686f737465642d73696e67756c61726974792d2d6875622d2532336533323932392e737667\" alt=\"https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg\" data-canonical-src=\"https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-biomec\" class=\"anchor\" href=\"#biomec\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBIOMEC\u003c/h1\u003e\n\u003cp\u003eBayesian Inference and Optimisation for the Monash electrochemical Simulator (MECSim) is the application developed by the\nmonash electrochemistry group with the assistance of Assosiate Professor Jie Zhang, Emeratious Professor Alan Bond and technical assistance from Gareth Kennedy And Martin Robinson.\u003c/p\u003e\n\u003cp\u003eIt is an automatic plaform for parameterisation that uses mathmatical optimisation and Bayesian Inference to calculate parameters involved in the electrochemical simulation.\nBuilt around \u003ca href=\"http://www.garethkennedy.net/MECSim.html\" rel=\"nofollow\"\u003eMECSim\u003c/a\u003e and first applied in the PAPER. BIOMEC allows for automated parameterisation of DC and FTAC voltammetery, allowing highly dimensional fits of the posteriour distrabution.\u003c/p\u003e\n\u003cp\u003eBIOMEC uses \u003ca href=\"https://github.com/pints-team/pints\"\u003ePINTS\u003c/a\u003e for univariant Bayesian inference.\u003c/p\u003e\n\u003cp\u003eFor information of current uses see the original \u003ca href=\"https://chemistry-europe.onlinelibrary.wiley.com/doi/abs/10.1002/celc.202100391\" rel=\"nofollow\"\u003eBIOMEC paper\u003c/a\u003e, the \u003ca href=\"https://doi.org/10.1002/celc.201700678\" rel=\"nofollow\"\u003eoriginal Bayesian inference paper\u003c/a\u003e for AC voltammetry or our most recent \u003ca href=\"https://doi.org/10.1039/D0CC07549C\" rel=\"nofollow\"\u003efeatured article\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-installing-biomec-image\" class=\"anchor\" href=\"#installing-biomec-image\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstalling BIOMEC image\u003c/h2\u003e\n\u003cp\u003eThe code is run in a singularity container which works for Ubuntu/UNIX and MAC (untested) OS systems.\nSingularity will need to be installed to use the image. Where the guide is seen in the following \u003ca href=\"https://sylabs.io/guides/3.6/user-guide/quick_start.html\" rel=\"nofollow\"\u003ewebsite\u003c/a\u003e or downloaded from connected singularity hub.\u003c/p\u003e\n\u003cp\u003eOnce singularity has been installed, download the BIOMEC file and run the code to create the BIOMEC container (which should be around 580MB).\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ sudo singularity build BIOMEC.simg Singularity.def\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce the image is built the imput file (input.txt) can be passed to the image by using the following command.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ ./BIOMEC.simg input.txt\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis will generate and ouput file with plots and results once completed.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-generating-input-files\" class=\"anchor\" href=\"#generating-input-files\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGenerating input files\u003c/h2\u003e\n\u003cp\u003einputwritter.py can guide users unfamilaur with generating input files to create an input file for the BIOMEC container, this program is contained in the BIOMEC_inputwritter.\nSimply run the file using the following command and follow the prompts and an input file will be generated.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ python3 inputwritter.py\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe output of this file will then be of the form \u0026lt;input.txt\u0026gt; though other names will work.\nIt is important that a copy of the MECSim Master.inp file is present in the folder you run inputwritter.py as the MECSim input file is required for BIOMEC to run.\u003c/p\u003e\n\u003cp\u003eOnce comfortable with writting the input file it is recommended to use any text editor.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-running-biomec\" class=\"anchor\" href=\"#running-biomec\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning BIOMEC\u003c/h2\u003e\n\u003cp\u003ePDF tutorial or youtube videos to come.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-supporting-code\" class=\"anchor\" href=\"#supporting-code\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSupporting Code\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eBIOMEC_inputwritter: Basic terminal/ .exe code for guiding uses in writting the input files for BIOMEC\u003c/li\u003e\n\u003cli\u003eMCMC PLOTTER: code to plot the mcmc output chains from the Iter_log.txt to images\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-known-issues\" class=\"anchor\" href=\"#known-issues\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eKnown Issues\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eCustom waveforms have not been tested and Estart and End cannot equal zero.\u003c/li\u003e\n\u003cli\u003eNumber of data poins in experimental data must be a multiple of two.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-citing\" class=\"anchor\" href=\"#citing\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCiting\u003c/h2\u003e\n\u003cp\u003ePlease, cite the original \u003ca href=\"https://chemistry-europe.onlinelibrary.wiley.com/doi/abs/10.1002/celc.202100391\" rel=\"nofollow\"\u003eBIOMEC paper\u003c/a\u003e if you have used this package in a publication.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLicense\u003c/h2\u003e\n\u003cp\u003eBIOMEC analysis/python code is open source under the GPL-3.0 License, with MECSim developed by Gareth Kennedy and contaned in the mecsim.cpython-37m-x86_64-linux-gnu.so shared object is under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-get-in-touch\" class=\"anchor\" href=\"#get-in-touch\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGet in touch\u003c/h2\u003e\n\u003cp\u003eFor Questions/Bugs Email me at \u003ca href=\"mailto:luke.gundry1@monash.edu\"\u003eluke.gundry1@monash.edu\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 3,
    "topics": [
      "baysian-inference",
      "optimization",
      "voltammetry",
      "electrochemistry"
    ],
    "updated_at": 1622080196.0
  },
  {
    "data_format": 2,
    "description": "Custom implementation of neurodocker (https://github.com/ReproNim/neurodocker)",
    "filenames": [
      "Singularity"
    ],
    "full_name": "achennings/neurodocker",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-neurodocker\" class=\"anchor\" href=\"#neurodocker\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eneurodocker\u003c/h1\u003e\n\u003cp\u003eCustom implementation of neurodocker (\u003ca href=\"https://github.com/ReproNim/neurodocker\"\u003ehttps://github.com/ReproNim/neurodocker\u003c/a\u003e)\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1622577015.0
  },
  {
    "data_format": 2,
    "description": "Applied nuclear physics relevant software, containerized.",
    "filenames": [
      "Singularity"
    ],
    "full_name": "peter-jansson/appnuc",
    "latest_release": "v0.2.0.0",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-appnuc\" class=\"anchor\" href=\"#appnuc\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eappnuc\u003c/h1\u003e\n\u003cp\u003eApplied nuclear physics relevant software.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://camo.githubusercontent.com/f400597fcdcb66eeb5702e037732d66d7eecdf94f4f363a2dde0da21c4ba9ec4/68747470733a2f2f7777772e676e752e6f72672f67726170686963732f6c67706c76332d776974682d746578742d3135347836382e706e67\" target=\"_blank\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f400597fcdcb66eeb5702e037732d66d7eecdf94f4f363a2dde0da21c4ba9ec4/68747470733a2f2f7777772e676e752e6f72672f67726170686963732f6c67706c76332d776974682d746578742d3135347836382e706e67\" alt=\"LGPL-3\" data-canonical-src=\"https://www.gnu.org/graphics/lgplv3-with-text-154x68.png\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eAn Ubuntu based image/container with a bunch of standard programs that are useful for scientific work in the field of applied nuclear physics. In addition, the following list of relevant software is installed.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://geant4.web.cern.ch/\" rel=\"nofollow\"\u003eGeant4\u003c/a\u003e monte carlo framework\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://root.cern.ch/\" rel=\"nofollow\"\u003eRoot\u003c/a\u003e data analysis framework\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://dx.doi.org/10.18434/T48G6X\" rel=\"nofollow\"\u003eXCOM\u003c/a\u003e program from NIST\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-docker\" class=\"anchor\" href=\"#docker\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDocker\u003c/h2\u003e\n\u003cp\u003eDocker hub contains the \u003ca href=\"https://hub.docker.com/r/jansson/appnuc\" rel=\"nofollow\"\u003eimage\u003c/a\u003e built using the Dockerfile, which can pulled into the local Docker registry by the command \u003ccode\u003edocker pull jansson/appnuc\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eThe image can be started in a container by, e.g., the command \u003ccode\u003edocker run --rm -it jansson/appnuc bash -l\u003c/code\u003e. Significantly more information on how to mount a local file system to the container as well as other command line options is available in the \u003ca href=\"https://docs.docker.com/engine/reference/commandline/cli/\" rel=\"nofollow\"\u003eDocker documentation\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-singularity\" class=\"anchor\" href=\"#singularity\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSingularity\u003c/h2\u003e\n\u003cp\u003eA \u003ca href=\"https://sylabs.io/\" rel=\"nofollow\"\u003eSingularity\u003c/a\u003e file containing the same containerized Ubuntu and software can be built using the Singularity definition file, named \u003ccode\u003eSingularity\u003c/code\u003e. E.g. using the command \u003ccode\u003esudo singularity build appnuc.sif Singularity\u003c/code\u003e to build \u003ccode\u003eappnuc.sif\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eSee the \u003ca href=\"https://sylabs.io/guides/3.7/user-guide/\" rel=\"nofollow\"\u003eSingularity user guide\u003c/a\u003e for more information.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [
      "applied-nuclear-physics",
      "dockerfile",
      "singularity"
    ],
    "updated_at": 1621832060.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "Singularity"
    ],
    "full_name": "baxpr/bedpost-singularity",
    "latest_release": null,
    "readme": "\u003cp\u003eRuns FSL\u0027s bedpostx on the input DWI data set, and creates a PDF report of the results.\nQuite simple - see /opt/src/pipeline.sh for the main script.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1621804490.0
  },
  {
    "data_format": 2,
    "description": "Def File of Singularity",
    "filenames": [
      "def/lafin.def",
      "def/wav2pix.def",
      "def/contextual-attention.def",
      "def/singan.def",
      "def/stargan.def",
      "def/edge-connect.def",
      "def/vae-mnist.def",
      "def/sc-fegan.def"
    ],
    "full_name": "Nahuel-Mk2/def-space",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-def-space\" class=\"anchor\" href=\"#def-space\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003edef-space\u003c/h1\u003e\n\u003cp\u003eThis repository is def-space for Singularity\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1606189900.0
  },
  {
    "data_format": 2,
    "description": "My Singularity recipe files",
    "filenames": [
      "bat/Singularity.def",
      "asciinema/Singularity.def",
      "arch-base/Singularity.def",
      "centos-base/Singularity.def",
      "lilypond/Singularity.def",
      "gerda-tgsend/Singularity.def",
      "root-cern/Singularity.def",
      "julia/Singularity.def",
      "itunes/Singularity.def",
      "texlive/Singularity.def"
    ],
    "full_name": "gipert/Singularity.def",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularity-recipe-files\" class=\"anchor\" href=\"#singularity-recipe-files\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSingularity recipe files\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/sylabs/singularity\"\u003eSingularity\u003c/a\u003e containers I use the most on HPC clusters.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [
      "singularity",
      "containers"
    ],
    "updated_at": 1587858477.0
  },
  {
    "data_format": 2,
    "description": "Singularity definition files for various projects",
    "filenames": [
      "hauntedhouse_freesurfer/Singularity",
      "hauntedhouse/Singularity",
      "miniconda/Singularity"
    ],
    "full_name": "mvdoc/singularity-def",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularity-recipe-files\" class=\"anchor\" href=\"#singularity-recipe-files\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSingularity recipe files\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/sylabs/singularity\"\u003eSingularity\u003c/a\u003e containers I use the most on HPC clusters.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1495630055.0
  },
  {
    "data_format": 2,
    "description": "singularity def file for flair(fluka)",
    "filenames": [
      "flair.def",
      "flair-cern.def"
    ],
    "full_name": "ifurther/flair-def",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularity-recipe-files\" class=\"anchor\" href=\"#singularity-recipe-files\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSingularity recipe files\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/sylabs/singularity\"\u003eSingularity\u003c/a\u003e containers I use the most on HPC clusters.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1619686613.0
  },
  {
    "data_format": 2,
    "description": "Singularity definition files for building various software to run on HPC systems",
    "filenames": [
      "checkm.def",
      "instrain.def",
      "octopus.def",
      "torstyverse.def"
    ],
    "full_name": "slhogle/singularity_def_files",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularity-definition-files\" class=\"anchor\" href=\"#singularity-definition-files\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSingularity definition files\u003c/h1\u003e\n\u003cp\u003eCollection of def files for building some bioinformatics software I commonly use.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-instrain-v1214\" class=\"anchor\" href=\"#instrain-v1214\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003einStrain v1.2.14\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/MrOlm/inStrain\"\u003ehttps://github.com/MrOlm/inStrain\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eAlso contains these functioning binaries:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/samtools/samtools\"\u003esamtools v1.10\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/hyattpd/Prodigal\"\u003eprodigal v2.6.3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/lh3/bwa\"\u003ebwa v0.7.17-r1198-dirty\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/lh3/minimap2\"\u003eminimap2 v2.17 (r941)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/dnbaker/dashing\"\u003eDashing v0.4.8-1-g47e6\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/ParBLiSS/FastANI\"\u003eFastANI v1.3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/wwood/CoverM\"\u003eCoverM v0.4.0\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca href=\"https://cloud.sylabs.io/library/slhogle/base/instrain\" rel=\"nofollow\"\u003eImage at Sylabs\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eDownload with:\u003cbr\u003e\n\u003ccode\u003esingularity pull library://slhogle/base/instrain\u003c/code\u003e\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-octopus-development-branch-version-v070-develop-2bde0433\" class=\"anchor\" href=\"#octopus-development-branch-version-v070-develop-2bde0433\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eOctopus development branch version v0.7.0 (develop 2bde0433)\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/luntergroup/octopus\"\u003ehttps://github.com/luntergroup/octopus\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eBuilt with:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003epatchelf v0.10\u003c/li\u003e\n\u003cli\u003eopenssl v1.1.1g\u003c/li\u003e\n\u003cli\u003epkg-config v0.29.2\u003c/li\u003e\n\u003cli\u003egpatch v2.7.6\u003c/li\u003e\n\u003cli\u003encurses v6.2\u003c/li\u003e\n\u003cli\u003ecmake v3.17.3\u003c/li\u003e\n\u003cli\u003ehtslib v1.10\u003c/li\u003e\n\u003cli\u003eboost v1.72.0\u003c/li\u003e\n\u003cli\u003eGNU C/C++ compiler v9.3.0\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTarget: x86_64 Linux 5.3.0-7642-generic\u003cbr\u003e\nSIMD extension: AVX2\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://cloud.sylabs.io/library/slhogle/base/octopus\" rel=\"nofollow\"\u003eImage at Sylabs\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eDownload with:\u003cbr\u003e\n\u003ccode\u003esingularity pull library://slhogle/base/octopus\u003c/code\u003e\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-torstyverse\" class=\"anchor\" href=\"#torstyverse\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTorstyverse\u003c/h2\u003e\n\u003cp\u003eBundle of useful packages from \u003ca href=\"https://github.com/tseemann\"\u003eTorsten Seeman\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/tseemann/samclip\"\u003esampclip v0.4.0\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/tseemann/any2fasta\"\u003eany2fasta v0.4.2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/tseemann/barrnap\"\u003ebarrnap v0.9\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/tseemann/prokka\"\u003eprokka v1.14.6\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/tseemann/shovill\"\u003eshovill v1.1.0\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/tseemann/abricate\"\u003eabricate v1.0.1\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/tseemann/snippy\"\u003esnippy v4.6.0\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca href=\"https://cloud.sylabs.io/library/slhogle/base/torstyverse\" rel=\"nofollow\"\u003eImage at Sylabs\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eDownload with:\u003cbr\u003e\n\u003ccode\u003esingularity pull library://slhogle/base/torstyverse\u003c/code\u003e\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1614942669.0
  },
  {
    "data_format": 2,
    "description": "Definition (recipe) files for singularity containers.",
    "filenames": [
      "diffnets/diffnets.def",
      "H5N1/Singularity.def",
      "H5N1/Singularity_R_3.6.def",
      "H5N1/h5n1day100.def",
      "cite-seq/Singularity_xenial.def",
      "cite-seq/Singularity_publish.def",
      "cite-seq/Singularity_rocker.def",
      "cite-seq/Singularity_3.def",
      "generic/Singularity.def",
      "bittersweet/Singularity.def",
      "cytof-workflow-v3/Singularity.def",
      "comet/Singularity.def",
      "comet/chemlab-comet.def",
      "cytof-deep-cnn/Singularity.def"
    ],
    "full_name": "rohitfarmer/singularity-defs",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-definitionrecipe-files-for-singularity-containers\" class=\"anchor\" href=\"#definitionrecipe-files-for-singularity-containers\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDefinition/Recipe Files for Singularity Containers\u003c/h1\u003e\n\u003cp\u003eSome of the containers are available to download from \u003ca href=\"https://cloud.sylabs.io/library/rohitfarmer\" rel=\"nofollow\"\u003ehttps://cloud.sylabs.io/library/rohitfarmer\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eFor feedback and collaboration write to me at \u003ca href=\"mailto:rohit.farmer@gmail.com\"\u003erohit.farmer@gmail.com\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-install-singularity-on-linux\" class=\"anchor\" href=\"#install-singularity-on-linux\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstall Singularity on Linux\u003c/h1\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-singularity-version-34\" class=\"anchor\" href=\"#singularity-version-34\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSingularity Version 3.4\u003c/h2\u003e\n\u003cp\u003eFollow the instructions on \u003ca href=\"https://sylabs.io/guides/3.4/user-guide/quick_start.html#quick-installation-steps\" rel=\"nofollow\"\u003ehttps://sylabs.io/guides/3.4/user-guide/quick_start.html#quick-installation-steps\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-building-a-singularity-container\" class=\"anchor\" href=\"#building-a-singularity-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding a Singularity Container\u003c/h1\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-readonly-container\" class=\"anchor\" href=\"#readonly-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eReadonly Container\u003c/h2\u003e\n\u003cp\u003eTo build a read-only SquashFS Singularity container on a local machine using a recipe/definition file.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003esudo singularity build \u0026lt;container-name.sif\u0026gt; \u0026lt;Singularity.def\u0026gt;\u003c/code\u003e\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-writable-sandbox\" class=\"anchor\" href=\"#writable-sandbox\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWritable Sandbox\u003c/h2\u003e\n\u003cp\u003eTo build a writable sandbox (essentially a folder) on a local machine using a recipe/definition file.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003esudo singularity build --sandbox  \u0026lt;sandbox-folder-name/\u0026gt; \u0026lt;Singularity.def\u0026gt;\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eNote: The advantage of building a writable sandbox is that it can be used to install and configure packages as you go, and once you are satisfied with the requirements, the sandbox can be converted into a read-only SquashFS container. To build a sandbox quickly, it\u0027s better to install a minimal set of packages via the definition file.\u003c/em\u003e\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-installconfigure-packages-in-a-writable-sandbox\" class=\"anchor\" href=\"#installconfigure-packages-in-a-writable-sandbox\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstall/Configure Packages in a Writable Sandbox\u003c/h3\u003e\n\u003cp\u003eOnce a writable sandbox is created to execute it to invoke the shell of the operating installed in the container in the \"writable\" mode. If the shell is not invoked in the \"writable\" mode, all the changes will be lost once you exit from the container environment.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003esudo singularity shell --writable \u0026lt;sandbox-folder-name/\u0026gt;\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eInstall packages as you would, for example, in Ubuntu from the command line.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-convert-a-writable-sandbox-to-a-readonly-container\" class=\"anchor\" href=\"#convert-a-writable-sandbox-to-a-readonly-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eConvert a Writable Sandbox to a Readonly Container\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003esudo singularity build \u0026lt;container-name.sif\u0026gt; \u0026lt;sandbox-folder-name/\u0026gt;\u003c/code\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-execute-a-container\" class=\"anchor\" href=\"#execute-a-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eExecute a Container\u003c/h1\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-invoke-a-shell\" class=\"anchor\" href=\"#invoke-a-shell\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInvoke a shell\u003c/h2\u003e\n\u003cp\u003eThe command below can be used for both read-only/writable containers/sandbox.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003esingularity shell \u0026lt;container-name.sif\u0026gt;\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eNote: By default, Singularity binds to your current working and home directory. Therefore, you do not need to do anything else to execute a script that is in your current working directory. It can also pull, for example, Vim settings from the .vimrc file in your home directory. Therefore, if Vim installed in the container, it can be used with the same settings from inside the container as it would from outside.\u003c/em\u003e\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-execute-a-command-via-container\" class=\"anchor\" href=\"#execute-a-command-via-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eExecute a Command via Container\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003esingularity exec \u0026lt;container-name.sif\u0026gt; \u0026lt;command\u0026gt;\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eFor example: \u003ccode\u003esingularity exec \u0026lt;container-name.sif\u0026gt; Rscript --vanilla hello.R\u003c/code\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-running-jupyter-notebooks-from-within-a-container\" class=\"anchor\" href=\"#running-jupyter-notebooks-from-within-a-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning Jupyter Notebooks from Within a Container\u003c/h1\u003e\n\u003cp\u003eThis section is for containers that have Jupyter notebook installed (e.g. cite-seq).\u003c/p\u003e\n\u003cp\u003eA generic command that should work on a personal computer. \u003ccode\u003esingularity exec container-name.sif jupyter notebook --no-browser --ip=127.0.0.1 --port=8888\u003c/code\u003e\u003cbr\u003e\n\u003cem\u003eNote: The IP address and the port number mentioned in the command are the jupyter defaults. They can be changed as per need.\u003c/em\u003e\u003cbr\u003e\nCopy the URL generated by jupyter daemon and paste it in your browser; this should open Jupyter with the list of the files in your current working directory on the host computer.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-running-with-r-as-a-kernel\" class=\"anchor\" href=\"#running-with-r-as-a-kernel\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning with R as a Kernel\u003c/h2\u003e\n\u003cp\u003eSometimes if you already have an R kernel installed in your home directory, it conflicts with what you have inside the container. Therefore, it would require you to re-install the kernel specs in your home directory via the container.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esingularity exec container-name.sif R --quiet --slave -e \u0027IRkernel::installspec()\u0027\n\n# Screen log.\n# [InstallKernelSpec] Removing existing kernelspec in /home/user/.local/share/jupyter/kernels/ir\n# [InstallKernelSpec] Installed kernelspec ir in /home/user/.local/share/jupyter/kernels/ir\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-running-on-an-hpc\" class=\"anchor\" href=\"#running-on-an-hpc\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning on an HPC\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eSSH to the HPC.\u003c/li\u003e\n\u003cli\u003eClaim an interactive node.\u003c/li\u003e\n\u003cli\u003eNavigate to your project directory. Singularity container should be in your project directory.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esingularity exec container-name.sif jupyter notebook --no-browser --ip=\u00270.0.0.0\u0027\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eKeep the SSH session and Jupyter notebook session running. Copy the URL on your local browser.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cem\u003eNote: On some HPCs, you may have to initiate an additional SSH tunnel connecting your local machine to the interactive node on the HPC. In that case, follow some generic instructions here \u003ca href=\"https://rohitfarmer.github.io/docs/docs/HPC/jupyter/\" rel=\"nofollow\"\u003ehttps://rohitfarmer.github.io/docs/docs/HPC/jupyter/\u003c/a\u003e or ask your system administrator.\u003c/em\u003e\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 0,
    "topics": [],
    "updated_at": 1598393438.0
  },
  {
    "data_format": 2,
    "description": "definition files for containers used in Hanlab",
    "filenames": [
      "singularity.SAD/SAD.def",
      "singularity.R.3.6.3.phylo/R.3.6.3.phylo.def",
      "singularity.Rconda/R.3.6.3.def",
      "singularity.R.4.0.2.Bioc/R.4.0.2.Bioc.def",
      "singularity.mkl/mkl.def",
      "singularity.mkl/mkl.ubuntu.def",
      "singularity.py37.ml.openblas/py37.ml.openblas.def",
      "singularity.phylo/phylo.def",
      "singularity.py37.ml.mkl/py37.ml.mkl.def",
      "singularity.R.3.6.3.Bioc/R.3.6.3.Bioc.def",
      "singularity.rnaseq/rnaseq.def"
    ],
    "full_name": "HanLabUNLV/hanlab_singularity_defs",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-hpc_mpi_cuda_singu_def_file\" class=\"anchor\" href=\"#hpc_mpi_cuda_singu_def_file\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ehpc_mpi_cuda_singu_def_file\u003c/h1\u003e\n\u003cp\u003eA collect of definition files to build images for singularity containers, which includes hpc benchmarks and mpis with cuda support.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://singularity-hub.org/collections/4181\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a07b23d4880320ac89cdc93bbbb603fa84c215d135e05dd227ba8633a9ff34be/68747470733a2f2f7777772e73696e67756c61726974792d6875622e6f72672f7374617469632f696d672f686f737465642d73696e67756c61726974792d2d6875622d2532336533323932392e737667\" alt=\"https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg\" data-canonical-src=\"https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1617130184.0
  },
  {
    "data_format": 2,
    "description": "Evaluate the effectiveness of any short read mapper and its parameters using artificially generated reads. See the \"releases\" page for download: https://github.com/mlell/tapas/releases. The manual can be found at https://mlell.github.io/tapas.",
    "filenames": [
      "Singularity"
    ],
    "full_name": "mlell/tapas",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-tapas\" class=\"anchor\" href=\"#tapas\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTAPAS\u003c/h1\u003e\n\u003cp\u003eThis software package is meant for comparing NGS short read mappers.\u003c/p\u003e\n\u003cp\u003eArtificial reads can be generated from genome sequences such that their true\nmapping positions are known (\u003ccode\u003escripts/uniform\u003c/code\u003e). Artificial point mutations\n(\u003ccode\u003escripts/multiple_mutate\u003c/code\u003e) and indels (\u003ccode\u003escripts/indel\u003c/code\u003e) can be introduced.\nBy comparing the original read locations to the positions the reads were\nassigned to by the mapper, the sensitivity and specificity of the mapper can\nbe assessed.\u003c/p\u003e\n\u003cp\u003eBy running the mapper with different combinations of parameters, an optimal\nparameter set can be found (\u003ccode\u003escripts/cross_tab\u003c/code\u003e and \u003ccode\u003escripts/table2calls\u003c/code\u003e).\nTAPAS is compatible with all short read mappers by through a simple text\nfile which contains the mapping command and the relevant parameters. Instead\nof the parameter values, bash variables (\u003ccode\u003e${variablename}\u003c/code\u003e) are used. They\nare replaced with the mapping parameter values to be tested by TAPAS.\u003c/p\u003e\n\u003cp\u003eAdditionally, reads can be mutated in a pattern similar to typical damage found\nin ancient DNA (aDNA) (\u003ccode\u003escripts/mapdamage2geomparam\u003c/code\u003e). The effect of this\nmutations can be inspected as well.\u003c/p\u003e\n\u003cp\u003eAll the scripts are designed with the UNIX philosophy \"do one thing and do it\nwell\" in mind. Therefore an analysis consists of a pipeline of these scripts.\u003c/p\u003e\n\u003cp\u003eThe universal data format is the text table, a simple text file containing data\nin whitespace- or tab-separated columns. The first line serves as header line\nwith column names.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-the-manual\" class=\"anchor\" href=\"#the-manual\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eThe manual\u003c/h2\u003e\n\u003cp\u003eThe availabe tools are described in-depth in the TAPAS manual.\nThe manual is located in the \u003ccode\u003edocs/\u003c/code\u003e folder. Open the file \u003ccode\u003edocs/index.html\u003c/code\u003e\ninside the TAPAS folder with your browser to view it.\u003c/p\u003e\n\u003cp\u003eThe manual can also be found online, \u003ca href=\"https://mlell.github.io/tapas\" rel=\"nofollow\"\u003eclick here\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThere is also one \u003cstrong\u003eexample script\u003c/strong\u003e which summarises the steps of the manual.\nIt can be found at \u003ccode\u003emanual/example-manual.sh\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eTo get help about one specific TAPAS tool, execute the tool with the option\n\u003ccode\u003e--help\u003c/code\u003e. Each tool prints then an extensive help page which explains how\nto use it. Example: \u003ccode\u003eTAPAS/scripts/uniform --help\u003c/code\u003e, where \u003ccode\u003eTAPAS\u003c/code\u003e is the\nfolder you installed TAPAS to, prints the help of the artificial read\ngeneration tool \u003ccode\u003euniform\u003c/code\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-installation\" class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eThis software package needs the following tools to be installed:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eR \u0026gt;= 3.2\u003c/li\u003e\n\u003cli\u003ePython \u0026gt;= 3.4 and Pip, the Python package manager\u003c/li\u003e\n\u003cli\u003eStandard GNU tools like \u003ccode\u003ehead\u003c/code\u003e, \u003ccode\u003eawk\u003c/code\u003e, \u003ccode\u003esort\u003c/code\u003e, \u003ccode\u003ejoin\u003c/code\u003e, \u003ccode\u003esed\u003c/code\u003e. These are\nincluded in all GNU/Linux and Mac distributions. On Windows you can install\nCygwin to get these programs. However, this software package is not yet\ntested on Windows.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThese are the commands needed to install these dependencies on your\nsystem. Select those which match your GNU/Linux distribution:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eUbuntu\u003c/strong\u003e and derivatives, like \u003cstrong\u003eScientific Linux\u003c/strong\u003e and \u003cstrong\u003eLinux Mint\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esudo apt-get install r python3 python3-pip\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eCentOS\u003c/strong\u003e or \u003cstrong\u003eRed Hat Linux\u003c/strong\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esudo yum --enablerepo=extras install epel-release\nsudo yum install r python3 python3-pip\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo install TAPAS, first download it from the\n\u003ca href=\"https://github.com/mlell/tapas/releases\"\u003eReleases section\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThen, execute the script\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eTAPAS/scripts/gen/install_dependencies\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ewhere you replace \u003ccode\u003eTAPAS\u003c/code\u003e by the folder where you installed TAPAS into. The\ntool downloads and installs the needed R and Python packages. The packages\nare installed inside the TAPAS folder and do no affect the rest of the system.\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-alternative-method-use-global-r-and-python-packages\" class=\"anchor\" href=\"#alternative-method-use-global-r-and-python-packages\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAlternative method: Use global R and Python packages\u003c/h3\u003e\n\u003cp\u003eIf you want to run TAPAS using R and Python packages which are installed\nglobally on your system, instead of the \u003ccode\u003einstall_dependencies\u003c/code\u003e script, run\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eTAPAS/script/gen/gen-launchers.sh --ext-libs\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo check if all dependencies are met, run\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eTAPAS/scripts/setup_check_dependencies\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eon your computer.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-the-scripts\" class=\"anchor\" href=\"#the-scripts\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eThe scripts\u003c/h2\u003e\n\u003cp\u003eAll scripts lie in the \u003ccode\u003escripts/\u003c/code\u003e folder. Read the manual to get an overview.\nAdditionally, each script can be executed with the \u003ccode\u003e--help\u003c/code\u003e switch to get\ndetailed information about the script\u0027s functionality and how it can be tailored\nto your specific needs.\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1622395670.0
  },
  {
    "data_format": 2,
    "description": "Fast and scalable NGS data processing",
    "filenames": [
      "Singularity"
    ],
    "full_name": "cibiobcg/PaCBAM",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-pacbam\" class=\"anchor\" href=\"#pacbam\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePaCBAM\u003c/h1\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1578735123.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "containers/Singularity.intel_netcdf",
      "containers/Singularity.intel_cm4",
      "containers/Singularity.cm4"
    ],
    "full_name": "NOAA-GFDL/CM4",
    "latest_release": "2021.01",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-gfdl-cm4-model\" class=\"anchor\" href=\"#gfdl-cm4-model\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGFDL CM4 Model\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://www.gfdl.noaa.gov\" rel=\"nofollow\"\u003eGeophysical Fluid Dynamics Laboratory\n(GFDL)\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe layout of this package includes the following directories:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003esrc - The source code for the CM4 model\u003c/li\u003e\n\u003cli\u003eexec - The build directory with Makefiles for building the model executable\u003c/li\u003e\n\u003cli\u003erun - Sample run script\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-cloning-instructions\" class=\"anchor\" href=\"#cloning-instructions\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCloning Instructions\u003c/h2\u003e\n\u003cp\u003eThis repository uses \u003ca href=\"https://git-scm.com/book/en/v2/Git-Tools-Submodules\" rel=\"nofollow\"\u003egit\nsubmodules\u003c/a\u003e to\npoint to other repositories.  Thus, care should be taken when cloning,\nand updating the source to ensure all source.  To obtain all source,\nuse the following git command\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone --recursive https://github.com/NOAA-GFDL/CM4.git\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003e--recursive\u003c/code\u003e option to \u003ccode\u003egit clone\u003c/code\u003e instructs git to recursively\nclone all submodules.  In the event the repository was not cloned\nusing the \u003ccode\u003e--recursive\u003c/code\u003e option, the following step must be taken to\nobtain all sources:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# From within the CM4 parent directory\ngit submodule update --init --recursive\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-source-code\" class=\"anchor\" href=\"#source-code\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSource Code\u003c/h2\u003e\n\u003cp\u003eAll model source is contained in the \u003ca href=\"src\"\u003esrc\u003c/a\u003e directory.  GFDL\ntracks code using the git version control system.  This package\nincludes a single version of the following GFDL model components.  The\ngit hash listed corresponds to the commit hash in the internal GFDL\ngit repository.\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eComponent\u003c/th\u003e\n\u003cth\u003eCommit Hash\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eatmos_cubed_sphere\u003c/td\u003e\n\u003ctd\u003eb8b05bf650c0d3293b538bdaceb894ba0fd6910b\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eatmos_drivers\u003c/td\u003e\n\u003ctd\u003e3be6ed406de2db29766746a69115fd6a47048692\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eatmos_param\u003c/td\u003e\n\u003ctd\u003e4fe4ca54a0224ef5c4cf9ebf1010d5b869930a3f\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eatmos_shared\u003c/td\u003e\n\u003ctd\u003e2e9d8b770cdb2d70d8d9264e4b2de24213ae21bd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eland_lad2\u003c/td\u003e\n\u003ctd\u003e154bd2b4bf523f3e699de5017679b156242ec13f\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eThe following components are available in the\n\u003ca href=\"https://github.com/NOAA-GFDL\"\u003eNOAA-GFDL\u003c/a\u003e github organization:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-GFDL/MOM6\"\u003eMOM6\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-GFDL/SIS2\"\u003eSIS2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/NOAA-GFDL/GFDL_atmos_cubed_sphere/tree/AM4.0\"\u003eGFDL_atmos_cubed_sphere\u003c/a\u003e (as \u003ca href=\"src/atmos_cubed_sphere\"\u003eatmos_cubed_sphere\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-GFDL/icebergs\"\u003eicebergs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-GFDL/ice_param\"\u003eice_param\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-GFDL/ocean_BGC\"\u003eocean_BGC\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-GFDL/FMScoupler\"\u003ecoupler\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/NOAA-GFDL/FMS\"\u003eFMS\u003c/a\u003e (as \u003ca href=\"src/shared\"\u003eshared\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-GFDL/mocsy\"\u003emocsy\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-building-cm4\" class=\"anchor\" href=\"#building-cm4\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding CM4\u003c/h2\u003e\n\u003cp\u003eThe \u003ca href=\"exec\"\u003eexec\u003c/a\u003e directory contains Makefiles that can be used to\nbuild the CM4 executable.  These Makefiles were generated using the\n\u003ca href=\"https://github.com/NOAA-GFDL/mkmf\"\u003eMake Makefile (mkmf)\u003c/a\u003e program.\nIncluded in the exec direcgtory is a sample make template file for the\nIntel compilers (\u003ca href=\"exec/templates/intel.mk\"\u003eintel.mk\u003c/a\u003e).  This make\ntemplate can be used on any system with a relatively recent version of\nthe Intel compilers, the netCDF 4 library and the MPICH2 MPI library.\nIncluded in the \u003ca href=\"exec/templates/intel.mk\"\u003eintel.mk\u003c/a\u003e file are\nadditional settings that can be modified during the build.\u003c/p\u003e\n\u003cp\u003eTo run the default build (-O3 -msse2), go to the exec directory and\nenter the command\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emake HDF_INCLUDE=-I/path/to/hdf5/include\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhere \u003cem\u003e/path/to/hdf5/include\u003c/em\u003e is the path to your HDF5 include folder where hdf5.mod\nis.\u003c/p\u003e\n\u003cp\u003eIf you would like to change some of the compiler options, there are several different\noptions to add to the make command.  For example\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emake ISA=-xhost REPRO=on\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ewill replace -msse with -xhost and -O3 with -O2.  The three options for\nbuilding are\u003cbr\u003e\n\u003ccode\u003ePROD=on\u003c/code\u003e (-O3) Default\n\u003ccode\u003eREPRO=on\u003c/code\u003e (-O2)\u003cbr\u003e\n\u003ccode\u003eDEBUG=on\u003c/code\u003e (-O0 and other traps)\u003cbr\u003e\nAll of the make line options can be\nfound in the \u003ca href=\"exec/templates/intel.mk\"\u003eintel.mk\u003c/a\u003e file.\u003c/p\u003e\n\u003cp\u003eTo build with GNU compilers, add \u003ccode\u003egcc=on\u003c/code\u003e to the \u003ccode\u003emake\u003c/code\u003e line. The make line\noptions can be found in the \u003ca href=\"exec/templates/gnu.mk\"\u003egnu.mk\u003c/a\u003e file.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-obtaining-the-input-data\" class=\"anchor\" href=\"#obtaining-the-input-data\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eObtaining the input data\u003c/h2\u003e\n\u003cp\u003eThe input data required for running the CM4 model can be found on\n\u003ca href=\"http://data1.gfdl.noaa.gov/nomads/forms/cm4/\" rel=\"nofollow\"\u003eGFDL\u0027s data\nportal\u003c/a\u003e .\u003c/p\u003e\n\u003cp\u003eThe file \u003ccode\u003eCM4_runDir.tar.gz\u003c/code\u003e contains a configured run directory to run a\nsample experiment of the CM4 model.  Included in the tar file is a\nREADME.CM4 with more instructions on how to configure the CM4 run\ndirectory.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-running-cm4\" class=\"anchor\" href=\"#running-cm4\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning CM4\u003c/h2\u003e\n\u003cp\u003eIncluded in the run directory is a sample run script for reference.\nTo run the CM4 sample experiment, first download the data file\nmentioned in \u003ca href=\"#obtaining-the-input-data\"\u003eObtaining the Input data\u003c/a\u003e\nsection.  Modify the variables in the configuration section in the\nsample run script, and then run the script.\u003c/p\u003e\n\u003cp\u003eThe sample data and run script are configured to run on a total of 8127\nprocessors (864 cores 4 threads for the atmosphere and 4671 ocean cores).\u003cbr\u003e\nTo run on a different number of processors, or modify the\nexperiment, refer to the \u003ccode\u003eREADME.CM4\u003c/code\u003e file included in the CM4\ndata tarball.\u003c/p\u003e\n\u003cp\u003eNote: The \u003ccode\u003einput.nml\u003c/code\u003e file (found in the CM4 data tarball) contains\nFortran namelists and namelist variables that modify, at run time, the\nmodel.  To learn more about the settings in the \u003ccode\u003einput.nml\u003c/code\u003e file,\nplease refer to source code where the namelist/variable are defined.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-model-output-and-other-references\" class=\"anchor\" href=\"#model-output-and-other-references\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eModel output and Other References\u003c/h2\u003e\n\u003cp\u003ePlease refer to the \u003ca href=\"http://data1.gfdl.noaa.gov/nomads/forms/cm4/\" rel=\"nofollow\"\u003eCM4 data and code\nsite\u003c/a\u003e for details\nabout where to find model and OBS data used in the papers.\u003c/p\u003e\n\u003cp\u003eFor all analysis figures and pertaining data, please use the CM4\ndocumentation papers as the original reference.\u003c/p\u003e\n\u003cp\u003ePlease direct your questions and feedback to\n\u003ca href=\"mailto:gfdl.climate.model.info@noaa.gov\"\u003egfdl.climate.model.info@noaa.gov\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-disclaimer\" class=\"anchor\" href=\"#disclaimer\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDisclaimer\u003c/h2\u003e\n\u003cp\u003eThe United States Department of Commerce (DOC) GitHub project code is\nprovided on an \u0027as is\u0027 basis and the user assumes responsibility for\nits use.  DOC has relinquished control of the information and no\nlonger has responsibility to protect the integrity, confidentiality,\nor availability of the information.  Any claims against the Department\nof Commerce stemming from the use of its GitHub project will be\ngoverned by all applicable Federal law.  Any reference to specific\ncommercial products, processes, or services by service mark,\ntrademark, manufacturer, or otherwise, does not constitute or imply\ntheir endorsement, recommendation or favoring by the Department of\nCommerce.  The Department of Commerce seal and logo, or the seal and\nlogo of a DOC bureau, shall not be used in any manner to imply\nendorsement of any commercial product or activity by DOC or the United\nStates Government.\u003c/p\u003e\n\u003cp\u003eThis project code is made available through GitHub but is managed by\nNOAA-GFDL at \u003ca href=\"https://gitlab.gfdl.noaa.gov\" rel=\"nofollow\"\u003ehttps://gitlab.gfdl.noaa.gov\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1622054482.0
  },
  {
    "data_format": 2,
    "description": "Creates Manhattan and QQ plots with annotated peaks.",
    "filenames": [
      "Singularity"
    ],
    "full_name": "hmgu-itg/man_qq_annotate",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-man_qq_annotate\" class=\"anchor\" href=\"#man_qq_annotate\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eman_qq_annotate\u003c/h1\u003e\n\u003cp\u003eCreates Manhattan and QQ plots with annotated peaks for sequencing-based GWAS outputs, by thinning the dataset to what the eye can see.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-installation\" class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eClone the repository and install using \u003ccode\u003edevtools\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone https://github.com/hmgu-itg/man_qq_annotate.git\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e man_qq_annotate\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Install devtools if you don\u0027t have it\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e R -e \u0027install.packages(\u0027devtools\u0027)\u003c/span\u003e\nR -e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003elibrary(devtools) ; install()\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-usage\" class=\"anchor\" href=\"#usage\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsage\u003c/h2\u003e\n\u003cp\u003eYou can either use the CLI or load the package into your R environment.\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-command-line-interface-cli\" class=\"anchor\" href=\"#command-line-interface-cli\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCommand Line Interface (CLI)\u003c/h3\u003e\n\u003cp\u003eOnce installed, you can use the \u003ccode\u003erun_manqq.R\u003c/code\u003e script in the base of the repository as a command line tool.\u003cbr\u003e\nFor a GCTA output, use the following:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e./run_manqq.R --chr-col Chr --pval-col p --pos-col bp --a1 A1 --a2 A2 --build 38 --image png --af-col Freq input.assoc.txt.gz output.prefix\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can add \u003ccode\u003erun_manqq.R\u003c/code\u003e to your \u003ccode\u003ePATH\u003c/code\u003e variable for convenient execution:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e PATH=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e/path/to/man_qq_annotate:\u003cspan class=\"pl-smi\"\u003e$PATH\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Or to make this permanent:\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eecho\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003eexport PATH=\"/path/to/man_qq_annotate:$PATH\"\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026gt;\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e~\u003c/span\u003e/.bashrc\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eInput files can be gzipped or plain. Run without arguments for a list of options, run with \u003ccode\u003e--help\u003c/code\u003e for detailed options:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eusage: ./run_manqq.R [-h] [--chr-col [character]] [--pval-col [character]]\n                     [--pos-col [character]] [--a1 [character]]\n                     [--a2 [character]] [--build [integer]]\n                     [--image [character]] [--af-col [character]]\n                     [--maf-filter [double]] [--sig [double]]\n                     [--maxpeaks [integer]] [--no-qq] [--no-man] [--no-annot]\n                     [--no-distance] [--man-height [integer]]\n                     [--upper-margin [double]] [--annot-cex [double]]\n                     [--axes-cex [double]] [--ylim [double]]\n                     infile outfile\n\nA program to plot Manhattan and QQ plots\n\npositional arguments:\n  infile                Input file name, must be gzip file\n  outfile               Output file name (with no file extension)\n\noptional arguments:\n  \u003cspan class=\"pl-k\"\u003e-h\u003c/span\u003e, --help            show this \u003cspan class=\"pl-c1\"\u003ehelp\u003c/span\u003e message and \u003cspan class=\"pl-c1\"\u003eexit\u003c/span\u003e\n  --chr-col [character]\n                        The column NAME \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e the chromosome column, default chr\n  --pval-col [character]\n                        The column NAME \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e the chromosome column, default\n                        p_score\n  --pos-col [character]\n                        The column NAME \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e the chromosome column, default ps\n  --a1 [character]      The column NAME \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e the effect allele column, default\n                        allele1\n  --a2 [character]      The column NAME \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e the non-effect column, default\n                        allele0\n  --build [integer]     The genome build the positions refer to\n  --image [character]   The filetype to save plots to (png or pdf)\n  --af-col [character]  The column NAME \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e the allele frequency column,\n                        default af\n  --maf-filter [double]\n                        The significance threshold \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e MAF filter, default\n                        0.0.\n  --sig [double]        The significance threshold to use \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e peak annotation\n  --maxpeaks [integer]  The maximum number of peaks to annotate\n  --no-qq               Don\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003et plot QQ.\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e  --no-man              Don\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003et plot Manhattan.\n  --no-annot            Disable peak annotation even \u003cspan class=\"pl-k\"\u003eif\u003c/span\u003e peaks are present.\n  --no-distance         Don\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003et add very useful distance to gene info.\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e  --man-height [integer]\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e                        Force height of Manhattan in inches. Can have\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e                        unpredictable consequences (some of which you may\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e                        regret).\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e  --upper-margin [double]\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e                        Y limit of Manhattan plot in units of maximum data\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e                        points. Even more unpredictable than the above.\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e  --annot-cex [double]  Size factor for annotations.\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e  --axes-cex [double]   Size factor for axes and labels.\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e  --ylim [double]       The y-axis limit (-log10(p))\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-loading-the-package\" class=\"anchor\" href=\"#loading-the-package\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLoading the package\u003c/h3\u003e\n\u003cp\u003eYou can load the package into your R environment and use the available functions.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-r\"\u003e\u003cpre\u003elibrary(\u003cspan class=\"pl-smi\"\u003emanqq\u003c/span\u003e)\nls(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003epackage:manqq\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e)\u003c/pre\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003e[1] \"run_manqq\"      \"run_manqq.gcta\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCurrently, only two functions are exported and available for users. The other functions are all hidden and only used internally within the package. If there are any particular functionality you wish to use from the package, please make a request in the \u003ca href=\"https://github.com/hmgu-itg/man_qq_annotate/issues\"\u003eissue page\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-development\" class=\"anchor\" href=\"#development\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDevelopment\u003c/h2\u003e\n\u003cp\u003eYou can use \u003ccode\u003edevtools\u003c/code\u003e to load all the functions into your environment for development/debugging:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-r\"\u003e\u003cpre\u003elibrary(\u003cspan class=\"pl-smi\"\u003edevtools\u003c/span\u003e)\nsetwd(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e/base/of/the/repo/man_qq_annotate\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e)\nload_all()\ntest() \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Use testthat\u0027s test function to run the testsuite\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1622250961.0
  },
  {
    "data_format": 2,
    "description": "docker and singularity containers for R",
    "filenames": [
      "images/rstan_4.1.0/Singularity.def",
      "images/rmd-light_4.1.0/Singularity.def",
      "images/myenv_4.1.0/Singularity.def"
    ],
    "full_name": "mattocci27/r-containers",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-docker-and-singularity-images-for-r\" class=\"anchor\" href=\"#docker-and-singularity-images-for-r\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDocker and singularity images for R\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/45b4ffbd594af47fe09a3432f9f8e122c6518aa6352b4ce453a1a2563da2905c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d677265656e2e737667\" alt=\"GitHub License\" data-canonical-src=\"https://img.shields.io/badge/license-MIT-green.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-images\" class=\"anchor\" href=\"#images\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eImages\u003c/h2\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003edocker\u003c/th\u003e\n\u003cth\u003esingularity\u003c/th\u003e\n\u003cth\u003edescription\u003c/th\u003e\n\u003cth\u003er-ver\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://hub.docker.com/repository/docker/mattocci/rstan\" rel=\"nofollow\"\u003erstan\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://cloud.sylabs.io/library/mattocci27/default/rstan\" rel=\"nofollow\"\u003erstan\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eadds rstan on \u003ca href=\"https://hub.docker.com/r/rocker/geospatial\" rel=\"nofollow\"\u003egeospatial\u003c/a\u003e\n\u003c/td\u003e\n\u003ctd\u003e3.6.3, 4.0.5\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://hub.docker.com/repository/docker/mattocci/myenv\" rel=\"nofollow\"\u003emyenv\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://cloud.sylabs.io/library/mattocci27/default/myenv\" rel=\"nofollow\"\u003emyenv\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003eadds a bunch of packages on \u0027rstan\u0027\u003c/td\u003e\n\u003ctd\u003e3.6.3, 4.0.5\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://hub.docker.com/repository/docker/mattocci/rmd-light\" rel=\"nofollow\"\u003ermd-light\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003eR markdown + TinyTex + pandoc-crossref without Rstudio and Tidyverse\u003c/td\u003e\n\u003ctd\u003e4.0.5\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1621951768.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "Singularity"
    ],
    "full_name": "jolars/ReproduciblePythonProject",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-reproduciblepythonproject\" class=\"anchor\" href=\"#reproduciblepythonproject\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eReproduciblePythonProject\u003c/h1\u003e\n\u003cp\u003eA template for reproducible projects using python, singularity, and c++ (via\npybind11).\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1621946266.0
  },
  {
    "data_format": 2,
    "description": "To build hpc benchmark and mpi with cuda support sif",
    "filenames": [
      "hpcc_intel.def",
      "bert.def",
      "hpc_mpi_cuda.def",
      "hpl_intel_cuda.def"
    ],
    "full_name": "perambluate/singularity-definition-files-for-HPC",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-hpc_mpi_cuda_singu_def_file\" class=\"anchor\" href=\"#hpc_mpi_cuda_singu_def_file\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ehpc_mpi_cuda_singu_def_file\u003c/h1\u003e\n\u003cp\u003eA collect of definition files to build images for singularity containers, which includes hpc benchmarks and mpis with cuda support.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://singularity-hub.org/collections/4181\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a07b23d4880320ac89cdc93bbbb603fa84c215d135e05dd227ba8633a9ff34be/68747470733a2f2f7777772e73696e67756c61726974792d6875622e6f72672f7374617469632f696d672f686f737465642d73696e67756c61726974792d2d6875622d2532336533323932392e737667\" alt=\"https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg\" data-canonical-src=\"https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 0,
    "topics": [],
    "updated_at": 1588998487.0
  },
  {
    "data_format": 2,
    "description": "Part of the sc-eQTLgen consortium pipeline. Step 1, where the QC is done.",
    "filenames": [
      "Singularity.Imputation",
      "Singularity.WGpipeline"
    ],
    "full_name": "sc-eQTLgen-consortium/WG1-pipeline-QC",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-wg1-pipeline-qc\" class=\"anchor\" href=\"#wg1-pipeline-qc\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWG1-pipeline-QC\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://user-images.githubusercontent.com/44268007/89252548-35b96f80-d659-11ea-97e9-4b4176df5f08.png\" target=\"_blank\" rel=\"nofollow\"\u003e\u003cimg src=\"https://user-images.githubusercontent.com/44268007/89252548-35b96f80-d659-11ea-97e9-4b4176df5f08.png\" width=\"300\" height=\"140\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePart of the sceQTL-Gen consortium pipeline. Step 1, where the QC is done.\u003c/p\u003e\n\u003cp\u003ePlease see the \u003ca href=\"https://github.com/sc-eQTLgen-consortium/WG1-pipeline-QC/wiki\"\u003eWiki\u003c/a\u003e for information on running the QC pipeline.\u003c/p\u003e\n",
    "stargazers_count": 2,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1622436472.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "containers/Singularity.intel_netcdf",
      "containers/Singularity.esm4",
      "containers/Singularity.intel_esm4"
    ],
    "full_name": "NOAA-GFDL/ESM4",
    "latest_release": "2021.02",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-earth-system-model-4\" class=\"anchor\" href=\"#earth-system-model-4\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eEarth System Model 4\u003c/h1\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-what-is-included\" class=\"anchor\" href=\"#what-is-included\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWhat Is Included\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e[src/]((\u003ca href=\"https://github.com/NOAA-GFDL/ESM4/tree/master/src\"\u003ehttps://github.com/NOAA-GFDL/ESM4/tree/master/src\u003c/a\u003e) source code for the ESM4 model (all code is in submodules)\u003c/li\u003e\n\u003cli\u003e[exec/]((\u003ca href=\"https://github.com/NOAA-GFDL/ESM4/tree/master/exec\"\u003ehttps://github.com/NOAA-GFDL/ESM4/tree/master/exec\u003c/a\u003e) Makefiles to compile the code\u003c/li\u003e\n\u003cli\u003e[run/]((\u003ca href=\"https://github.com/NOAA-GFDL/ESM4/tree/master/run\"\u003ehttps://github.com/NOAA-GFDL/ESM4/tree/master/run\u003c/a\u003e) Simple run script\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-cloning\" class=\"anchor\" href=\"#cloning\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCloning\u003c/h2\u003e\n\u003cp\u003eTo clone the ESM4 model please use the recursive option\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone --recursive git@github.com:NOAA-GFDL/ESM4.git \u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eor\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone --recursive https://github.com/NOAA-GFDL/ESM4.git\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-compiling\" class=\"anchor\" href=\"#compiling\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCompiling\u003c/h2\u003e\n\u003cp\u003eThis model was originally compiled and run with the intel16 compiler.\nIt is recommended that you compile with an intel compiler.\u003c/p\u003e\n\u003cp\u003eCompiling assumes that you have an intel compiler, MPI (impi, mpich,\nopenmpi, etc), netcdf, and hdf5 in your LD_LIBRARY_PATH and LIBRARY_PATH.\nIt is also assumed that nf-config and nc-config are in your path.\nIf you work on a machine with modules, you may need to load these\npackages into your environment.\u003c/p\u003e\n\u003cp\u003eMakefiles have been included in the\n\u003ca href=\"https://github.com/NOAA-GFDL/ESM4/tree/master/exec\"\u003eexec/\u003c/a\u003e folder.\nThere are several option for compiling, which can be found in the\n\u003ca href=\"https://github.com/NOAA-GFDL/ESM4/blob/master/exec/templates/intel.mk\"\u003etemplate/intel.mk\u003c/a\u003e.\u003cbr\u003e\nYou may need to edit the template/intel.mk to update the compiler names\nor add any CPPDEF options specific for your system.\nThe most common compile with optimizations on and with openmp would be\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003eexec\u003c/span\u003e\nmake OPENMP=on\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you would like to compile with \u003cem\u003e-O2\u003c/em\u003e instead of \u003cem\u003e-O3\u003c/em\u003e do\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003emake REPRO=on OPENMP=on\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTo compile with \u003cem\u003e-O0\u003c/em\u003e and debug flags do\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003emake DEBUG=on OPENMP=on\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eCompiling with openMP is optional.\u003c/p\u003e\n\u003cp\u003eHere are examples of how to compile the model on various systems:\u003c/p\u003e\n\u003cp\u003egaea (NOAA RDHPCS cray system)\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003emodule load intel\nmodule load cray-netcdf\nmodule load cray-hdf5\ngit clone --recursive git@github.com:NOAA-GFDL/ESM4.git\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e ESM4/exec\nmake MKL_LIBS=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003enone\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e OPENMP=y\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eCompiling on orion (MSU)\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003emodule load intel impi netcdf hdf5\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e LIBRARY_PATH=\u003cspan class=\"pl-smi\"\u003e${LIBRARY_PATH}\u003c/span\u003e:\u003cspan class=\"pl-smi\"\u003e${LD_LIBRARY_PATH}\u003c/span\u003e\ngit clone --recursive git@github.com:NOAA-GFDL/ESM4.git\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e ESM4/exec\nmake OPENMP=on\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-model-running\" class=\"anchor\" href=\"#model-running\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eModel running\u003c/h2\u003e\n\u003cp\u003eA work directory needed for running the model can be obtained from\n\u003ca href=\"ftp://data1.gfdl.noaa.gov/users/ESM4/ESM4Documentation/GFDL-ESM4/inputData/ESM4_rundir.tar.gz\" rel=\"nofollow\"\u003eftp://data1.gfdl.noaa.gov/users/ESM4/ESM4Documentation/GFDL-ESM4/inputData/ESM4_rundir.tar.gz\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThe directory contains input.nml as the namelist, various input tables needed\nfor running the model, and model input files in a folder called INPUT/.  There\nis also a directory named RESTART/ that should be empty at the beginning of\neach run.\u003c/p\u003e\n\u003cp\u003eThere is a skeleton of a run script named \u003ca href=\"https://github.com/NOAA-GFDL/ESM4/blob/master/run/ESM4_run.sh\"\u003erun/ESM4_run.sh\u003c/a\u003e.  You must update this\nscript to run the model.  Include a path to the work directory and the executable.\nYou should also update the program you need to run the model on your system.  The\ndefault for this script is \u003ccode\u003esrun\u003c/code\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-disclaimer\" class=\"anchor\" href=\"#disclaimer\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDisclaimer\u003c/h2\u003e\n\u003cp\u003eThe United States Department of Commerce (DOC) GitHub project code is provided\non an \u0027as is\u0027 basis and the user assumes responsibility for its use. DOC has\nrelinquished control of the information and no longer has responsibility to\nprotect the integrity, confidentiality, or availability of the information. Any\nclaims against the Department of Commerce stemming from the use of its GitHub\nproject will be governed by all applicable Federal law. Any reference to\nspecific commercial products, processes, or services by service mark,\ntrademark, manufacturer, or otherwise, does not constitute or imply their\nendorsement, recommendation or favoring by the Department of Commerce. The\nDepartment of Commerce seal and logo, or the seal and logo of a DOC bureau,\nshall not be used in any manner to imply endorsement of any commercial product\nor activity by DOC or the United States Government.\u003c/p\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 5,
    "topics": [
      "gfdl",
      "ems",
      "ems4",
      "fms",
      "climate",
      "model",
      "fortran"
    ],
    "updated_at": 1622050940.0
  },
  {
    "data_format": 2,
    "description": "Install methods for UPPMAX modules plus some helper scripts",
    "filenames": [
      "singularity_info/metaWRAP_1.3.2/Singularity.metaWRAP",
      "singularity_info/bonito/Singularity.bonito",
      "singularity_info/gapseq-RT-227932/Singularity.gapseq"
    ],
    "full_name": "UPPMAX/install-methods",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-module-installation-methods\" class=\"anchor\" href=\"#module-installation-methods\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eModule Installation Methods\u003c/h1\u003e\n\u003cp\u003eThis is a collection of READMEs generated during installation of software\napplications on Uppmax clusters.  It is incomplete in terms of modules\navailable on Uppmax, and the individual READMEs may also be incomplete in terms\nof what was actually done to install the modules.  We are publicising these in\nthe hopes that they can be helpful.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-example-workflow-of-a-basic-installation\" class=\"anchor\" href=\"#example-workflow-of-a-basic-installation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eExample workflow of a basic installation\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eClone the install methods git repo (\u003ccode\u003egit clone https://github.com/UPPMAX/install-methods.git\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eAdd the repo to your \u003ccode\u003e$PATH\u003c/code\u003e and source the \u003ccode\u003euppmax_functions.sh\u003c/code\u003e file to get access to the functions.\u003c/li\u003e\n\u003cli\u003eRun \u003ccode\u003erun_makeroom\u003c/code\u003e with at least \u003ccode\u003e-t\u003c/code\u003e and \u003ccode\u003e-v\u003c/code\u003e, to generate a \u003ccode\u003e.sh\u003c/code\u003e (\u003ccode\u003emakeroom_toolname_version.sh\u003c/code\u003e) file that will create the directory structure needed in \u003ccode\u003e/sw\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eRun the \u003ccode\u003e.sh\u003c/code\u003e file created in the directory you are standing to create the directory structure (\u003ccode\u003e/sw/category/toolname/\u003c/code\u003e and \u003ccode\u003e/sw/mf/common/category\u003c/code\u003e) and template files.\u003c/li\u003e\n\u003cli\u003ePut the source code for the program in \u003ccode\u003e/sw/category/toolname/version/src\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eCompile and/or install the tool in \u003ccode\u003e/sw/category/toolname/version/cluster/bin\u003c/code\u003e etc.\u003c/li\u003e\n\u003cli\u003eEdit the readme file, explaining how you did the installation, in \u003ccode\u003e/sw/category/toolname/toolname-version_install-README.md\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eEdit the template module file \u003ccode\u003e/sw/category/toolname/mf/version\u003c/code\u003e to do what you want when the module loads.\u003c/li\u003e\n\u003cli\u003eCopy the module file to the live location, \u003ccode\u003e/sw/mf/common/category/[section]/toolname\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eRun \u003ccode\u003eall_mflink toolname version\u003c/code\u003e to create links for all clusters to the module file in \u003ccode\u003e/sw/mf/common/category/[section]/toolname\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eRun \u003ccode\u003efixup /sw/category/toolname/version /sw/mf/common/category/[section]/toolname\u003c/code\u003e to make sure the ownership and permissions are ok.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-scripts\" class=\"anchor\" href=\"#scripts\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eScripts\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003egather-READMEs.sh\u003c/code\u003e - bash script to scan installation directories, looking for\nREADME files having a particular filename format that we create during\ninstallation of tools\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003efixup\u003c/code\u003e - bash script fixing up permissions and group membership within\ninstallation trees; our local installation group is \u003ccode\u003esw\u003c/code\u003e. With the \u003ccode\u003e-g\u003c/code\u003e option,\nthis script will \u003ccode\u003echmod g+s\u003c/code\u003e directories in the tree, too.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003euppmax_functions.sh\u003c/code\u003e - bash helper functions for SLURM job viewing and various\nmodule-related tasks, mostly to do with setting up mf files for loading\nmodules; the latter require appexpert privileges.  Source these from \u003ccode\u003e.bashrc\u003c/code\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-installation-directories\" class=\"anchor\" href=\"#installation-directories\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation directories\u003c/h2\u003e\n\u003cp\u003eThe directories contain software installations in major subject areas.\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-apps\" class=\"anchor\" href=\"#apps\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eapps/\u003c/h3\u003e\n\u003cp\u003eGeneral applications.\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-appsbioinfo\" class=\"anchor\" href=\"#appsbioinfo\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eapps/bioinfo/\u003c/h3\u003e\n\u003cp\u003eBioinformatics applications.\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-libs\" class=\"anchor\" href=\"#libs\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003elibs/\u003c/h3\u003e\n\u003cp\u003eLibraries.\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-comp\" class=\"anchor\" href=\"#comp\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ecomp/\u003c/h3\u003e\n\u003cp\u003eCompilers, interpreters, build tools.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-database-directories\" class=\"anchor\" href=\"#database-directories\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDatabase directories\u003c/h2\u003e\n\u003cp\u003eThese directories cover installations of databases updated either manually, or via update scripts.\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-data_uppnex\" class=\"anchor\" href=\"#data_uppnex\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003edata_uppnex/\u003c/h3\u003e\n\u003cp\u003eInstallation instructions for databases under \u003ccode\u003e/sw/data/uppnex/\u003c/code\u003e.  Database\ndirectories containing \u003ccode\u003e*-install-README.md\u003c/code\u003e files are updated manually.\nDatabase directories containing \u003ccode\u003e*-db-README.md\u003c/code\u003e files and scripts (currently,\n\u003ccode\u003eKraken\u003c/code\u003e, \u003ccode\u003ediamond_databases\u003c/code\u003e and \u003ccode\u003eRTG\u003c/code\u003e) are updated monthly via crontab entries.\u003c/p\u003e\n\u003cp\u003eBlast database updates are included here, and involve multiple scripts, crontab\nentries and a test directory.  These are updated monthly via crontab entries.\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-data_other\" class=\"anchor\" href=\"#data_other\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003edata_other/\u003c/h3\u003e\n\u003cp\u003eInstallation instructions for databases under other locations, currently just\n\u003ccode\u003eBUSCO\u003c/code\u003e lineage sets, which are kept in the module installation directory.\nThese are updated monthly via crontab entries.\u003c/p\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 5,
    "topics": [],
    "updated_at": 1622535198.0
  },
  {
    "data_format": 2,
    "description": "The Recommender Engine for Intelligent Transient Tracking",
    "filenames": [
      "Singularity"
    ],
    "full_name": "refitt/refitt",
    "latest_release": "0.16.5",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularity-ubuntu20\" class=\"anchor\" href=\"#singularity-ubuntu20\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003esingularity-ubuntu20\u003c/h1\u003e\n",
    "stargazers_count": 4,
    "subscribers_count": 1,
    "topics": [
      "science",
      "astronomy",
      "distributed-systems",
      "machine-learning",
      "citizen-science",
      "open-source",
      "python"
    ],
    "updated_at": 1622312948.0
  },
  {
    "data_format": 2,
    "description": "definition files and wrapper scripts used by NIH HPC staff to install user-facing apps on the Biowulf cluster",
    "filenames": [
      "molecular-modeling-graphics/blender/2.82/blender.def",
      "molecular-modeling-graphics/starseqr/0.6.7/starseqr.def",
      "molecular-modeling-graphics/chimerax/1.1/chimerax.def",
      "molecular-modeling-graphics/chimerax/0.93/chimerax.def",
      "systems-biology/cellphonedb/2.1.7/cellphonedb.def",
      "systems-biology/cellphonedb/2.1.2/cellphonedb.def",
      "sequence-analysis/cicero/1.4.0/cicero.def",
      "sequence-analysis/roary/3.13.0/roary.def",
      "sequence-analysis/roary/3.12.0/roary.def",
      "sequence-analysis/arriba/2.0.0/arriba.def",
      "sequence-analysis/arriba/1.2.0/arriba.def",
      "sequence-analysis/xhla/2018-04-04/xhla.def",
      "sequence-analysis/qtltools/1.3.1/qtltools.def",
      "sequence-analysis/glu/1.0b3/glu.def",
      "sequence-analysis/annogesic/1.0.2/annogesic.def",
      "sequence-analysis/focus/0.6.10/focus.def",
      "sequence-analysis/wisexome/20180814/wisexome.def",
      "sequence-analysis/anvio/7/anvio.def",
      "sequence-analysis/cactus/1.2.3/cactus.def",
      "sequence-analysis/bamgineer/2-20200624/bamgineer.def",
      "sequence-analysis/svtools/0.5.1/svtools.def",
      "sequence-analysis/phaser/1.1.1/phaser.def",
      "sequence-analysis/accurity/20210209/accurity.def",
      "sequence-analysis/accurity/20180724/accurity.def",
      "sequence-analysis/sonicparanoid/1.3.5/sonicparanoid.def",
      "sequence-analysis/sonicparanoid/1.3.2/sonicparanoid.def",
      "sequence-analysis/orffinder/0.4.3-sing-install/orffinder.def",
      "sequence-analysis/vcf-kit/0.1.6/vcf-kit.def",
      "sequence-analysis/smoove/0.2.5/smoove.def",
      "sequence-analysis/smoove/0.2.1/smoove.def",
      "sequence-analysis/m-tools/20210208/m-tools.def",
      "sequence-analysis/eukrep/20180308/eukrep.def",
      "sequence-analysis/asgal/1.0/asgal.def",
      "sequence-analysis/netoglyc/3.1d/netoglyc.def",
      "sequence-analysis/saige/0.44.1/saige.def",
      "sequence-analysis/intarna/3.2.0/intarna.def",
      "sequence-analysis/chipseq_pipeline/1.2.0/chipseq_pipeline.def",
      "sequence-analysis/mmarge/1.0/mmarge.def",
      "sequence-analysis/acfs/20180316/acfs.def",
      "sequence-analysis/ldsc/3d0c4464/ldsc.def",
      "sequence-analysis/deepsea/0.94c/deepsea.def",
      "sequence-analysis/braker/2/braker.def",
      "sequence-analysis/prokka/1.13/prokka.def",
      "sequence-analysis/prokka/1.14.6/prokka.def",
      "sequence-analysis/htgtsrep/9fe74ff/htgtsrep.def",
      "sequence-analysis/glnexus/1.1.11/glnexus.def",
      "sequence-analysis/glnexus/1.2.7/glnexus.def",
      "sequence-analysis/augustus/3.3.3/augustus.def",
      "image-analysis/terastitcher/1.11.10/terastitcher.def",
      "image-analysis/terastitcher/1.10.8/terastitcher.def",
      "image-analysis/mrtrix/3.0.2-cuda9.1/mrtrix.def",
      "image-analysis/mrtrix/3.0.1/mrtrix.def",
      "image-analysis/mrtrix/3.0.0/mrtrix.def",
      "image-analysis/mriqc/0.16.1/mriqc.def",
      "image-analysis/mriqc/0.15.1/mriqc.def",
      "image-analysis/mriqc/0.15.2/mriqc.def",
      "image-analysis/mriqc/0.15.2-0be03bf/mriqc.def",
      "image-analysis/xcpengine/1.2.1/xcpengine.def",
      "image-analysis/xcpengine/1.0/xcpengine.def",
      "image-analysis/xcpengine/1.2.3/xcpengine.def",
      "image-analysis/tesseract/4.1.1/tesseract.def",
      "image-analysis/civet/2.1.1/civet.def",
      "image-analysis/topaz/0.2.5/topaz.def",
      "image-analysis/deepmedic/0.8.0/deepmedic.def",
      "image-analysis/deepmedic/0.8.2/deepmedic.def",
      "image-analysis/broccoli/1.0.1/broccoli.def",
      "image-analysis/qsiprep/0.8.0/qsiprep.def",
      "image-analysis/fitlins/0.8.0/fitlins.def",
      "image-analysis/fitlins/0.7.0/fitlins.def",
      "image-analysis/minc-toolkit/1.9.16/minc-toolkit.def",
      "image-analysis/minc-toolkit/1.9.18/minc-toolkit.def",
      "image-analysis/resmap/1.95/resmap.def",
      "image-analysis/fmriprep/20.2.1/fmriprep.def",
      "image-analysis/fmriprep/20.0.5/fmriprep.def",
      "image-analysis/fmriprep/20.1.1/fmriprep.def",
      "image-analysis/fmriprep/20.1.3/fmriprep.def",
      "image-analysis/fmriprep/20.2.0/fmriprep.def",
      "image-analysis/baracus/1.1.4/baracus.def",
      "computational-chemistry/ampl/f35623d4/ampl.def",
      "mass-spectrometry/maxquant/1.6.17.0/maxquant.def",
      "mass-spectrometry/maxquant/1.6.3.3/maxquant.def",
      "mass-spectrometry/maxquant/1.6.7.0/maxquant.def",
      "utilities/sysbench/1.0.11/sysbench.def",
      "utilities/sysbench/1.0.20/sysbench.def",
      "utilities/uropa/3.5.0/uropa.def",
      "utilities/pyega3/3.3.0/pyega3.def",
      "utilities/whatshap/0.18/whatshap.def",
      "utilities/snp-sites/2.4.1/snp-sites.def",
      "utilities/gdc-client/1.5.0/gdc-client.def",
      "utilities/datalad/0.13.0rc2/datalad.def",
      "utilities/visidata/2.2/visidata.def",
      "utilities/ariba/2.14.4/ariba.def",
      "utilities/atom/1.13.1/atom.def",
      "utilities/xvfb/1.19.6/xvfb.def",
      "utilities/longshot/0.3.5/longshot.def",
      "utilities/pdf2svg/0.2.3/pdf2svg.def",
      "utilities/vcf2db/2020.09.14/vcf2db.def",
      "high-throughput-sequencing/pepr/1.1.24/pepr.def",
      "high-throughput-sequencing/cicero/0.3.0/cicero.def",
      "high-throughput-sequencing/deepsignal/0.1.8/deepsignal.def",
      "high-throughput-sequencing/bamutil/1.0.15/bamutil.def",
      "high-throughput-sequencing/vagrent/3.3.4/vagrent.def",
      "high-throughput-sequencing/metaphlan/3.0/metaphlan.def",
      "high-throughput-sequencing/metaphlan/3.0.6/metaphlan.def",
      "high-throughput-sequencing/hap.py/0.3.9/hap.py.def",
      "high-throughput-sequencing/rilseq/0.75/rilseq.def",
      "high-throughput-sequencing/tetoolkit/2.2.1/tetoolkit.def",
      "high-throughput-sequencing/tetoolkit/2.1.4/tetoolkit.def",
      "high-throughput-sequencing/ascatngs/4.3.4/ascatngs.def",
      "high-throughput-sequencing/ascatngs/4.3.3/ascatngs.def",
      "high-throughput-sequencing/ascatngs/4.5.0/ascatngs.def",
      "high-throughput-sequencing/htseq/0.11.4/htseq.def",
      "high-throughput-sequencing/metabat/2.13/metabat.def",
      "high-throughput-sequencing/atropos/1.1.18/atropos.def",
      "high-throughput-sequencing/epic2/0.0.41/epic2.def",
      "high-throughput-sequencing/deeptools/3.4.2/deeptools.def",
      "high-throughput-sequencing/deeptools/3.5.0/deeptools.def",
      "high-throughput-sequencing/vep/101/vep.def",
      "high-throughput-sequencing/vep/103/vep.def",
      "high-throughput-sequencing/vep/97/vep.def",
      "high-throughput-sequencing/atac_dnase_pipelines/0.3.4-19-gcbd2a00/atac_dnase_pipelines.def",
      "high-throughput-sequencing/sve/0.1.0/sve.def",
      "high-throughput-sequencing/sicer/2-1.0.2/sicer.def",
      "high-throughput-sequencing/salmon/1.4.0/salmon.def",
      "high-throughput-sequencing/dropest/0.8.6/dropest.def",
      "high-throughput-sequencing/tandemtools/current/tandemtools.def",
      "high-throughput-sequencing/multiqc/1.9/multiqc.def",
      "high-throughput-sequencing/multiqc/1.10/multiqc.def",
      "high-throughput-sequencing/svtk/0.1/svtk.def",
      "high-throughput-sequencing/ricopili/2019_Jun_25.001/ricopili.def",
      "high-throughput-sequencing/bison/0.4.0/bison.def",
      "high-throughput-sequencing/umitools/1.1.1/umitools.def",
      "high-throughput-sequencing/eager/1.92/eager.def",
      "high-throughput-sequencing/deepvariant/0.10.0/deepvariant.def",
      "high-throughput-sequencing/deepvariant/0.9.0/deepvariant.def",
      "high-throughput-sequencing/deepvariant/1.1.0/deepvariant.def",
      "high-throughput-sequencing/macs/2.2.7.1/macs.def",
      "high-throughput-sequencing/medaka/1.0.3/medaka.def",
      "high-throughput-sequencing/medaka/0.12.1/medaka.def",
      "high-throughput-sequencing/medaka/1.2.0/medaka.def",
      "high-throughput-sequencing/svtyper/0.7.1/svtyper.def",
      "high-throughput-sequencing/scramble/0.0.20190211.82c78b9/scramble.def",
      "high-throughput-sequencing/scramble/1.0.1-32893ef/scramble.def",
      "high-throughput-sequencing/parliament/0.1.7/parliament.def",
      "high-throughput-sequencing/cutadapt/3.0/cutadapt.def",
      "high-throughput-sequencing/cutadapt/2.10/cutadapt.def",
      "high-throughput-sequencing/cutadapt/1.18/cutadapt.def",
      "high-throughput-sequencing/abruijn/1.0/abruijn.def",
      "high-throughput-sequencing/canvas/1.40/canvas.def",
      "high-throughput-sequencing/seqlinkage/1.0/seqlinkage.def",
      "high-throughput-sequencing/gossamer/ac492a8/gossamer.def",
      "high-throughput-sequencing/hicexplorer/3.5.1/hicexplorer.def",
      "high-throughput-sequencing/hicpro/2.11.4/hicpro.def",
      "high-throughput-sequencing/pvactools/2.0.1/pvactools.def",
      "high-throughput-sequencing/pvactools/1.5.5/pvactools.def",
      "high-throughput-sequencing/mtoolbox/1.1/mtoolbox.def",
      "high-throughput-sequencing/bamsurgeon/1111e5d/bamsurgeon.def",
      "high-throughput-sequencing/gridss/2.9.4/gridss.def",
      "high-throughput-sequencing/bigscale2/20191119/bigscale2.def",
      "high-throughput-sequencing/xengsort/28762aac/xengsort.def",
      "high-throughput-sequencing/csvkit/1.0.5/csvkit.def",
      "high-throughput-sequencing/cnvkit/0.9.8/cnvkit.def",
      "high-throughput-sequencing/cnvkit/0.9.6/cnvkit.def",
      "high-throughput-sequencing/fusioninspector/2.5.0/fusioninspector.def",
      "high-throughput-sequencing/fusioninspector/2.3.0/fusioninspector.def",
      "high-throughput-sequencing/megalodon/2.2.9/megalodon.def",
      "high-throughput-sequencing/slamdunk/0.4.3/slamdunk.def",
      "high-throughput-sequencing/rsd/1.1.7/rsd.def",
      "high-throughput-sequencing/tvc/5.10.1/tvc.def",
      "high-throughput-sequencing/maggie/0.3.4/maggie.def",
      "high-throughput-sequencing/flye/2.8-1/flye.def",
      "high-throughput-sequencing/flye/2.7/flye.def",
      "high-throughput-sequencing/tpmcalculator/0.0.4/tpmcalculator.def",
      "high-throughput-sequencing/tpmcalculator/0.0.3/tpmcalculator.def",
      "high-throughput-sequencing/idep/0.81/idep.def",
      "high-throughput-sequencing/transvar/2.5.9/transvar.def",
      "high-throughput-sequencing/flappie/1.0.0/flappie.def",
      "high-throughput-sequencing/flappie/2.1.3/flappie.def",
      "high-throughput-sequencing/cellsnp/0.1.7/cellsnp.def",
      "high-throughput-sequencing/cellsnp/0.3.2/cellsnp.def",
      "high-throughput-sequencing/crossmap/0.5.2/crossmap.def",
      "high-throughput-sequencing/brass/6.3.4/brass.def",
      "high-throughput-sequencing/brass/6.1.2/brass.def",
      "high-throughput-sequencing/rseqc/4.0.0/rseqc.def",
      "high-throughput-sequencing/hail/0.2.61/hail.def",
      "high-throughput-sequencing/hail/0.2.56/hail.def",
      "high-throughput-sequencing/hail/0.2.3/hail.def",
      "high-throughput-sequencing/rmats/4.0.2/rmats.def",
      "high-throughput-sequencing/mitosuite/1.0.9b/mitosuite.def",
      "high-throughput-sequencing/taiji/1.1.0/taiji.def",
      "high-throughput-sequencing/taiji/1.2.0/taiji.def",
      "high-throughput-sequencing/humann2/2.8.1/humann2.def",
      "high-throughput-sequencing/vireosnp/0.5.1/vireosnp.def",
      "high-throughput-sequencing/vireosnp/0.3.2/vireosnp.def",
      "high-throughput-sequencing/cnvnator/0.4.1/cnvnator.def",
      "high-throughput-sequencing/delly/0.8.7/delly.def",
      "high-throughput-sequencing/mageck-vispr/0.5.4/mageck-vispr.def",
      "high-throughput-sequencing/guppy/4.2.2/guppy.def",
      "high-throughput-sequencing/guppy/3.4.5/guppy.def",
      "high-throughput-sequencing/guppy/4.0.15/guppy.def",
      "high-throughput-sequencing/cancerit-wgs/2.1.0/cancerit-wgs.def",
      "high-throughput-sequencing/repeatmodeler/2.0.1/repeatmodeler.def",
      "high-throughput-sequencing/surpi/1.0.67/surpi.def",
      "high-throughput-sequencing/bamliquidator/1.3.8/bamliquidator.def",
      "high-throughput-sequencing/neusomatic/0.2.1/neusomatic.def",
      "high-throughput-sequencing/rnapeg/current/rnapeg.def",
      "high-throughput-sequencing/biom-format/2.1.10/biom-format.def",
      "high-throughput-sequencing/pcap-core/4.3.5/pcap-core.def",
      "high-throughput-sequencing/humann/3.0.0-alpha.3/humann.def",
      "high-throughput-sequencing/crispresso/2.0.40/crispresso.def",
      "high-throughput-sequencing/crispresso/2.0.45/crispresso.def",
      "high-throughput-sequencing/busco/5.0.0/busco.def",
      "high-throughput-sequencing/busco/4.1.3/busco.def",
      "high-throughput-sequencing/bamreadcount/cram-v0.0.1/bamreadcount.def",
      "high-throughput-sequencing/lefse/1.0.8/lefse.def",
      "high-throughput-sequencing/lefse/1.0.7/lefse.def",
      "high-throughput-sequencing/cgpbattenberg/3.5.3/cgpbattenberg.def",
      "high-throughput-sequencing/pychopper/2.4.0/pychopper.def",
      "high-throughput-sequencing/freebayes/1.3.5/freebayes.def",
      "high-throughput-sequencing/raremetal/4.15.1/raremetal.def",
      "high-throughput-sequencing/stream/20180816/stream.def",
      "linkage-phylogenetics/bali-phy/3.5/bali-phy.def",
      "linkage-phylogenetics/gubbins/2.3.4/gubbins.def",
      "structural-biology/parsnip/20180507/parsnip.def",
      "structural-biology/rdock/2013.1/rdock.def",
      "structural-biology/pymol/2.4.0/pymol.def",
      "structural-biology/pymol/2.3.0/pymol_2.3.0.def",
      "deep-learning/basset/0.1.0/basset.def",
      "deep-learning/deeplab/20180816/deeplab.def",
      "deep-learning/caffe2/0.8.1/caffe2.def",
      "deep-learning/dextr-pytorch/20180710/dextr-pytorch.def",
      "deep-learning/tensorrt/18.09/tensorrt.def",
      "deep-learning/clairvoyante/1.0/clairvoyante.def",
      "deep-learning/polyrnnpp/20180718/polyrnnpp.def",
      "deep-learning/few-shot-ssl/20180723/few-shot-ssl.def",
      "deep-learning/digits/6.0/digits.def",
      "deep-learning/unet/20180704/unet.def",
      "mathematical-statistics/omeclust/1.1.4/omeclust.def",
      "mathematical-statistics/omeclust/1.1.6/omeclust.def",
      "mathematical-statistics/m2clust/1.1.3/m2clust.def",
      "mathematical-statistics/m2clust/0.0.7/m2clust.def",
      "mathematical-statistics/m2clust/0.0.8/m2clust.def"
    ],
    "full_name": "NIH-HPC/singularity-def-files",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-nih-hpc-singularity-definition-files\" class=\"anchor\" href=\"#nih-hpc-singularity-definition-files\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eNIH HPC Singularity Definition Files\u003c/h1\u003e\n\u003cp\u003eThese definition files and wrapper scripts are used by the \u003ca href=\"https://hpc.nih.gov/\" rel=\"nofollow\"\u003eNIH HPC (Biowulf)\u003c/a\u003e staff to install containerized applications using \u003ca href=\"https://github.com/sylabs/singularity\"\u003eSingularity\u003c/a\u003e. Each app is installed in a self-contained directory and access to the app is controlled through a module system (\u003ca href=\"https://github.com/TACC/Lmod\"\u003eLmod\u003c/a\u003e). This strategy allows users to transparently access apps that are installed within containers as though they were installed directly on the host system. More details can be found \u003ca href=\"https://hpc.nih.gov/apps/singularity.html#bind-stationary\" rel=\"nofollow\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eTypically, apps are installed under in a directory structure like so:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ tree appname/ver\nappname/ver\n|-- bin\n|   |-- cmd1 -\u0026gt; ../libexec/wrapper.sh\n|   |-- cmd2 -\u0026gt; ../libexec/wrapper.sh\n|   `-- cmd3 -\u0026gt; ../libexec/wrapper.sh\n`-- libexec\n    |-- app.sif\n    `-- wrapper.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBecause \u003ccode\u003ewrapper.sh\u003c/code\u003e is written to be introspective, any command symlinked to it will be carried through and executed within the associated container. The wrapper script is also sufficiently generic that it can be reused across apps with little or no modification.\u003c/p\u003e\n\u003cp\u003eEach app has its own \u003ccode\u003eREADME.md\u003c/code\u003e that contains:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ea link to the NIH HPC app page or developer\u0027s documentation\u003c/li\u003e\n\u003cli\u003ea list of symlinks that should be created to the wrapper script to expose executables within the container\u003c/li\u003e\n\u003cli\u003eany app specific installation notes\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFinally, please note that these definition files \u003cstrong\u003eare not guaranteed to reproduce the same container, or even to produce any container at all\u003c/strong\u003e. The internet, upon which these definition files are based, is subject to change without notice. These definition files are therefore intended to be treated as (potentially) helpful suggestions.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-computational-chemistry\" class=\"anchor\" href=\"#computational-chemistry\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"/computational-chemistry\"\u003eComputational Chemistry\u003c/a\u003e\n\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/computational-chemistry/ampl\"\u003eampl\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-deep-learning\" class=\"anchor\" href=\"#deep-learning\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"/deep-learning\"\u003eDeep Learning\u003c/a\u003e\n\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/deep-learning/caffe2\"\u003eCaffe2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/deep-learning/dextr-pytorch\"\u003eDEXTR-PyTorch\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/deep-learning/polyrnnpp\"\u003ePolyRNNpp\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/deep-learning/basset\"\u003ebasset\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/deep-learning/clairvoyante\"\u003eclairvoyante\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/deep-learning/deeplab\"\u003edeeplab\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/deep-learning/digits\"\u003edigits\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/deep-learning/few-shot-ssl\"\u003efew-shot-ssl\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/deep-learning/tensorrt\"\u003etensorrt\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/deep-learning/unet\"\u003eunet\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-high-throughput-sequencing\" class=\"anchor\" href=\"#high-throughput-sequencing\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"/high-throughput-sequencing\"\u003eHigh Throughput Sequencing\u003c/a\u003e\n\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/atac_dnase_pipelines\"\u003eATAC-Seq / DNase-Seq Pipeline\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/ascatngs\"\u003eAscatNGS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/atropos\"\u003eAtropos\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/bamsurgeon\"\u003eBAMSurgeon\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/brass\"\u003eBRASS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/canvas\"\u003eCanvas\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/maggie\"\u003eMAGGIE\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/pcap-core\"\u003ePCAP-core\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/pepr\"\u003ePePr\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/rsd\"\u003eRSD\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/surpi\"\u003eSURPI\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/tpmcalculator\"\u003eTPMCalculator\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/tvc\"\u003eTVC\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/vagrent\"\u003eVAGrENT\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/vep\"\u003eVEP\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/abruijn\"\u003eabruijn\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/bamliquidator\"\u003ebamliquidator\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/bamreadcount\"\u003ebamreadcount\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/bamutil\"\u003ebamutil\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/bigscale2\"\u003ebigscale2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/biom-format\"\u003ebiom-format\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/bison\"\u003ebison\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/busco\"\u003ebusco\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/cancerit-wgs\"\u003ecancerit-wgs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/cellsnp\"\u003ecellsnp\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/cgpbattenberg\"\u003ecgpBattenberg\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/cicero\"\u003ecicero\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/cnvkit\"\u003ecnvkit\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/cnvnator\"\u003ecnvnator\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/crispresso\"\u003ecrispresso\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/crossmap\"\u003ecrossmap\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/csvkit\"\u003ecsvkit\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/cutadapt\"\u003ecutadapt\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/deepsignal\"\u003edeepsignal\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/deeptools\"\u003edeeptools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/deepvariant\"\u003edeepvariant\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/delly\"\u003edelly\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/dropest\"\u003edropest\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/eager\"\u003eeager\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/epic2\"\u003eepic2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/flappie\"\u003eflappie\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/flye\"\u003eflye\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/freebayes\"\u003efreebayes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/fusioninspector\"\u003efusioninspector\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/gossamer\"\u003egossamer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/gridss\"\u003egridss\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/guppy\"\u003eguppy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/hail\"\u003ehail\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/hap.py\"\u003ehap.py\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/hicexplorer\"\u003ehicexplorer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/hicpro\"\u003ehicpro\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/htseq\"\u003ehtseq\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/humann2\"\u003ehumann2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/idep\"\u003eidep\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/lefse\"\u003elefse\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/macs\"\u003emacs\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/mageck-vispr\"\u003emageck-vispr\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/medaka\"\u003emedaka\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/megalodon\"\u003emegalodon\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/metabat\"\u003emetabat\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/metaphlan\"\u003emetaphlan\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/mitosuite\"\u003emitosuite\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/mtoolbox\"\u003emtoolbox\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/multiqc\"\u003emultiqc\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/neusomatic\"\u003eneusomatic\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/parliament\"\u003eparliament\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/pvactools\"\u003epvactools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/pychopper\"\u003epychopper\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/raremetal\"\u003eraremetal\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/repeatmodeler\"\u003erepeatmodeler\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/ricopili\"\u003ericopili\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/rilseq\"\u003erilseq\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/rmats\"\u003ermats\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/rnapeg\"\u003ernapeg\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/rseqc\"\u003erseqc\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/salmon\"\u003esalmon\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/scramble\"\u003escramble\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/seqlinkage\"\u003eseqlinkage\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/sicer\"\u003esicer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/slamdunk\"\u003eslamdunk\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/stream\"\u003estream\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/sve\"\u003esve\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/svtk\"\u003esvtk\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/svtyper\"\u003esvtyper\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/taiji\"\u003etaiji\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/tandemtools\"\u003etandemtools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/tetoolkit\"\u003etetoolkit\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/transvar\"\u003etransvar\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/umitools\"\u003eumitools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/vireosnp\"\u003evireosnp\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/high-throughput-sequencing/xengsort\"\u003exengsort\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-image-analysis\" class=\"anchor\" href=\"#image-analysis\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"/image-analysis\"\u003eImage Analysis\u003c/a\u003e\n\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/image-analysis/resmap\"\u003eResMap\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/image-analysis/terastitcher\"\u003eTeraStitcher\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/image-analysis/baracus\"\u003ebaracus\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/image-analysis/broccoli\"\u003ebroccoli\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/image-analysis/civet\"\u003ecivet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/image-analysis/ctf\"\u003ectf\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/image-analysis/deepmedic\"\u003edeepmedic\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/image-analysis/fitlins\"\u003efitlins\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/image-analysis/fmriprep\"\u003efmriprep\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/image-analysis/minc-toolkit\"\u003eminc-toolkit\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/image-analysis/mriqc\"\u003emriqc\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/image-analysis/mrtrix\"\u003emrtrix\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/image-analysis/qsiprep\"\u003eqsiprep\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/image-analysis/tesseract\"\u003etesseract\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/image-analysis/topaz\"\u003etopaz\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/image-analysis/xcpengine\"\u003excpengine\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-linkage-phylogenetics\" class=\"anchor\" href=\"#linkage-phylogenetics\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"/linkage-phylogenetics\"\u003eLinkage Phylogenetics\u003c/a\u003e\n\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/linkage-phylogenetics/bali-phy\"\u003ebali-phy\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/linkage-phylogenetics/gubbins\"\u003egubbins\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-mass-spectrometry\" class=\"anchor\" href=\"#mass-spectrometry\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"/mass-spectrometry\"\u003eMass Spectrometry\u003c/a\u003e\n\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/mass-spectrometry/maxquant\"\u003emaxquant\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-mathematicalstatistics\" class=\"anchor\" href=\"#mathematicalstatistics\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"/mathematical-statistics\"\u003eMathematical/Statistics\u003c/a\u003e\n\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/mathematical-statistics/m2clust\"\u003em2clust\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/mathematical-statistics/omeclust\"\u003eomeClust\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-molecular-modeling-graphics\" class=\"anchor\" href=\"#molecular-modeling-graphics\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"/molecular-modeling-graphics\"\u003eMolecular Modeling Graphics\u003c/a\u003e\n\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/molecular-modeling-graphics/chimerax\"\u003eChimeraX\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/molecular-modeling-graphics/blender\"\u003eblender\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/molecular-modeling-graphics/starseqr\"\u003estarseqr\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-sequence-analysis\" class=\"anchor\" href=\"#sequence-analysis\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"/sequence-analysis\"\u003eSequence Analysis\u003c/a\u003e\n\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/acfs\"\u003eACFS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/annogesic\"\u003eANNOgesic\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/asgal\"\u003eASGAL\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/accurity\"\u003eAccurity\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/eukrep\"\u003eEukRep\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/glu\"\u003eGLU\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/htgtsrep\"\u003eHTGTSrep\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/orffinder\"\u003eORFfinder\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/saige\"\u003eSAIGE\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/vcf-kit\"\u003eVCF-kit\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/anvio\"\u003eanvio\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/arriba\"\u003earriba\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/augustus\"\u003eaugustus\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/bamgineer\"\u003ebamgineer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/braker\"\u003ebraker\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/cactus\"\u003ecactus\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/chipseq_pipeline\"\u003echipseq_pipeline\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/cicero\"\u003ecicero\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/deepsea\"\u003edeepsea\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/focus\"\u003efocus\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/glnexus\"\u003eglnexus\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/intarna\"\u003eintarna\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/ldsc\"\u003eldsc\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/m-tools\"\u003em-tools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/mmarge\"\u003emmarge\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/netoglyc\"\u003enetOglyc\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/phaser\"\u003ephaser\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/prokka\"\u003eprokka\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/qtltools\"\u003eqtltools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/roary\"\u003eroary\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/smoove\"\u003esmoove\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/sonicparanoid\"\u003esonicparanoid\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/svtools\"\u003esvtools\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/wisexome\"\u003ewisexome\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sequence-analysis/xhla\"\u003exHLA\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-structural-biology\" class=\"anchor\" href=\"#structural-biology\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"/structural-biology\"\u003eStructural Biology\u003c/a\u003e\n\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/structural-biology/parsnip\"\u003eparsnip\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/structural-biology/pymol\"\u003epymol\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/structural-biology/rdock\"\u003erDock\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-systems-biology\" class=\"anchor\" href=\"#systems-biology\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"/systems-biology\"\u003eSystems Biology\u003c/a\u003e\n\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/systems-biology/cellphonedb\"\u003ecellphonedb\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-utilities\" class=\"anchor\" href=\"#utilities\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"/utilities\"\u003eUtilities\u003c/a\u003e\n\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/utilities/xvfb\"\u003eXvfb\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/utilities/ariba\"\u003eariba\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/utilities/atom\"\u003eatom\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/utilities/datalad\"\u003edatalad\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/utilities/gdc-client\"\u003egdc-client\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/utilities/longshot\"\u003elongshot\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/utilities/pdf2svg\"\u003epdf2svg\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/utilities/pyega3\"\u003epyega3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/utilities/snp-sites\"\u003esnp-sites\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/utilities/sysbench\"\u003esysbench\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/utilities/uropa\"\u003europa\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/utilities/vcf2db\"\u003evcf2db\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/utilities/visidata\"\u003evisidata\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/utilities/whatshap\"\u003ewhatshap\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 8,
    "subscribers_count": 6,
    "topics": [],
    "updated_at": 1622586137.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "container/Singularity.intel_netcdf",
      "container/Singularity.intel_am4",
      "container/Singularity.gnu"
    ],
    "full_name": "NOAA-GFDL/AM4",
    "latest_release": "2021.02",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-gfdl-am4-model\" class=\"anchor\" href=\"#gfdl-am4-model\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGFDL AM4 Model\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://zenodo.org/badge/latestdoi/102487636\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/878db836b9000fd7d9ff531257cade7343f3a3fdf8f764b5a7f1e8ef6ccc6abe/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3130323438373633362e737667\" alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/102487636.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThis repository includes the public release of the GFDL AM4 model\ncode.  The AM4 model is described in the\n\u003ca href=\"https://doi.org/10.1002/2017MS001208\" rel=\"nofollow\"\u003etwo\u003c/a\u003e\n\u003ca href=\"https://doi.org/10.1002/2017MS001209\" rel=\"nofollow\"\u003earticles\u003c/a\u003e published in the\n\u003ca href=\"https://agupubs.onlinelibrary.wiley.com/journal/19422466\" rel=\"nofollow\"\u003eJournal of Advances in Modeling Earth Systems\n(JAMES)\u003c/a\u003e.\nMore information on the model and access to the output is available on\nthe \u003ca href=\"http://data1.gfdl.noaa.gov/nomads/forms/am4.0/\" rel=\"nofollow\"\u003eAM4 data and code\nsite\u003c/a\u003e at the\n\u003ca href=\"https://www.gfdl.noaa.gov\" rel=\"nofollow\"\u003eGeophysical Fluid Dynamics Laboratory\n(GFDL)\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe layout of this package includes the following directories:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003esrc - The source code for the AM4 model\u003c/li\u003e\n\u003cli\u003eexec - The build directory with Makefiles for building the model executable\u003c/li\u003e\n\u003cli\u003erun - Sample run script and updated files needed for running\u003c/li\u003e\n\u003cli\u003eanalysis - Sample analysis scripts\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-cloning-instructions\" class=\"anchor\" href=\"#cloning-instructions\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCloning Instructions\u003c/h2\u003e\n\u003cp\u003eThis repository uses \u003ca href=\"https://git-scm.com/book/en/v2/Git-Tools-Submodules\" rel=\"nofollow\"\u003egit\nsubmodules\u003c/a\u003e to\npoint to other repositories.  Thus, care should be taken when cloning,\nand updating the source to ensure all source.  To obtain all source,\nuse the following git command\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone --recursive https://github.com/NOAA-GFDL/AM4.git\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003e--recursive\u003c/code\u003e option to \u003ccode\u003egit clone\u003c/code\u003e instructs git to recursively\nclone all submodules.  In the event the repository was not cloned\nusing the \u003ccode\u003e--recursive\u003c/code\u003e option, the following step must be taken to\nobtain all sources:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# From within the AM4 parent directory\ngit submodule update --init --recursive\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-source-code\" class=\"anchor\" href=\"#source-code\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSource Code\u003c/h2\u003e\n\u003cp\u003eAll model source is contained in the \u003ca href=\"src\"\u003esrc\u003c/a\u003e directory.  GFDL\ntracks code using the git version control system.  This package\nincludes a single version of the following GFDL model components.  The\ngit hash listed corresponds to the commit hash in the internal GFDL\ngit repository.\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eComponent\u003c/th\u003e\n\u003cth\u003eCommit Hash\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eatmos_drivers\u003c/td\u003e\n\u003ctd\u003e5ee95d6abf0879594551dd7e6635dff4004c4010\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eatmos_param\u003c/td\u003e\n\u003ctd\u003e2e94acfd8621e85216bf822c395a8c3f15a511a5\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eatmos_shared\u003c/td\u003e\n\u003ctd\u003ea557d4d7bab033ef1ad1d400a62fe07a97ccb477\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eice_param\u003c/td\u003e\n\u003ctd\u003e1553c8bc4f9a66791c89367b6f327147523155ed\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eice_sis\u003c/td\u003e\n\u003ctd\u003eccc7328dcd79706dd5c17c8bab660222886fc80b\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eland_lad2\u003c/td\u003e\n\u003ctd\u003ea220288ecb289bf9d793d051fc5076072874ce07\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eThe following components are available in the\n\u003ca href=\"https://github.com/NOAA-GFDL\"\u003eNOAA-GFDL\u003c/a\u003e github organization:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-GFDL/MOM6\"\u003eMOM6\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-GFDL/coupler\"\u003ecoupler\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/NOAA-GFDL/FMS\"\u003eFMS\u003c/a\u003e (as \u003ca href=\"src/shared\"\u003eshared\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/NOAA-GFDL/GFDL_atmos_cubed_sphere\"\u003eGFDL_atmos_cubed_sphere (tag AM4.0)\u003c/a\u003e (as \u003ca href=\"src/atmos_cubed_sphere\"\u003eatmos_cubed_sphere\u003c/a\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-building-am4\" class=\"anchor\" href=\"#building-am4\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding AM4\u003c/h2\u003e\n\u003cp\u003eThe \u003ca href=\"exec\"\u003eexec\u003c/a\u003e directory contains Makefiles that can be used to\nbuild the AM4 executable.  These Makefiles were generated using the\n\u003ca href=\"https://github.com/NOAA-GFDL/mkmf\"\u003eMake Makefile (mkmf)\u003c/a\u003e program.\nIncluded in the exec direcgtory is a sample make template file for the\nIntel compilers (\u003ca href=\"exec/templates/intel.mk\"\u003eintel.mk\u003c/a\u003e).  This make\ntemplate can be used on any system with a relatively recent version of\nthe Intel compilers, the netCDF 4 library and the MPICH2 MPI library.\nIncluded in the \u003ca href=\"exec/templates/intel.mk\"\u003eintel.mk\u003c/a\u003e file are\nadditional settings that can be modified during the build.\u003c/p\u003e\n\u003cp\u003eTo run the default build (-O3 -msse2), go to the exec directory and\nenter the command\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emake\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf you would like to change some of the compiler options, there are several different\noptions to add to the make command.  For example\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emake ISA=-xhost BLD_TYPE=REPRO\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ewill replace -msse with -xhost and -O3 with -O2.  The three options for\n\u003ccode\u003eBLD_TYPE\u003c/code\u003e are\u003cbr\u003e\n\u003ccode\u003ePROD\u003c/code\u003e (-O3)\u003cbr\u003e\n\u003ccode\u003eREPRO\u003c/code\u003e (-O2)\u003cbr\u003e\n\u003ccode\u003eDEBUG\u003c/code\u003e (-O0 and other traps)\u003cbr\u003e\nAll of the make line options can be\nfound in the \u003ca href=\"exec/templates/intel.mk\"\u003eintel.mk\u003c/a\u003e file.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-obtaining-the-input-data\" class=\"anchor\" href=\"#obtaining-the-input-data\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eObtaining the input data\u003c/h2\u003e\n\u003cp\u003eThe input data required for running the AM4 model can be found on\n\u003ca href=\"http://data1.gfdl.noaa.gov/nomads/forms/am4.0/\" rel=\"nofollow\"\u003eGFDL\u0027s data\nportal\u003c/a\u003e .\u003c/p\u003e\n\u003cp\u003eThe file \u003ccode\u003eAM4.tar.gz\u003c/code\u003e contains a configured run directory to run a\nsample experiment of the AM4 model.  Included in the tar file is a\nREADME.AM4_run with more instructions on how to configure the AM4 run\ndirectory.\u003c/p\u003e\n\u003cp\u003eOn Linux systems, the \u003ccode\u003ewget\u003c/code\u003e command is usually sufficient to download the data\nfile:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ewget ftp://nomads.gfdl.noaa.gov/users/Ming.Zhao/AM4Documentation/GFDL-AM4.0/inputData/AM4_run.tar.gz\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo ensure the file downloaded is complete and not corrupted, download one of the two files:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ewget ftp://nomads.gfdl.noaa.gov/users/Ming.Zhao/AM4Documentation/GFDL-AM4.0/inputData/AM4_run.tar.gz.sha256\nwget ftp://nomads.gfdl.noaa.gov/users/Ming.Zhao/AM4Documentation/GFDL-AM4.0/inputData/AM4_run.tar.gz.sig\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eand run the following command that corresponds to the signature file downloaded:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esha256sum -c AM4_run.tar.gz.sha256\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003egpg --verify AM4_run.tar.gz.sig\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-running-am4\" class=\"anchor\" href=\"#running-am4\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning AM4\u003c/h2\u003e\n\u003cp\u003eIncluded in the run directory is a sample run script for reference.\nTo run the AM4 sample experiment, first download the data file\nmentioned in \u003ca href=\"#obtaining-the-input-data\"\u003eObtaining the Input data\u003c/a\u003e\nsection.  Replace diag_table and input.nml in the top level of the\nuntar\u0027d directory with the corresponding files in the run directory\nof this repository. Modify the variables in the configuration section\nin the sample run script, and then run the script.\u003c/p\u003e\n\u003cp\u003eThe sample data and run script are configured to run on 216\nprocessors.  To run on a different number of processors, or modify the\nexperiment, refer to the \u003ccode\u003eREADME.AM4_run\u003c/code\u003e file included in the AM4\ndata tarball.\u003c/p\u003e\n\u003cp\u003eNote: The \u003ccode\u003einput.nml\u003c/code\u003e file (found in the AM4 data tarball) contains\nFortran namelists and namelist variables that modify, at run time, the\nmodel.  To learn more about the settings in the \u003ccode\u003einput.nml\u003c/code\u003e file,\nplease refer to source code where the namelist/variable are defined.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-analysis-scripts\" class=\"anchor\" href=\"#analysis-scripts\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAnalysis Scripts\u003c/h2\u003e\n\u003cp\u003eSome of the climate analysis scripts run at NOAA GFDL and used in the\nAM4 documentation papers are located in the analysis directory.\nWithin each analysis suite, is a \u003ca href=\"https://jupyter-notebook.readthedocs.io/en/stable/\" rel=\"nofollow\"\u003ejupyter\nnotebook\u003c/a\u003e, both\nreadable and runnable from your local jupyter environment, provided\nall dependencies are installed.\u003c/p\u003e\n\u003cp\u003eE.g.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"analysis/cjs1/radiation_atmos_av_mon/radiation_atmos_av_mon.ipynb\"\u003eRadiation processor\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"analysis/bw/bw_atmos_cru_ts_a1r/bw_atmos_monthly_cru_ts.1980-2014.ipynb\"\u003eLong-term DJF seasonal mean\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"analysis/bw/bw_atmos_zm_atl_pac_a1r/bw_atmos_atl_pac.1980-2014.ipynb\"\u003eZonal_mean_zonal_wind_stress\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"analysis/pcmdimetrics/portraitPlot-AM4.AMIP.ipynb\"\u003ePCMDI Metrics Portrait Plot\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-model-output-and-other-references\" class=\"anchor\" href=\"#model-output-and-other-references\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eModel output and Other References\u003c/h2\u003e\n\u003cp\u003ePlease refer to the \u003ca href=\"http://data1.gfdl.noaa.gov/nomads/forms/am4.0/\" rel=\"nofollow\"\u003eAM4 data and code\nsite\u003c/a\u003e for details\nabout where to find model and OBS data used in the papers.\u003c/p\u003e\n\u003cp\u003eFor all analysis figures and pertaining data, please use the AM4\ndocumentation papers as the original reference.\u003c/p\u003e\n\u003cp\u003ePlease direct your questions and feedback to\n\u003ca href=\"mailto:gfdl.climate.model.info@noaa.gov\"\u003egfdl.climate.model.info@noaa.gov\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-disclaimer\" class=\"anchor\" href=\"#disclaimer\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDisclaimer\u003c/h2\u003e\n\u003cp\u003eThe United States Department of Commerce (DOC) GitHub project code is\nprovided on an \u0027as is\u0027 basis and the user assumes responsibility for\nits use.  DOC has relinquished control of the information and no\nlonger has responsibility to protect the integrity, confidentiality,\nor availability of the information.  Any claims against the Department\nof Commerce stemming from the use of its GitHub project will be\ngoverned by all applicable Federal law.  Any reference to specific\ncommercial products, processes, or services by service mark,\ntrademark, manufacturer, or otherwise, does not constitute or imply\ntheir endorsement, recommendation or favoring by the Department of\nCommerce.  The Department of Commerce seal and logo, or the seal and\nlogo of a DOC bureau, shall not be used in any manner to imply\nendorsement of any commercial product or activity by DOC or the United\nStates Government.\u003c/p\u003e\n\u003cp\u003eThis project code is made available through GitHub but is managed by\nNOAA-GFDL at \u003ca href=\"https://gitlab.gfdl.noaa.gov\" rel=\"nofollow\"\u003ehttps://gitlab.gfdl.noaa.gov\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 9,
    "subscribers_count": 6,
    "topics": [
      "fortran",
      "jupyter-notebook",
      "shell-script",
      "ncl"
    ],
    "updated_at": 1622048423.0
  },
  {
    "data_format": 2,
    "description": "Scripts for building Singularity images",
    "filenames": [
      "tensorflow/ubuntu.def",
      "mxnet/ubuntu.def",
      "caffe2/ubuntu.def",
      "dl/ubuntu.def",
      "circuitscape/ubuntu.def",
      "caffe/ubuntu.def"
    ],
    "full_name": "clemsonciti/singularity-images",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularity-image-scripts\" class=\"anchor\" href=\"#singularity-image-scripts\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSingularity image scripts\u003c/h1\u003e\n\u003cp\u003eScripts to generate singularity images\nfor running different software on Palmetto cluster.\u003c/p\u003e\n",
    "stargazers_count": 10,
    "subscribers_count": 5,
    "topics": [],
    "updated_at": 1597386388.0
  },
  {
    "data_format": 2,
    "description": "PEMA: a flexible Pipeline for Environmental DNA Metabarcoding Analysis of the 16S/18S rRNA, ITS and COI marker genes",
    "filenames": [
      "Singularity",
      "singularity/Singularity.latest",
      "singularity/Singularity.v.1.3.1",
      "singularity/Singularity.v.2.0.3",
      "singularity/Singularity.v.1.1",
      "singularity/Singularity.v.2.1.0",
      "singularity/Singularity.v.2.0.2",
      "singularity/Singularity.v.2.1.3",
      "singularity/Singularity.v.1.3",
      "singularity/Singularity.v.1.3.2"
    ],
    "full_name": "hariszaf/pema",
    "latest_release": "v1.2",
    "readme": "\u003cp align=\"center\"\u003e\n  \u003ca href=\"https://camo.githubusercontent.com/762c1129f266494bbbb3faff3d673040cf7b1f19d45c6e13f49b08de12f5116a/68747470733a2f2f692e70617374652e706963732f38373031383966616466363638613935386338616163383366333865373939632e706e67\" target=\"_blank\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/762c1129f266494bbbb3faff3d673040cf7b1f19d45c6e13f49b08de12f5116a/68747470733a2f2f692e70617374652e706963732f38373031383966616466363638613935386338616163383366333865373939632e706e67\" width=\"300\" align=\"left\" data-canonical-src=\"https://i.paste.pics/870189fadf668a958c8aac83f38e799c.png\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-pema\" class=\"anchor\" href=\"#pema\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePEMA:\u003c/h1\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-a-flexible-pipeline-for-environmental-dna-metabarcoding-analysis-of-the-16s18s-rrna-its-and-coi-marker-genes\" class=\"anchor\" href=\"#a-flexible-pipeline-for-environmental-dna-metabarcoding-analysis-of-the-16s18s-rrna-its-and-coi-marker-genes\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ea flexible Pipeline for Environmental DNA Metabarcoding Analysis of the 16S/18S rRNA, ITS and COI marker genes\u003c/h2\u003e\n\u003cp\u003e\u003cem\u003ePEMA is reposited in\u003c/em\u003e \u003ca href=\"https://hub.docker.com/r/hariszaf/pema\" rel=\"nofollow\"\u003e\u003cem\u003eDocker Hub\u003c/em\u003e\u003c/a\u003e \u003cem\u003eas well as in\u003c/em\u003e \u003ca href=\"https://singularity-hub.org/collections/2295\" rel=\"nofollow\"\u003e\u003cem\u003eSingularity Hub\u003c/em\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-a-pema-tutorial-can-be-found-here\" class=\"anchor\" href=\"#a-pema-tutorial-can-be-found-here\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eA PEMA tutorial can be found \u003ca href=\"https://docs.google.com/presentation/d/1lVH23DPa2NDNBhVvOTRoip8mraw8zfw8VQwbK4vkB1U/edit?fbclid=IwAR14PpWfPtxB8lLBBnoxs7UbG3IJfkArrJBS5f2kRA__kvGDUb8wiJ2Cy_s#slide=id.g57f092f54d_1_21\" rel=\"nofollow\"\u003e\u003cstrong\u003ehere\u003c/strong\u003e\u003c/a\u003e.\u003c/h4\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-for-any-troubles-you-may-have-when-running-pema-or-for-any-potential-improvevments-you-would-like-to-suggest-please-share-on-the-pema-gitter-community\" class=\"anchor\" href=\"#for-any-troubles-you-may-have-when-running-pema-or-for-any-potential-improvevments-you-would-like-to-suggest-please-share-on-the-pema-gitter-community\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFor any troubles you may have when running PEMA or for any potential improvevments you would like to suggest, please share on the \u003ca href=\"https://gitter.im/pema-helpdesk/community\" rel=\"nofollow\"\u003ePEMA Gitter community\u003c/a\u003e.\u003c/h4\u003e\n\n\u003cp\u003e\u003ca href=\"https://gitter.im/pema-helpdesk/community?utm_source=badge\u0026amp;utm_medium=badge\u0026amp;utm_campaign=pr-badge\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7385c04b449351f12fb57a4bd6f9791ebd68a483493399e50a8f096fadde4246/68747470733a2f2f6261646765732e6769747465722e696d2f70656d612d68656c706465736b2f636f6d6d756e6974792e737667\" alt=\"Gitter\" data-canonical-src=\"https://badges.gitter.im/pema-helpdesk/community.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.gnu.org/licenses/gpl-3.0\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/400c4e52df43f6a0ab8a89b74b1a78d1a64da56a7848b9110c9d2991bb7c3105/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d47504c76332d626c75652e737667\" alt=\"License: GPL v3\" data-canonical-src=\"https://img.shields.io/badge/License-GPLv3-blue.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-table-of-contents\" class=\"anchor\" href=\"#table-of-contents\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTable of Contents\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#pema-biodiversity-in-all-its-different-levels\"\u003ePEMA: biodiversity in all its different levels\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#a-container-based-tool\"\u003e A container-based tool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#how-to-run-pema\"\u003eHow to run PEMA\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#parameters-file\"\u003eParameters\u0027 file\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#pema-on-hpc\"\u003ePEMA on HPC\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#prerequisites-1\"\u003ePrerequisites\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#installing-1\"\u003eInstalling\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#running-pema-1\"\u003eRunning PEMA\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#example\"\u003eExample\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#pema-on-a-simple-pc\"\u003ePEMA on a simple PC\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#prerequisites\"\u003ePrerequisites\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#installing\"\u003eInstalling\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#running-pema\"\u003eRunning PEMA\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#step-1---build-a-docker-container\"\u003eStep 1 - Build a Docker container\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#step-2---run-pema\"\u003eStep 2 - Run PEMA\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#the-phyloseq-r-package\"\u003ephyloseq - for a downstream ecological analysis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#acknowledgments\"\u003eAcknowledgments\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#license\"\u003eLicense\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#citation\"\u003eCitation\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight highlight-source-diff\"\u003e\u003cpre\u003e\u003cspan class=\"pl-mi1\"\u003e\u003cspan class=\"pl-mi1\"\u003e+\u003c/span\u003e convertion of the Illumina raw data is now implemented in the framework of PEMA\u003c/span\u003e\n\u003cspan class=\"pl-mi1\"\u003e\u003cspan class=\"pl-mi1\"\u003e+\u003c/span\u003e PEMA now supports 2 extra marker genes, 18S rRNA and ITS. \u003c/span\u003e\n\u003cspan class=\"pl-mi1\"\u003e\u003cspan class=\"pl-mi1\"\u003e+\u003c/span\u003e PEMA is now available for macOS!\u003c/span\u003e\n\u003cspan class=\"pl-mi1\"\u003e\u003cspan class=\"pl-mi1\"\u003e+\u003c/span\u003e for anything feel free to contact me at: haris-zaf@hcmr.gr\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\n\u003ch1\u003e\n\u003ca id=\"user-content-pema-biodiversity-in-all-its-different-levels\" class=\"anchor\" href=\"#pema-biodiversity-in-all-its-different-levels\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePEMA: biodiversity in all its different levels\u003c/h1\u003e\n\u003cp\u003ePEMA supports the metabarcoding analysis of four marker genes, \u003cstrong\u003e16S rRNA\u003c/strong\u003e (Bacteria), \u003cstrong\u003eITS\u003c/strong\u003e (Fungi) as well as \u003cstrong\u003eCOI\u003c/strong\u003e and \u003cstrong\u003e18S rRNA\u003c/strong\u003e (metazoa). As input, PEMA accepts .fastq.gz files as returned by Illumina sequencing platforms.\u003c/p\u003e\n\u003cp\u003ePEMA processes the reads from each sample and \u003cstrong\u003ereturns an OTU- or an ASV-table with the taxonomies\u003c/strong\u003e of the taxa found and their abundances in each sample. It also returns statistics and a FASTQC diagram about the quality of the reads for each sample. Finally, PEMA supports \u003cstrong\u003edownstream ecological analysis\u003c/strong\u003e of the profiles retrieved, facilitated by the \u003ca href=\"http://joey711.github.io/phyloseq/index.html\" rel=\"nofollow\"\u003ephyloseq\u003c/a\u003e R package.\u003c/p\u003e\n\u003cp\u003ePEMA supports both OTU clustering (thanks to VSEARCH and CROP algorithms) and ASV inference (via SWARM) for all four marker genes.\u003c/p\u003e\n\u003cp\u003eFor the case of the 16S rRNA marker gene, PEMA includes two separate approaches for taxonomy assignment: alignment-based and phylogenetic-based. For the latter, a reference tree of 1000 taxa was created using SILVA_132_SSURef, EPA-ng and RaxML-ng.\u003c/p\u003e\n\u003cp\u003ePEMA has been implemented in \u003ca href=\"https://pcingola.github.io/BigDataScript/\" rel=\"nofollow\"\u003eBigDataScript\u003c/a\u003e programming language. BDS\u2019s ad hoc task parallelism and task synchronization, supports heavyweight computation. Thus, PEMA inherits such features and it also supports roll-back checkpoints and on-demand partial pipeline execution. In addition, PEMA takes advantage of all the computational power available on a specific machine; for example, if PEMA is executed on a personal laptop with 4 cores, it is going to use all four of them.\u003c/p\u003e\n\u003cp\u003eFinally, container-based technologies such as Docker and Singularity, make PEMA easy accessible for all operating systems.\nAs you can see in the \u003ca href=\"https://github.com/hariszaf/pema/blob/master/help_files/GitHub%20tutorial.pdf\"\u003ePEMA_tutorial.pdf\u003c/a\u003e, once you have either Docker or Singularity on your computational environment (see below which suits your case better), running PEMA is cakewalk. You can also find the \u003ca href=\"https://docs.google.com/presentation/d/1lVH23DPa2NDNBhVvOTRoip8mraw8zfw8VQwbK4vkB1U/edit?usp=sharing\" rel=\"nofollow\"\u003e\u003cstrong\u003ePEMA tutorial\u003c/strong\u003e\u003c/a\u003e as a Google Slides file.\u003c/p\u003e\n\n\u003ch1\u003e\n\u003ca id=\"user-content-a-container-based-tool\" class=\"anchor\" href=\"#a-container-based-tool\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eA container-based tool\u003c/h1\u003e\n\u003cp\u003ePEMA can run either on a HPC environment (server, cluster etc) or on a simple PC. However, we definitely suggest to run it on an HPC environment to exploit the full potential of PEMA. Running on a powerful server or a cluster can be time-saving since it would require significantly less computational time than in a common PC. However, for analyses with a small number of samples, a common PC can suffice.\u003c/p\u003e\n\u003cp\u003eThere is one \u003cstrong\u003emajor difference\u003c/strong\u003e between running PEMA on a common PC than running it on a HPC environment. In the first case, PEMA runs through \u003ca href=\"https://www.docker.com/\" rel=\"nofollow\"\u003e\u003cstrong\u003eDocker\u003c/strong\u003e\u003c/a\u003e, while in the latter one, it runs through \u003ca href=\"https://sylabs.io/singularity/\" rel=\"nofollow\"\u003e\u003cstrong\u003eSingularity\u003c/strong\u003e\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eOn the following chapters, you can find how to install PEMA both in Docker and Singlularity including examples.\u003c/p\u003e\n\u003cp\u003eRunning PEMA is exactly \u003cstrong\u003ethe same\u003c/strong\u003e procedure in both of those cases.\u003c/p\u003e\n\n\u003ch2\u003e\n\u003ca id=\"user-content-how-to-run-pema\" class=\"anchor\" href=\"#how-to-run-pema\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow to run PEMA\u003c/h2\u003e\n\u003cp\u003eAssuming you have either Docker or Singularity on your system (see below how to get them).\nYou need to create a directory where you will have everything PEMA needs - we will call it \u003cem\u003e\u003cstrong\u003eanalysis directory\u003c/strong\u003e\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eIn this directory, you need to add the following \u003cstrong\u003emandatory\u003c/strong\u003e files:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ethe \u003ca href=\"https://github.com/hariszaf/pema/blob/master/analysis_directory/parameters.tsv\"\u003e\u003cem\u003e\u003cstrong\u003eparameters.tsv\u003c/strong\u003e\u003c/em\u003e\u003c/a\u003e file (you can download it from this repository and then \u003cstrong\u003ecomplete it\u003c/strong\u003e according to the needs of your analysis)\u003c/li\u003e\n\u003cli\u003ea subdirectory called \u003cem\u003e\u003cstrong\u003emydata\u003c/strong\u003e\u003c/em\u003e where your .fastq.gz files will be located \u003cbr\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf your need to perform phyloseq, in the analysis directory you also need to add the following \u003cstrong\u003eoptionally\u003c/strong\u003e files:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ethe \u003ca href=\"https://github.com/hariszaf/pema/blob/master/analysis_directory/phyloseq_in_PEMA.R\"\u003e\u003cem\u003e\u003cstrong\u003ephyloseq_in_PEMA.R\u003c/strong\u003e\u003c/em\u003e\u003c/a\u003e which you can also download from this repository and set it the way you want (that is an R script which we have implemented and has some main features that need to stay always the same in order to be executed as part of PEMA and some parts where the user can set what exactly needs to get from the phyloseq package)\u003c/li\u003e\n\u003cli\u003ethe \u003ca href=\"https://raw.githubusercontent.com/hariszaf/pema/master/analysis_directory/metadata.csv\" rel=\"nofollow\"\u003e\u003cem\u003e\u003cstrong\u003emetadata.csv\u003c/strong\u003e\u003c/em\u003e\u003c/a\u003e file which has to be in a \u003cstrong\u003ecomma separated\u003c/strong\u003e format (you can find an example of this file on PEMA\u0027s GitHub repository).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-attention--\" class=\"anchor\" href=\"#attention--\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003cstrong\u003eAttention!\u003c/strong\u003e  \u003cbr\u003e\n\u003c/h3\u003e\n\u003cp\u003ePEMA will \u003cstrong\u003efail\u003c/strong\u003e unless you name the aforementioned files and directories \u003cstrong\u003eexactly\u003c/strong\u003e as described above.\n\u003cbr\u003e\u003c/p\u003e\n\u003cp\u003eHere is an example of how your \u003cem\u003eanalysis directory\u003c/em\u003e should be in case you do want a phyloseq analysis:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003euser@home-PC:~/Desktop/analysis_directory$ ls\nmydata  parameters.tsv  phyloseq_in_PEMA.R  metadata.csv\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eand in case you do not:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003euser@home-PC:~/Desktop/analysis_directory$ ls\nmydata  parameters.tsv \n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/hariszaf/pema/tree/master/analysis_directory\"\u003e\u003cstrong\u003eHere\u003c/strong\u003e\u003c/a\u003e you can find an example of an \u003cem\u003eanalysis directory\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eAfter you have prepared this \u003cem\u003eanalysis directory\u003c/em\u003e you are ready to run PEMA (see below).\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAn extended list with PEMA\u0027s ouput can be found \u003ca href=\"https://github.com/hariszaf/pema/blob/master/help_files/PEMA\u0027s%20output%20files.md\"\u003e\u003cstrong\u003ehere\u003c/strong\u003e\u003c/a\u003e.\u003c/strong\u003e\u003c/p\u003e\n\n\u003ch1\u003e\n\u003ca id=\"user-content-parameters-file\" class=\"anchor\" href=\"#parameters-file\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eParameters\u0027 file\u003c/h1\u003e\n\u003cp\u003eThe most crucial component in running PEMA is the parameters file. This file must be located \u003cstrong\u003ein\u003c/strong\u003e the \u003cem\u003eanalysis directory\u003c/em\u003e and the user needs to fill it \u003cstrong\u003eevery time\u003c/strong\u003e PEMA is about to be called. If you need more than one analyses to run, then you need to make copies of the parameters\u0027 file and have one of those in eah of the analysis directrories you create.\u003c/p\u003e\n\u003cp\u003eSo, here is the \u003ca href=\"https://github.com/hariszaf/pema/blob/master/analysis_directory/parameters.tsv\"\u003e\u003cem\u003e\u003cstrong\u003eparameters.tsv\u003c/strong\u003e\u003c/em\u003e\u003c/a\u003e file as it looks like, in a study case of our own.\u003c/p\u003e\n\n\u003ch1\u003e\n\u003ca id=\"user-content-pema-on-hpc\" class=\"anchor\" href=\"#pema-on-hpc\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePEMA on HPC\u003c/h1\u003e\n\u003cp\u003ePEMA is best to run on HPC (server, cluster, cloud). Usually environmental data are quite large and the whole process has huge computational demands. To get PEMA running on your HPC you (actually your system administrator) need to install Singularity as described below.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-prerequisites\" class=\"anchor\" href=\"#prerequisites\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePrerequisites\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca href=\"https://www.sylabs.io/guides/3.0/user-guide/quick_start.html#quick-installation-steps\" rel=\"nofollow\"\u003eSingularity\u003c/a\u003e\u003c/strong\u003e  is a free, cross-platform and open-source computer program that performs operating-system-level virtualization also known as containerization. One of the main uses of Singularity is to bring containers and reproducibility to scientific computing and the high-performance computing (HPC) world.\u003c/p\u003e\n\u003cp\u003eSingularity needs a Linux/Unix system to run.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-installing\" class=\"anchor\" href=\"#installing\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstalling\u003c/h2\u003e\n\u003cp\u003eAfter you install Singularity in your environment and open it, you need to download PEMA\u0027s image from Singularity Hub, by running the command:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e singularity pull shub://hariszaf/pema:v.1.1\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow you have PEMA on your environment. But there is still one really \u003cstrong\u003eimportant\u003c/strong\u003e thing that you need to do! Please \u003cstrong\u003edownload\u003c/strong\u003e the \u003ca href=\"https://github.com/hariszaf/pema/blob/master/analysis_directory/parameters.tsv\"\u003e\u003cem\u003eparameters.tsv\u003c/em\u003e\u003c/a\u003e file and move it or copy it to the same directory with your raw data.\u003c/p\u003e\n\u003cp\u003eNow you are ready to go!\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-running-pema\" class=\"anchor\" href=\"#running-pema\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning PEMA\u003c/h2\u003e\n\u003cp\u003eSingularity permits the use of a job scheduler that allocates computional resources on clusters and at the same time, works as a queuing system, as \u003cstrong\u003e\u003ca href=\"https://slurm.schedmd.com/overview.html\" rel=\"nofollow\"\u003eSlurm\u003c/a\u003e\u003c/strong\u003e. This way you are able to create a job as you usually do in your system and after editing the parameters file as needed, run PEMA as a job on your cluster.\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-example\" class=\"anchor\" href=\"#example\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eExample\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e#SBATCH --partition=batch\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=20\n#SBATCH --mem=\n# Memory per node specification is in MB. It is optional.\n# The default limit is 3000MB per core.\n#SBATCH --job-name=\"testPema\"\n#SBATCH --output=PEMA.output\n#SBATCH --mail-user=haris-zafr@hcmr.gr\n#SBATCH --mail-type=ALL\n#SBATCH --requeue\n\n\nsingularity run -B /\u0026lt;path\u0026gt;/\u0026lt;of\u0026gt;/\u0026lt;input\u0026gt;/\u0026lt;directory\u0026gt;/:/mnt/analysis /\u0026lt;path\u0026gt;/\u0026lt;of\u0026gt;/\u0026lt;PEMA_container\u0026gt;\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn the above example, we set the cluster \"Zorba\", to run PEMA in 1 node, with 20 cores.\u003c/p\u003e\n\u003cp\u003eFor further information, you can always check \u003ca href=\"https://docs.google.com/presentation/d/1lVH23DPa2NDNBhVvOTRoip8mraw8zfw8VQwbK4vkB1U/edit?fbclid=IwAR14PpWfPtxB8lLBBnoxs7UbG3IJfkArrJBS5f2kRA__kvGDUb8wiJ2Cy_s#slide=id.g57f092f54d_1_21\" rel=\"nofollow\"\u003ePEMA\u0027s tutorial\u003c/a\u003e.\u003c/p\u003e\n\n\u003ch1\u003e\n\u003ca id=\"user-content-pema-on-a-simple-pc\" class=\"anchor\" href=\"#pema-on-a-simple-pc\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePEMA on a simple PC\u003c/h1\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-prerequisites-1\" class=\"anchor\" href=\"#prerequisites-1\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePrerequisites\u003c/h2\u003e\n\u003cp\u003eTo run PEMA in a simple PC on your own environment, you first need to install \u003ca href=\"https://docs.docker.com/install/\" rel=\"nofollow\"\u003eDocker\u003c/a\u003e, in case you do not already have it.\u003c/p\u003e\n\u003cp\u003eYou should check your software version. A version of Docker is avalable for all Windows, Mac and Linux. If you have Windows 10 Pro or your Mac\u0027s hardware in after 2010, then you can insall Docker straightforward. Otherwise, you need to install the \u003ca href=\"https://docs.docker.com/toolbox/\" rel=\"nofollow\"\u003eDocker toolbox\u003c/a\u003e instead. You can check if your System Requirements are according to the ones mentioned below in order to be sure what you need to do.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSystem Requirements\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e**__Windows 10 64bit__**:\nPro, Enterprise or Education (1607 Anniversary Update, Build 14393 or later).\nVirtualization is enabled in BIOS. Typically, virtualization is enabled by default.\nThis is different from having Hyper-V enabled. For more detail see Virtualization must be enabled in Troubleshooting.\nCPU SLAT-capable feature.\nAt least 4GB of RAM.\n\n**__Mac__**\nMac hardware must be a 2010 or newer model, with Intel\u2019s hardware support for memory management unit (MMU)\nvirtualization, including Extended Page Tables (EPT) and Unrestricted Mode. You can check to see if your machine\nhas this support by running the following command in a terminal:\nsysctl kern.hv_support macOS El Capitan 10.11 and newer macOS releases are supported.\nWe recommend upgrading to the latest version of macOS.\nAt least 4GB of RAM\nVirtualBox prior to version 4.3.30 must NOT be installed (it is incompatible with Docker for Mac).\nIf you have a newer version of VirtualBox installed, it\u2019s fine.\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-installing-1\" class=\"anchor\" href=\"#installing-1\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstalling\u003c/h2\u003e\n\u003cp\u003eAfter you install Docker in your environment and run it, the only thing you need to do, is to download PEMA\u0027s image, by running the command:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edocker pull hariszaf/pema\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe PEMA image file is a quite large (~3Gb), so it will take a while until it is downloaded in your computer system.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-running-pema-1\" class=\"anchor\" href=\"#running-pema-1\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning PEMA\u003c/h2\u003e\n\u003cp\u003eRunning PEMA has two discrete steps.\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-step-1---build-a-docker-container\" class=\"anchor\" href=\"#step-1---build-a-docker-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eStep 1 - Build a Docker container\u003c/h3\u003e\n\u003cp\u003eAt first, you need to let Docker have access in your dataset. To provide access you need to run the following command and specifying the path to where your data is stored, i.e. changing the \u0026lt;path_to_analysis_directory\u0026gt; accordingly:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edocker run -it -v /\u0026lt;path_to_analysis_directory\u0026gt;/:/mnt/analysis hariszaf/pema\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAfter you run the command above, you have now built a Docker container, in which you can run PEMA!\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-step-2---run-pema\" class=\"anchor\" href=\"#step-2---run-pema\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eStep 2 - Run PEMA\u003c/h3\u003e\n\u003cp\u003eNow, being inside the PEMA container, the only thing remaining to do, is to run PEMA\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e./PEMA_v1.bds\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ePEMA is now running. The runtime of PEMA depends on the computational features of your environment, on the size of your data, as well as the parameters you chose.\u003c/p\u003e\n\u003cp\u003ePlease, keep in mind that when you need to copy a whole directory, then you always have to put \"/\" in the end of the path that describes where the directory is located.\u003c/p\u003e\n\u003cp\u003eFinally, you will find the PEMA output in the analysis directory on your computer. \u003cbr\u003e\nAs the output directory is mounted into the built Docker container, you can copy its contents wherever you want. However, in case you want to remove it permanently, you need to do this as a sudo user.\u003c/p\u003e\n\n\u003ch1\u003e\n\u003ca id=\"user-content-the-phyloseq-r-package\" class=\"anchor\" href=\"#the-phyloseq-r-package\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eThe \"phyloseq\" R package\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003efor a downstream ecological analysis of OTUs/ASVs retrieved\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003ePEMA performs all the basic functions of the \"phyloseq\" R package. In addition, it performs certain functions of the \u003ca href=\"https://cran.r-project.org/web/packages/vegan/index.html\" rel=\"nofollow\"\u003e\u003cem\u003e\u003cstrong\u003evegan\u003c/strong\u003e\u003c/em\u003e\u003c/a\u003e R package.\u003c/p\u003e\n\u003cp\u003eWhen the user asks for a downstream analysis using the \"phyloseq\" R package, then an extra input file called \u003ca href=\"https://github.com/hariszaf/pema/blob/master/analysis_directory/phyloseq_in_PEMA.R\"\u003e\u003cem\u003e\u003cstrong\u003e\"phyloseq_script.R\"\u003c/strong\u003e\u003c/em\u003e\u003c/a\u003e needs to be imported in the \"analysis_directory\". In PEMA\u0027s main repository, you can find a template of this file; this file needs to be as it would run on your own computer, as you would run \u003cem\u003ephyloseq\u003c/em\u003e in any case. PEMA will create the \u003cem\u003e\"phyloseq object\"\u003c/em\u003e automatically and then it will perform the analysis as asked. The output will be placed in an extra subfolder in the main output directory of PEMA called \u003cem\u003ephyloseq_analysis\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eIn addition, the \u003cem\u003e\u003cstrong\u003emetadata.tsv\u003c/strong\u003e\u003c/em\u003e file is also required when the phyloseq option has been selected. An example of this file you can find \u003ca href=\"https://raw.githubusercontent.com/hariszaf/pema/master/analysis_directory/metadata.csv\" rel=\"nofollow\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-acknowledgments\" class=\"anchor\" href=\"#acknowledgments\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAcknowledgments\u003c/h1\u003e\n\u003cp\u003ePEMA uses a series of tools, datasets as well as Big Data Script language. We thank all the groups that developed them.\nThe tools \u0026amp; databases that PEMA uses are:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBigDataScript programming language - \u003ca href=\"https://pcingola.github.io/BigDataScript/\" rel=\"nofollow\"\u003ehttps://pcingola.github.io/BigDataScript/\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eFASTQC - \u003ca href=\"https://www.bioinformatics.babraham.ac.uk/projects/fastqc/\" rel=\"nofollow\"\u003ehttps://www.bioinformatics.babraham.ac.uk/projects/fastqc/\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\u03a4rimmomatic - \u003ca href=\"http://www.usadellab.org/cms/?page=trimmomatic\" rel=\"nofollow\"\u003ehttp://www.usadellab.org/cms/?page=trimmomatic\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eCutadapt - \u003ca href=\"https://cutadapt.readthedocs.io/en/stable/\" rel=\"nofollow\"\u003ehttps://cutadapt.readthedocs.io/en/stable/\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eBayesHammer - included in SPAdes - \u003ca href=\"http://cab.spbu.ru/software/spades/\" rel=\"nofollow\"\u003ehttp://cab.spbu.ru/software/spades/\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003ePANDAseq - \u003ca href=\"https://github.com/neufeld/pandaseq\"\u003ehttps://github.com/neufeld/pandaseq\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eOBITools - \u003ca href=\"https://pythonhosted.org/OBITools/welcome.html\" rel=\"nofollow\"\u003ehttps://pythonhosted.org/OBITools/welcome.html\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eBLAST Command Line Applications - \u003ca href=\"https://www.ncbi.nlm.nih.gov/books/NBK52640/\" rel=\"nofollow\"\u003ehttps://www.ncbi.nlm.nih.gov/books/NBK52640/\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eVSEARCH-2.9.1 - \u003ca href=\"https://github.com/torognes/vsearch/releases/tag/v2.9.1\"\u003ehttps://github.com/torognes/vsearch/releases/tag/v2.9.1\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eSWARM - \u003ca href=\"https://github.com/torognes/swarm\"\u003ehttps://github.com/torognes/swarm\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eCROP - \u003ca href=\"https://github.com/tingchenlab/CROP\"\u003ehttps://github.com/tingchenlab/CROP\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eCREST - \u003ca href=\"https://github.com/lanzen/CREST\"\u003ehttps://github.com/lanzen/CREST\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eRDPClassifier - \u003ca href=\"https://github.com/rdpstaff/classifier\"\u003ehttps://github.com/rdpstaff/classifier\u003c/a\u003e\n(RPDtools are required in order to execute RDPClassifier)\u003c/li\u003e\n\u003cli\u003eSILVA db - \u003ca href=\"https://www.arb-silva.de/no_cache/download/archive/current/Exports/\" rel=\"nofollow\"\u003ehttps://www.arb-silva.de/no_cache/download/archive/current/Exports/\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eMIDORI db - \u003ca href=\"http://reference-midori.info/index.html\" rel=\"nofollow\"\u003ehttp://reference-midori.info/index.html\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\"phat\" algorithm, from the \"gappa\" package - \u003ca href=\"https://github.com/lczech/gappa/wiki/Subcommand:-phat\"\u003ehttps://github.com/lczech/gappa/wiki/Subcommand:-phat\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eMAFFT - \u003ca href=\"https://mafft.cbrc.jp/alignment/software/\" rel=\"nofollow\"\u003ehttps://mafft.cbrc.jp/alignment/software/\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eRAxML -ng - \u003ca href=\"https://github.com/amkozlov/raxml-ng\"\u003ehttps://github.com/amkozlov/raxml-ng\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003ePaPaRa - \u003ca href=\"https://cme.h-its.org/exelixis/web/software/papara/index.html\" rel=\"nofollow\"\u003ehttps://cme.h-its.org/exelixis/web/software/papara/index.html\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eEPA-ng - \u003ca href=\"https://github.com/Pbdas/epa-ng\"\u003ehttps://github.com/Pbdas/epa-ng\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003ephyloseq R package - \u003ca href=\"http://joey711.github.io/phyloseq/index.html\" rel=\"nofollow\"\u003ehttp://joey711.github.io/phyloseq/index.html\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003evegan R package - \u003ca href=\"https://cran.r-project.org/web/packages/vegan/index.html\" rel=\"nofollow\"\u003ehttps://cran.r-project.org/web/packages/vegan/index.html\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAnd of course the container-based technologies:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDocker - \u003ca href=\"https://www.docker.com/\" rel=\"nofollow\"\u003ehttps://www.docker.com/\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eSingularity - \u003ca href=\"https://sylabs.io/singularity/\" rel=\"nofollow\"\u003ehttps://sylabs.io/singularity/\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLicense\u003c/h1\u003e\n\u003cp\u003ePEMA is under the GNU GPLv3 license (for 3rd party components separate licenses apply).\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-citation\" class=\"anchor\" href=\"#citation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCitation\u003c/h1\u003e\n\u003cp\u003eHaris Zafeiropoulos, Ha Quoc Viet, Katerina Vasileiadou, Antonis Potirakis, Christos Arvanitidis, Pantelis Topalis, Christina Pavloudi, Evangelos Pafilis, PEMA: a flexible Pipeline for Environmental DNA Metabarcoding Analysis of the 16S/18S ribosomal RNA, ITS, and COI marker genes, GigaScience, Volume 9, Issue 3, March 2020, giaa022, \u003ca href=\"https://doi.org/10.1093/gigascience/giaa022\" rel=\"nofollow\"\u003ehttps://doi.org/10.1093/gigascience/giaa022\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD\u003c/p\u003e\n\n\u003cp\u003e=======\u003c/p\u003e\n \n\u003cblockquote\u003e\n\u003cblockquote\u003e\n\u003cblockquote\u003e\n\u003cblockquote\u003e\n\u003cblockquote\u003e\n\u003cblockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003erearchitecturing\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003c/blockquote\u003e\n\u003c/blockquote\u003e\n\u003c/blockquote\u003e\n\u003c/blockquote\u003e\n\u003c/blockquote\u003e\n\u003c/blockquote\u003e\n",
    "stargazers_count": 12,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1622303297.0
  },
  {
    "data_format": 2,
    "description": "R in a Singularity container",
    "filenames": [
      "Singularity",
      "Singularity.3.6.2"
    ],
    "full_name": "nickjer/singularity-r",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularity-r\" class=\"anchor\" href=\"#singularity-r\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSingularity R\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://travis-ci.org/nickjer/singularity-r\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/67e2d6deb1aeb1e18fbd9d72b2bdb73c7ab12099a81313d76bea0546cdfdb1c6/68747470733a2f2f7472617669732d63692e6f72672f6e69636b6a65722f73696e67756c61726974792d722e7376673f6272616e63683d6d6173746572\" alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/nickjer/singularity-r.svg?branch=master\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://singularity-hub.org/collections/462\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a07b23d4880320ac89cdc93bbbb603fa84c215d135e05dd227ba8633a9ff34be/68747470733a2f2f7777772e73696e67756c61726974792d6875622e6f72672f7374617469632f696d672f686f737465642d73696e67756c61726974792d2d6875622d2532336533323932392e737667\" alt=\"Singularity Hub\" data-canonical-src=\"https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/45b4ffbd594af47fe09a3432f9f8e122c6518aa6352b4ce453a1a2563da2905c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d677265656e2e737667\" alt=\"GitHub License\" data-canonical-src=\"https://img.shields.io/badge/license-MIT-green.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSingularity image for \u003ca href=\"https://www.r-project.org/\" rel=\"nofollow\"\u003eR\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThis is still a work in progress.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-build\" class=\"anchor\" href=\"#build\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuild\u003c/h2\u003e\n\u003cp\u003eYou can build a local Singularity image named \u003ccode\u003esingularity-r.simg\u003c/code\u003e with:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003esudo singularity build singularity-r.simg Singularity\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-deploy\" class=\"anchor\" href=\"#deploy\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDeploy\u003c/h2\u003e\n\u003cp\u003eInstead of building it yourself you can download the pre-built image from\n\u003ca href=\"https://www.singularity-hub.org\" rel=\"nofollow\"\u003eSingularity Hub\u003c/a\u003e with:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003esingularity pull --name singularity-r.simg shub://nickjer/singularity-r\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-run\" class=\"anchor\" href=\"#run\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRun\u003c/h2\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-r\" class=\"anchor\" href=\"#r\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eR\u003c/h3\u003e\n\u003cp\u003eThe \u003ccode\u003eR\u003c/code\u003e command is launched using the default run command:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003esingularity run singularity-r.simg\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eor as an explicit app:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003esingularity run --app R singularity-r.simg\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eExample:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003esingularity run --app R singularity-r.simg --version\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eR version 3.4.3 (2017-11-30) -- \"Kite-Eating Tree\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eCopyright (C) 2017 The R Foundation for Statistical Computing\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ePlatform: x86_64-pc-linux-gnu (64-bit)\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003eR is free software and comes with ABSOLUTELY NO WARRANTY.\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eYou are welcome to redistribute it under the terms of the\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eGNU General Public License versions 2 or 3.\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eFor more information about these matters see\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ehttp://www.gnu.org/licenses/.\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-rscript\" class=\"anchor\" href=\"#rscript\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRscript\u003c/h3\u003e\n\u003cp\u003eThe \u003ccode\u003eRscript\u003c/code\u003e command is launched as an explicit app:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003esingularity run --app Rscript singularity-r.simg\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eExample:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003esingularity run --app Rscript singularity-r.simg --version\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eR scripting front-end version 3.4.3 (2017-11-30)\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-contributing\" class=\"anchor\" href=\"#contributing\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContributing\u003c/h2\u003e\n\u003cp\u003eBug reports and pull requests are welcome on GitHub at\n\u003ca href=\"https://github.com/nickjer/singularity-r\"\u003ehttps://github.com/nickjer/singularity-r\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLicense\u003c/h2\u003e\n\u003cp\u003eThe code is available as open source under the terms of the \u003ca href=\"http://opensource.org/licenses/MIT\" rel=\"nofollow\"\u003eMIT License\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 12,
    "subscribers_count": 2,
    "topics": [
      "r",
      "singularity-image"
    ],
    "updated_at": 1617151072.0
  },
  {
    "data_format": 2,
    "description": "Intel HPC Containers using Singularity",
    "filenames": [
      "definitionFiles/WRF/wrfRun.def",
      "definitionFiles/WRF/wrfBuild.def",
      "definitionFiles/gromacs/gromacsBuild.def",
      "definitionFiles/gromacs/gromacsRun.def",
      "definitionFiles/namd/namdBuild.def",
      "definitionFiles/namd/namdRun.def",
      "definitionFiles/lammps/lammpsRun.def",
      "definitionFiles/lammps/lammpsBuild.def",
      "definitionFiles/base/base.def"
    ],
    "full_name": "intel/HPC-containers-from-Intel",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-goal\" class=\"anchor\" href=\"#goal\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGoal:\u003c/h1\u003e\n\u003cp\u003eCreate containers using Singularity definition file for HPC apps and run them on the cloud or bare metal for Single and Cluster runs.\u003c/p\u003e\n\u003cp\u003eThis repo should have definition files only for few HPC applications. Users can utilize them to generate containers.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-get-help\" class=\"anchor\" href=\"#get-help\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGet Help\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/intel/HPC-containers-from-Intel/issues\"\u003ePost an issue\u003c/a\u003e if you face any problem building or running a container\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 16,
    "subscribers_count": 9,
    "topics": [
      "hpc",
      "cluster",
      "singularity-containers",
      "cloud"
    ],
    "updated_at": 1619711561.0
  },
  {
    "data_format": 2,
    "description": "From annotated genomes to metabolic screening in large scale microbiotas",
    "filenames": [
      "recipes/Singularity"
    ],
    "full_name": "AuReMe/metage2metabo",
    "latest_release": "1.5.0",
    "readme": "\u003cp\u003e\u003ca href=\"https://pypi.org/project/Metage2Metabo/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/68c19eb988f7da820e489e7d773438373c65af075fe846cb90e18836a7d7f9d4/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6d6574616765326d657461626f2e737667\" alt=\"PyPI version\" data-canonical-src=\"https://img.shields.io/pypi/v/metage2metabo.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/AuReMe/metage2metabo/blob/master/LICENSE\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fccd34831109fd6bdad80ef75ccdd11796acfad9808526a620456def8d9d9352/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f417552654d652f6d6574616765326d657461626f2e737667\" alt=\"GitHub license\" data-canonical-src=\"https://img.shields.io/github/license/AuReMe/metage2metabo.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/AuReMe/metage2metabo/actions\"\u003e\u003cimg src=\"https://github.com/AuReMe/metage2metabo/workflows/Python%20package/badge.svg\" alt=\"Actions Status\" style=\"max-width:100%;\"\u003e\u003c/a\u003e \u003ca href=\"https://metage2metabo.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/88095555c8fdcf3d56ae1cc3261918958b072a5308cc1d5113522bc284afd1b3/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6d6574616765326d657461626f2f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/metage2metabo/badge/?version=latest\" style=\"max-width:100%;\"\u003e\u003c/a\u003e \u003ca href=\"https://doi.org/10.7554/eLife.61968\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9e55e07ba04fd05d5e7a35a3dadc73af2472409b8403497e7056fb037f5e7875/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f692d31302e373535342f654c6966652e36313936382d626c756576696f6c65742e737667\" alt=\"\" data-canonical-src=\"https://img.shields.io/badge/doi-10.7554/eLife.61968-blueviolet.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-m2m---metage2metabo\" class=\"anchor\" href=\"#m2m---metage2metabo\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eM2M - metage2metabo\u003c/h1\u003e\n\u003cp\u003eMetage2metabo is a Python3 (Python \u0026gt;= 3.6, tested with 3.6 and 3.7) tool to perform graph-based metabolic analysis starting from annotated genomes (\u003cstrong\u003ereference genomes or metagenome-assembled genomes\u003c/strong\u003e). It uses \u003cem\u003ePathway Tools\u003c/em\u003e in a automatic and parallel way to \u003cstrong\u003ereconstruct metabolic networks\u003c/strong\u003e for a large number of genomes. The obtained metabolic networks are then \u003cstrong\u003eanalyzed individually and collectively\u003c/strong\u003e in order to get the \u003cstrong\u003eadded value of metabolic cooperation in microbiota over individual metabolism\u003c/strong\u003e and to \u003cstrong\u003eidentify and screen interesting organisms\u003c/strong\u003e among all.\u003c/p\u003e\n\u003cp\u003em2m can be used as a whole workflow (\u003ccode\u003em2m workflow\u003c/code\u003e, \u003ccode\u003em2m metacom\u003c/code\u003e) or steps can be performed individually (\u003ccode\u003em2m recon\u003c/code\u003e , \u003ccode\u003em2m iscope\u003c/code\u003e , \u003ccode\u003em2m cscope\u003c/code\u003e, \u003ccode\u003em2m addedvalue\u003c/code\u003e, \u003ccode\u003em2m mincom\u003c/code\u003e, \u003ccode\u003em2m seeds\u003c/code\u003e).\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eIf you use M2M, please cite\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eBelcour* A, Frioux* C, Aite M, Bretaudeau A, Hildebrand F, Siegel A. Metage2Metabo, microbiota-scale metabolic complementarity for the identification of key species. eLife 2020;9:e61968 \u003ca href=\"https://doi.org/10.7554/eLife.61968\" rel=\"nofollow\"\u003ehttps://doi.org/10.7554/eLife.61968\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eFor a summary of M2M and its applications, you can take a look at these \u003ca href=\"https://hal.inria.fr/hal-03151934/document\" rel=\"nofollow\"\u003eposter-slides\u003c/a\u003e, presented during the \u003ca href=\"https://jobim2020.sciencesconf.org/?forward-action=index\u0026amp;forward-controller=index\u0026amp;lang=en\" rel=\"nofollow\"\u003eJOBIM 2020 conference\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-table-of-contents\" class=\"anchor\" href=\"#table-of-contents\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTable of contents\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"#m2m---metage2metabo\"\u003eM2M - metage2metabo\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#table-of-contents\"\u003eTable of contents\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#general-information-about-the-modelling\"\u003eGeneral information about the modelling\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#license\"\u003eLicense\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#documentation\"\u003eDocumentation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#technologies\"\u003eTechnologies\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#requirements\"\u003eRequirements\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#installation\"\u003eInstallation\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#installation-with-pip\"\u003eInstallation with pip\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#availability-on-docker-and-singularity\"\u003eAvailability on Docker and Singularity\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#m2m-commands\"\u003eM2M commands\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#analysis-of-the-minimal-solutions\"\u003eAnalysis of the minimal solutions\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#release-notes\"\u003eRelease Notes\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#additional-features\"\u003eAdditional features\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#citation\"\u003eCitation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#article-data\"\u003eArticle data\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#authors\"\u003eAuthors\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#acknowledgement\"\u003eAcknowledgement\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-general-information-about-the-modelling\" class=\"anchor\" href=\"#general-information-about-the-modelling\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGeneral information about the modelling\u003c/h2\u003e\n\u003cp\u003eM2M has two main dependencies for modelling metabolic networks: \u003ca href=\"https://github.com/cfrioux/MeneTools\"\u003eMeneTools\u003c/a\u003e and \u003ca href=\"https://github.com/cfrioux/miscoto\"\u003eMiscoto\u003c/a\u003e. Accordingly metabolic models in M2M follow the producibility in metabolic networks as defined by the \u003ca href=\"http://www.ncbi.nlm.nih.gov/pubmed/15712108\" rel=\"nofollow\"\u003enetwork expansion\u003c/a\u003e algorithm.\nMainly, two rules are followed:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ea \u003cem\u003erecursive rule\u003c/em\u003e: the products of a reactions are producible if \u003cstrong\u003eall\u003c/strong\u003e reactants of this reaction are themselves producible\u003c/li\u003e\n\u003cli\u003ean \u003cem\u003einitiation rule\u003c/em\u003e: producibility is initiated by the presence of nutrients, called \u003cem\u003eseeds\u003c/em\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eA metabolite that is producible from a set of nutrients is described as being \"in the scope of the seeds\".\nThe computation is made using logic solvers (Answer Set Programming). The present modelling ignores the stoichiometry of reactions (2A + B --\u0026gt; C is considered equivalent to A + B --\u0026gt; C), and is therefore suited to non-curated or draft metabolic networks, as the ones built using M2M with the PathoLogic software of \u003ca href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5036846/pdf/bbv079.pdf\" rel=\"nofollow\"\u003ePathway Tools\u003c/a\u003e handled by \u003ca href=\"https://github.com/AuReMe/mpwt\"\u003eMpwt\u003c/a\u003e. Many works have relied on network expansion to study organisms (\u003ca href=\"http://doi.wiley.com/10.1111/tpj.12627\" rel=\"nofollow\"\u003ehere\u003c/a\u003e, \u003ca href=\"https://dx.plos.org/10.1371/journal.pcbi.1000049\" rel=\"nofollow\"\u003ehere\u003c/a\u003e or \u003ca href=\"http://dx.plos.org/10.1371/journal.pcbi.1005276\" rel=\"nofollow\"\u003ethere\u003c/a\u003e) and communities (\u003ca href=\"https://academic.oup.com/bioinformatics/article/34/17/i934/5093211\" rel=\"nofollow\"\u003ehere\u003c/a\u003e, \u003ca href=\"https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-4786-7\" rel=\"nofollow\"\u003ehere\u003c/a\u003e, or \u003ca href=\"https://www.ncbi.nlm.nih.gov/pubmed/18546499\" rel=\"nofollow\"\u003ehere\u003c/a\u003e). It has been \u003ca href=\"http://www.ncbi.nlm.nih.gov/pubmed/19425125\" rel=\"nofollow\"\u003ecompared\u003c/a\u003e, \u003ca href=\"https://www.cambridge.org/core/product/identifier/S1471068418000455/type/journal_article\" rel=\"nofollow\"\u003ecombined\u003c/a\u003e to steady-state modelling (Flux Balance Analysis).\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLicense\u003c/h2\u003e\n\u003cp\u003eThis project is licensed under the GNU General Public License - see the \u003ca href=\"https://github.com/AuReMe/metage2metabo/blob/master/LICENSE\"\u003eLICENSE.md\u003c/a\u003e file for details.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-documentation\" class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDocumentation\u003c/h2\u003e\n\u003cp\u003eA more detailled documentation is available at: \u003ca href=\"https://metage2metabo.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003ehttps://metage2metabo.readthedocs.io\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-technologies\" class=\"anchor\" href=\"#technologies\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTechnologies\u003c/h2\u003e\n\u003cp\u003ePython 3 (Python 3.6 is tested). M2M uses a certain number of Python dependencies. An example of all these dependencies working for Ubuntu 18.04 is available in \u003ca href=\"https://github.com/AuReMe/metage2metabo/blob/master/requirements.txt\"\u003erequirements.txt\u003c/a\u003e.\nThey can be installed with:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003epip install -r requirements.txt --no-cache-dir\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIn particular, m2m relies on:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/AuReMe/mpwt\"\u003empwt\u003c/a\u003e to automatize metabolic network reconstruction with Pathway Tools\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/AuReMe/padmet\"\u003epadmet\u003c/a\u003e to manage metabolic networks\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/cfrioux/MeneTools\"\u003emenetools\u003c/a\u003e to analyze individual metabolic capabilities using logic programming\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/cfrioux/miscoto\"\u003emiscoto\u003c/a\u003e to analyze collective metabolic capabilities and select communities within microbiota using logic programming\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAlso, m2m_analysis relies on other packages:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/networkx/networkx\"\u003enetworkx\u003c/a\u003e to create graph from miscoto results\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/etetoolkit/ete\"\u003eete3\u003c/a\u003e to add taxonomy information on the graph if you used mpwt taxon file\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/Aluriak/PowerGrASP\"\u003epowergrasp\u003c/a\u003e to compress networkx graph\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-requirements\" class=\"anchor\" href=\"#requirements\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRequirements\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"http://bioinformatics.ai.sri.com/ptools/\" rel=\"nofollow\"\u003ePathway Tools\u003c/a\u003e version 23.0 or higher (free for \u003ca href=\"https://biocyc.org/download-bundle.shtml\" rel=\"nofollow\"\u003eacademic users\u003c/a\u003e) is \u003cstrong\u003erequired for m2m workflow and m2m recon\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ePathway Tools requirements\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eLinux\u003c/strong\u003e: Gnome terminal and Libxm4\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eapt-get update \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e apt-get install gnome-terminal libxm4\u003c/pre\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eAll OS\u003c/strong\u003e: \u003ca href=\"https://www.ncbi.nlm.nih.gov/books/NBK279671/\" rel=\"nofollow\"\u003eNCBI Blast\u003c/a\u003e and a ncbirc file in user\u0027s home directory\n\u003cul\u003e\n\u003cli\u003eInstall with apt-get\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eapt-get update \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e apt-get install gnome-terminal libxm4 ncbi-blast+ \n\u003cspan class=\"pl-c1\"\u003eecho\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e[ncbi]\\nData=/usr/bin/data\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e~\u003c/span\u003e/.ncbirc\u003c/pre\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eInstall with a dmg installer on MacOS\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePathway Tools install\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eLinux\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003echmod +x ./pathway-tools-22.5-linux-64-tier1-install \n./pathway-tools-22.5-linux-64-tier1-install \u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eand follow the instructions during the interactive install\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eFor a silent install\u003c/em\u003e: \u003ccode\u003e./pathway-tools-22.5-linux-64-tier1-install --InstallDir your/install/directory/pathway-tools --PTOOLS_LOCAL_PATH your/chosen/directory/for/data/ptools --InstallDesktopShortcuts 0 --mode unattended\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eMacOS\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDmg installer with a graphical interface.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eWarning\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e/!\\ For all OS, Pathway Tools must be in \u003ccode\u003e$PATH\u003c/code\u003e.\nOn Linux and MacOS: \u003ccode\u003eexport PATH=$PATH:your/install/directory/pathway-tools\u003c/code\u003e.\nConsider adding Pathway Tools in \u003ccode\u003e$PATH\u003c/code\u003e permanently by running\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003eecho\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003eexport PATH=\"$PATH:your/install/directory/pathway-tools:\"\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026gt;\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e~\u003c/span\u003e/.bashrc\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"http://www.biotec.tu-dresden.de/research/schroeder/powergraphs/download-command-line-tool.html\" rel=\"nofollow\"\u003eOog Power Graph Command line tool\u003c/a\u003e to create a svg file from the compressed graph at the end of m2m_analysis. This tool is a jar file, Java is needed to use it.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-installation\" class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eDeveloped and tested on Linux (Ubuntu, Fedora, Debian) and MacOs (version 10.14) with Python3.6.\u003c/p\u003e\n\u003cp\u003eContinuous Integration using GitHub Actions with Python3.6 and Python3.7 on ubuntu-latest, macos-latest and windows-latest (\u003ca href=\"https://docs.github.com/en/free-pro-team@latest/actions/reference/specifications-for-github-hosted-runners#supported-runners-and-hardware-resources\"\u003ecorresponding virtual environment\u003c/a\u003e).\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-installation-with-pip\" class=\"anchor\" href=\"#installation-with-pip\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation with pip\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003epip install Metage2Metabo\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-availability-on-docker-and-singularity\" class=\"anchor\" href=\"#availability-on-docker-and-singularity\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAvailability on Docker and Singularity\u003c/h3\u003e\n\u003cp\u003eDue to Pathway-Tools license, Docker or Singularity images are not available publicly.\u003c/p\u003e\n\u003cp\u003eBut you can create these images by using the Dockerfile and Singularity recipes available inside the recipes folder.\nWith these files, you can create container with Pathway-Tools and m2m.\u003c/p\u003e\n\u003cp\u003eMore informations in the \u003ca href=\"https://metage2metabo.readthedocs.io/en/latest/install.html#installation-with-docker\" rel=\"nofollow\"\u003eDocker and Singularity Documentation\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-m2m-commands\" class=\"anchor\" href=\"#m2m-commands\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eM2M commands\u003c/h2\u003e\n\u003cp\u003eM2M commands are listed in the \u003ca href=\"https://metage2metabo.readthedocs.io/en/latest/command.html\" rel=\"nofollow\"\u003eCommands Documentation\u003c/a\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eCopyright (C) Dyliss \u0026amp; Pleiade\nLicense GPLv3+: GNU GPL version 3 or later \u0026lt;http://gnu.org/licenses/gpl.html\u0026gt;\nm2m is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\n\n\nusage: m2m [-h] [-v]\n        {recon,iscope,cscope,addedvalue,mincom,seeds,workflow,metacom,test}\n        ...\n\nFrom metabolic network reconstruction with annotated genomes to metabolic\ncapabilities screening to identify organisms of interest in a large\nmicrobiota. For specific help on each subcommand use: m2m {cmd} --help\n\noptional arguments:\n-h, --help            show this help message and exit\n-v, --version         show program\u0027s version number and exit\n\nsubcommands:\nvalid subcommands:\n\n{recon,iscope,cscope,addedvalue,mincom,seeds,workflow,metacom,test}\n    recon               metabolic network reconstruction\n    iscope              individual scope computation\n    cscope              community scope computation\n    addedvalue          added value of microbiota\u0027s metabolism over\n                        individual\u0027s\n    mincom              minimal communtity selection\n    seeds               creation of seeds SBML file\n    workflow            whole workflow\n    metacom             whole metabolism community analysis\n    test                test on sample data from rumen experiments\n\nRequires: Pathway Tools installed and in $PATH, and NCBI Blast\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-analysis-of-the-minimal-solutions\" class=\"anchor\" href=\"#analysis-of-the-minimal-solutions\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAnalysis of the minimal solutions\u003c/h2\u003e\n\u003cp\u003eM2M performs a community minimization to find the union and intersection of the minimal communities. But it is possible to analyze all the minimal communities.\nM2M has a second command-line, named m2m_analysis that performs this analysis. This method is slower than m2m as all sollutions are enumerated.\nThen it creates a solutions graph and compresses it in a powergraph. Then it creates visualization (html file and optionnaly svg files).\u003c/p\u003e\n\u003cp\u003eMore information about this command in the \u003ca href=\"https://metage2metabo.readthedocs.io/en/latest/m2m_analysis.html\" rel=\"nofollow\"\u003em2m_analysis Documentation\u003c/a\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eusage: m2m_analysis [-h] [-v] {enum,graph,powergraph,workflow} ...\n\nDetection of key species among communities.\n For specific help on each subcommand use: m2m_analysis {cmd} --help\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -v, --version         show program\u0027s version number and exit\n\nsubcommands:\n  valid subcommands:\n\n  {enum,graph,powergraph,workflow}\n    enum                enumeration using miscoto\n    graph               graph creation with enumeration solution\n    powergraph          powergraph creation and visualization\n    workflow            whole workflow\n\nOog jar file (http://www.biotec.tu-dresden.de/research/schroeder/powergraphs/download-command-line-tool.html) for powergraph svg creation.\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-release-notes\" class=\"anchor\" href=\"#release-notes\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRelease Notes\u003c/h2\u003e\n\u003cp\u003eChanges between version are listed on the \u003ca href=\"https://github.com/AuReMe/metage2metabo/releases\"\u003erelease page\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-additional-features\" class=\"anchor\" href=\"#additional-features\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAdditional features\u003c/h2\u003e\n\u003cp\u003eM2M relies on packages that can also be used independantly with more features:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/AuReMe/mpwt\"\u003empwt\u003c/a\u003e: command-line and multi-process solutions to run Pathway Tools. Suitable to multiple reconstruction, for example genomes of a microbiota\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/cfrioux/MeneTools\"\u003emenetools\u003c/a\u003e: individual metabolic capabilities analysis using graph-based producibility criteria\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/cfrioux/miscoto\"\u003emiscoto\u003c/a\u003e: community selection and metabolic screening in large-scal microbiotas, with or without taking a host into account\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-citation\" class=\"anchor\" href=\"#citation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCitation\u003c/h2\u003e\n\u003cp\u003eBelcour* A, Frioux* C, Aite M, Bretaudeau A, Hildebrand F, Siegel A. Metage2Metabo, microbiota-scale metabolic complementarity for the identification of key species. eLife 2020;9:e61968 \u003ca href=\"https://doi.org/10.7554/eLife.61968\" rel=\"nofollow\"\u003ehttps://doi.org/10.7554/eLife.61968\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-article-data\" class=\"anchor\" href=\"#article-data\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eArticle data\u003c/h2\u003e\n\u003cp\u003eData used to create figures and tables are listed in the \u003ca href=\"https://github.com/AuReMe/metage2metabo/tree/master/article_data\"\u003earticle_data\u003c/a\u003e folder, it contains:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/AuReMe/metage2metabo/tree/master/article_data/gsmn_characteristics\"\u003egsmn_characteristics\u003c/a\u003e: scripts and tables to show the characteristics of draft metabolic networks created by M2M for gut, rumen and diabetes dataset.\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/AuReMe/metage2metabo/tree/master/article_data/diabetes_study\"\u003ediabetes_study\u003c/a\u003e: scripts and tables to create the figures of the diabetes analyses in the article.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-authors\" class=\"anchor\" href=\"#authors\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAuthors\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://cfrioux.github.io/\" rel=\"nofollow\"\u003eCl\u00e9mence Frioux\u003c/a\u003e and \u003ca href=\"https://arnaudbelcour.github.io/blog/\" rel=\"nofollow\"\u003eArnaud Belcour\u003c/a\u003e, Univ Rennes, Inria, CNRS, IRISA, Rennes, France.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-acknowledgement\" class=\"anchor\" href=\"#acknowledgement\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAcknowledgement\u003c/h2\u003e\n\u003cp\u003ePeople of Pathway Tools (SRI International) for their help integrating Pathway Tools with command line and multiprocessing in the \u003ca href=\"https://github.com/AuReMe/mpwt\"\u003empwt\u003c/a\u003e package, used in M2M.\u003c/p\u003e\n",
    "stargazers_count": 18,
    "subscribers_count": 4,
    "topics": [
      "bioinformatics",
      "bioinformatics-pipeline",
      "metabolic-models"
    ],
    "updated_at": 1621957476.0
  },
  {
    "data_format": 2,
    "description": "SingularityCE is the Community Edition of Singularity, an open source container platform designed to be simple, fast, and secure.",
    "filenames": [
      "examples/legacy/2.2/arch.def",
      "examples/legacy/2.2/scientific.def",
      "examples/legacy/2.2/busybox.def",
      "examples/legacy/2.2/ubuntu.def",
      "examples/legacy/2.2/debian.def",
      "examples/legacy/2.2/docker.def",
      "examples/legacy/2.2/centos.def",
      "examples/legacy/2.2/contrib/ubuntu-bio.def",
      "examples/legacy/2.2/contrib/debian85-tensorflow-0.10.def",
      "examples/legacy/2.2/contrib/linuxbrew_and_non-root_software_example.def",
      "examples/legacy/2.2/contrib/ubuntu16-tensorflow-0.12.1.def",
      "examples/legacy/2.2/contrib/ubuntu-openfoam.def",
      "examples/legacy/2.2/contrib/centos7-ompi_master.def",
      "examples/legacy/2.2/contrib/centos-minimal.def",
      "examples/legacy/2.2/contrib/r_python_julia.def",
      "examples/legacy/2.2/contrib/centos7-ompi_cuda.def",
      "examples/legacy/2.2/contrib/ubuntu16-tensorflow-0.12.1-gpu.def",
      "examples/legacy/2.2/contrib/ubuntu-root.def",
      "examples/legacy/2.2/contrib/fedora.def",
      "examples/legacy/2.3/contrib/raspbian.def",
      "examples/build-singularity/build-singularity.def",
      "e2e/testdata/inspecter_container.def",
      "e2e/testdata/Docker_registry.def",
      "e2e/testdata/sshfs.def",
      "e2e/testdata/regressions/issue_5315.def",
      "e2e/testdata/regressions/issue_4203.def",
      "e2e/testdata/regressions/issue_4583.def",
      "e2e/testdata/regressions/issue_4969.def",
      "e2e/testdata/regressions/issue_5399.def",
      "e2e/testdata/regressions/issue_5250.def",
      "e2e/testdata/regressions/issue_4820.def",
      "e2e/testdata/regressions/issue_4967.def"
    ],
    "full_name": "sylabs/singularity",
    "latest_release": "v3.8.0",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularityce\" class=\"anchor\" href=\"#singularityce\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSingularityCE\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://circleci.com/gh/sylabs/singularity/tree/master\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ff56e7dd170e08e53c09fda12031315bb91f5b4220f2d3cfaf46044700f32fa1/68747470733a2f2f636972636c6563692e636f6d2f67682f73796c6162732f73696e67756c61726974792f747265652f6d61737465722e7376673f7374796c653d737667\" alt=\"CircleCI\" data-canonical-src=\"https://circleci.com/gh/sylabs/singularity/tree/master.svg?style=svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"CONTRIBUTING.md\"\u003eGuidelines for Contributing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\".github/PULL_REQUEST_TEMPLATE.md\"\u003ePull Request Template\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"LICENSE.md\"\u003eProject License\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.sylabs.io/docs/\" rel=\"nofollow\"\u003eDocumentation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#support\"\u003eSupport\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#citing-singularity\"\u003eCitation\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSingularityCE is the Community Edition of Singularity, an open source container\nplatform designed to be simple, fast, and secure. Singularity is optimized\nfor compute focused enterprise and HPC workloads, allowing untrusted users\nto run untrusted containers in a trusted way.\u003c/p\u003e\n\u003cp\u003eCheck out \u003ca href=\"https://www.sylabs.io/videos\" rel=\"nofollow\"\u003etalks about Singularity\u003c/a\u003e and some \u003ca href=\"https://sylabs.io/case-studies\" rel=\"nofollow\"\u003euse\ncases of Singularity\u003c/a\u003e on our website.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-getting-started-with-singularityce\" class=\"anchor\" href=\"#getting-started-with-singularityce\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGetting Started with SingularityCE\u003c/h2\u003e\n\u003cp\u003eTo install SingularityCE from source, see the \u003ca href=\"INSTALL.md\"\u003einstallation\ninstructions\u003c/a\u003e. For other installation options, see \u003ca href=\"https://www.sylabs.io/guides/latest/admin-guide/\" rel=\"nofollow\"\u003eour\nguide\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSystem administrators can learn how to configure SingularityCE, and get an\noverview of its architecture and security features in the \u003ca href=\"https://www.sylabs.io/guides/latest/admin-guide/\" rel=\"nofollow\"\u003eadministrator\nguide\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eFor users, see the \u003ca href=\"https://www.sylabs.io/guides/latest/user-guide/\" rel=\"nofollow\"\u003euser\nguide\u003c/a\u003e for details on how to use\nand build Singularity containers.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-contributing-to-singularityce\" class=\"anchor\" href=\"#contributing-to-singularityce\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContributing to SingularityCE\u003c/h2\u003e\n\u003cp\u003eCommunity contributions are always greatly appreciated. To start developing\nSingularityCE, check out the \u003ca href=\"CONTRIBUTING.md\"\u003eguidelines for contributing\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eWe also welcome contributions to our \u003ca href=\"https://github.com/sylabs/singularity-userdocs\"\u003euser\nguide\u003c/a\u003e and \u003ca href=\"https://github.com/sylabs/singularity-admindocs\"\u003eadmin\nguide\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-support\" class=\"anchor\" href=\"#support\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSupport\u003c/h2\u003e\n\u003cp\u003eTo get help with SingularityCE, check out the community spaces\ndetailed at our \u003ca href=\"https://www.sylabs.io/singularity/community/\" rel=\"nofollow\"\u003eCommunity\nPortal\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSee also our \u003ca href=\"SUPPORT.md\"\u003eSupport Guidelines\u003c/a\u003e for further\ninformation about the best place, and how, to raise different kinds of\nissues and questions.\u003c/p\u003e\n\u003cp\u003eFor additional support, \u003ca href=\"https://www.sylabs.io/contact/\" rel=\"nofollow\"\u003econtact us\u003c/a\u003e to receive\nmore information.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-citing-singularity\" class=\"anchor\" href=\"#citing-singularity\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCiting Singularity\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003eKurtzer GM, Sochat V, Bauer MW (2017) Singularity: Scientific containers for mobility of compute. PLoS ONE 12(5): e0177459. https://doi.org/10.1371/journal.pone.0177459\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe also have a Zenodo citation:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eKurtzer, Gregory M. et. al. Singularity - Linux application and environment\ncontainers for science. 10.5281/zenodo.1310023\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ca href=\"https://doi.org/10.5281/zenodo.1310023\" rel=\"nofollow\"\u003ehttps://doi.org/10.5281/zenodo.1310023\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThis is an \u0027all versions\u0027 DOI. Follow the link to Zenodo to obtain a DOI specific\nto a particular version of Singularity.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLicense\u003c/h2\u003e\n\u003cp\u003e\u003cem\u003eUnless otherwise noted, this project is licensed under a 3-clause BSD license\nfound in the \u003ca href=\"LICENSE.md\"\u003elicense file\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n",
    "stargazers_count": 31,
    "subscribers_count": 7,
    "topics": [
      "containers",
      "hpc",
      "linux"
    ],
    "updated_at": 1622602618.0
  }
]
