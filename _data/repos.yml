AdrianPlesner/Probabalistic-Multivariate-Timeseries-Forecasting:
  data_format: 2
  description: 'The Bachelor project of group .... at Aalborg University '
  filenames:
  - Singularity
  full_name: AdrianPlesner/Probabalistic-Multivariate-Timeseries-Forecasting
  latest_release: null
  readme: '<h1>

    <a id="user-content-p6-bachelor-project" class="anchor" href="#p6-bachelor-project"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>P6-Bachelor-Project</h1>

    <p>The Bachelor project of group SW617F21 at Aalborg University.</p>

    <p>This project implemnts the Gaussian Process, DeepFactor, DeepAR using <a href="https://github.com/awslabs/gluon-ts">https://github.com/awslabs/gluon-ts</a>
    and Conditioned Normalizong Flows models using <a href="https://github.com/zalandoresearch/pytorch-ts">https://github.com/zalandoresearch/pytorch-ts</a>.
    We also implement our own model LSTM-SCH.</p>

    <p>This guide provides a working example of how to reproduce our results.</p>

    <p>We use the data sets PEMS-BAY and METR-LA available as zip archives in /data.
    Unpack these to pems-bay.h5 and metr-la.h5.</p>

    <h1>

    <a id="user-content-baselines" class="anchor" href="#baselines" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Baselines</h1>

    <p>GP, DeepAR, DeepFactor and CNFlows make use of metadata json files to control
    hyper parameters, serialization and data location. Examples of these are made
    for the default implementations of each model and the optimal combination of hyper
    parameters for each model according to our experiments. They are located in the
    /resuts directory. Here are also serialized instances of the resulting models.</p>

    <p>To train one of these models, make sure that the corresponding metadata file
    has <code>"train": true </code> and the correct path to the location of the data
    file.</p>

    <p>Run src/main.py with the path to the metadata file as program argument or provide
    the path when prompted. When it is done, the predictor object will be serialized
    to the path provided by the "serilaize_path" in the metadata, and the program
    will evaluate the predictor on the validation set.</p>

    <p>If the metadata has the key "params" containing a list of hyper parameters,
    as well as "start", "end" and "step" containing lists of values for the corresponding
    parameters, the program will train a model for each combination of the parameters
    given and write the best combination back to the metadata file.</p>

    <p>To use an serilazed model make sure that the metadata file has <code>"train":
    false </code> and serialize path to the directory that contains the serialization
    files.</p>

    <p>To evaluate a model on the test set, run src/validate.py with the path to the
    metadata file as program argument, or provide the path when prompted. Make sure
    that the metadata file has the right path the the data file and the right path
    to the serilaization directory containing the serialization files.</p>

    <h1>

    <a id="user-content-lst-sch" class="anchor" href="#lst-sch" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>LST-SCH</h1>

    <p>The LST-SCH generates a xlsx file containing the MSE and CRPS result for all
    the sensors within a batch run. Do note, that this file is overwritten each time
    the code is runned. The first column contain the CRPS results and the second the
    MSE results. Note that the xlsx file is 1 index, and not zero, which gives a offset
    in the indexing compared to the python code.</p>

    <p>Training and testing are done sequentially, changes need to be made to the
    code, if the trained model needs to be saved.</p>

    <p>Run src/LSTM-SCH/main.py to run a batch.</p>

    <p>Use the src/LSTM-SCH/conf.py file to configure a run.</p>

    <ul>

    <li>filepath: is used to specify the data set to use</li>

    <li>start_sensor &amp; end_sensor: is used to specify the range of sensor to run
    in the batch</li>

    <li>max_threads: the maximum number of threads to run simulatenly</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1622020298.0
AuReMe/metage2metabo:
  data_format: 2
  description: From annotated genomes to metabolic screening in large scale microbiotas
  filenames:
  - recipes/Singularity
  full_name: AuReMe/metage2metabo
  latest_release: 1.5.0
  readme: "<p><a href=\"https://pypi.org/project/Metage2Metabo/\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/68c19eb988f7da820e489e7d773438373c65af075fe846cb90e18836a7d7f9d4/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6d6574616765326d657461626f2e737667\"\
    \ alt=\"PyPI version\" data-canonical-src=\"https://img.shields.io/pypi/v/metage2metabo.svg\"\
    \ style=\"max-width:100%;\"></a> <a href=\"https://github.com/AuReMe/metage2metabo/blob/master/LICENSE\"\
    ><img src=\"https://camo.githubusercontent.com/fccd34831109fd6bdad80ef75ccdd11796acfad9808526a620456def8d9d9352/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f417552654d652f6d6574616765326d657461626f2e737667\"\
    \ alt=\"GitHub license\" data-canonical-src=\"https://img.shields.io/github/license/AuReMe/metage2metabo.svg\"\
    \ style=\"max-width:100%;\"></a> <a href=\"https://github.com/AuReMe/metage2metabo/actions\"\
    ><img src=\"https://github.com/AuReMe/metage2metabo/workflows/Python%20package/badge.svg\"\
    \ alt=\"Actions Status\" style=\"max-width:100%;\"></a> <a href=\"https://metage2metabo.readthedocs.io/en/latest/?badge=latest\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/88095555c8fdcf3d56ae1cc3261918958b072a5308cc1d5113522bc284afd1b3/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6d6574616765326d657461626f2f62616467652f3f76657273696f6e3d6c6174657374\"\
    \ alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/metage2metabo/badge/?version=latest\"\
    \ style=\"max-width:100%;\"></a> <a href=\"https://doi.org/10.7554/eLife.61968\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/9e55e07ba04fd05d5e7a35a3dadc73af2472409b8403497e7056fb037f5e7875/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f692d31302e373535342f654c6966652e36313936382d626c756576696f6c65742e737667\"\
    \ alt=\"\" data-canonical-src=\"https://img.shields.io/badge/doi-10.7554/eLife.61968-blueviolet.svg\"\
    \ style=\"max-width:100%;\"></a></p>\n<h1>\n<a id=\"user-content-m2m---metage2metabo\"\
    \ class=\"anchor\" href=\"#m2m---metage2metabo\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>M2M - metage2metabo</h1>\n<p>Metage2metabo\
    \ is a Python3 (Python &gt;= 3.6, tested with 3.6 and 3.7) tool to perform graph-based\
    \ metabolic analysis starting from annotated genomes (<strong>reference genomes\
    \ or metagenome-assembled genomes</strong>). It uses <em>Pathway Tools</em> in\
    \ a automatic and parallel way to <strong>reconstruct metabolic networks</strong>\
    \ for a large number of genomes. The obtained metabolic networks are then <strong>analyzed\
    \ individually and collectively</strong> in order to get the <strong>added value\
    \ of metabolic cooperation in microbiota over individual metabolism</strong> and\
    \ to <strong>identify and screen interesting organisms</strong> among all.</p>\n\
    <p>m2m can be used as a whole workflow (<code>m2m workflow</code>, <code>m2m metacom</code>)\
    \ or steps can be performed individually (<code>m2m recon</code> , <code>m2m iscope</code>\
    \ , <code>m2m cscope</code>, <code>m2m addedvalue</code>, <code>m2m mincom</code>,\
    \ <code>m2m seeds</code>).</p>\n<p><strong>If you use M2M, please cite</strong></p>\n\
    <p>Belcour* A, Frioux* C, Aite M, Bretaudeau A, Hildebrand F, Siegel A. Metage2Metabo,\
    \ microbiota-scale metabolic complementarity for the identification of key species.\
    \ eLife 2020;9:e61968 <a href=\"https://doi.org/10.7554/eLife.61968\" rel=\"nofollow\"\
    >https://doi.org/10.7554/eLife.61968</a>.</p>\n<p>For a summary of M2M and its\
    \ applications, you can take a look at these <a href=\"https://hal.inria.fr/hal-03151934/document\"\
    \ rel=\"nofollow\">poster-slides</a>, presented during the <a href=\"https://jobim2020.sciencesconf.org/?forward-action=index&amp;forward-controller=index&amp;lang=en\"\
    \ rel=\"nofollow\">JOBIM 2020 conference</a>.</p>\n<h2>\n<a id=\"user-content-table-of-contents\"\
    \ class=\"anchor\" href=\"#table-of-contents\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Table of contents</h2>\n<ul>\n\
    <li>\n<a href=\"#m2m---metage2metabo\">M2M - metage2metabo</a>\n<ul>\n<li><a href=\"\
    #table-of-contents\">Table of contents</a></li>\n<li><a href=\"#general-information-about-the-modelling\"\
    >General information about the modelling</a></li>\n<li><a href=\"#license\">License</a></li>\n\
    <li><a href=\"#documentation\">Documentation</a></li>\n<li><a href=\"#technologies\"\
    >Technologies</a></li>\n<li><a href=\"#requirements\">Requirements</a></li>\n\
    <li>\n<a href=\"#installation\">Installation</a>\n<ul>\n<li><a href=\"#installation-with-pip\"\
    >Installation with pip</a></li>\n<li><a href=\"#availability-on-docker-and-singularity\"\
    >Availability on Docker and Singularity</a></li>\n</ul>\n</li>\n<li><a href=\"\
    #m2m-commands\">M2M commands</a></li>\n<li><a href=\"#analysis-of-the-minimal-solutions\"\
    >Analysis of the minimal solutions</a></li>\n<li><a href=\"#release-notes\">Release\
    \ Notes</a></li>\n<li><a href=\"#additional-features\">Additional features</a></li>\n\
    <li><a href=\"#citation\">Citation</a></li>\n<li><a href=\"#article-data\">Article\
    \ data</a></li>\n<li><a href=\"#authors\">Authors</a></li>\n<li><a href=\"#acknowledgement\"\
    >Acknowledgement</a></li>\n</ul>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-general-information-about-the-modelling\"\
    \ class=\"anchor\" href=\"#general-information-about-the-modelling\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>General\
    \ information about the modelling</h2>\n<p>M2M has two main dependencies for modelling\
    \ metabolic networks: <a href=\"https://github.com/cfrioux/MeneTools\">MeneTools</a>\
    \ and <a href=\"https://github.com/cfrioux/miscoto\">Miscoto</a>. Accordingly\
    \ metabolic models in M2M follow the producibility in metabolic networks as defined\
    \ by the <a href=\"http://www.ncbi.nlm.nih.gov/pubmed/15712108\" rel=\"nofollow\"\
    >network expansion</a> algorithm.\nMainly, two rules are followed:</p>\n<ul>\n\
    <li>a <em>recursive rule</em>: the products of a reactions are producible if <strong>all</strong>\
    \ reactants of this reaction are themselves producible</li>\n<li>an <em>initiation\
    \ rule</em>: producibility is initiated by the presence of nutrients, called <em>seeds</em>.</li>\n\
    </ul>\n<p>A metabolite that is producible from a set of nutrients is described\
    \ as being \"in the scope of the seeds\".\nThe computation is made using logic\
    \ solvers (Answer Set Programming). The present modelling ignores the stoichiometry\
    \ of reactions (2A + B --&gt; C is considered equivalent to A + B --&gt; C), and\
    \ is therefore suited to non-curated or draft metabolic networks, as the ones\
    \ built using M2M with the PathoLogic software of <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5036846/pdf/bbv079.pdf\"\
    \ rel=\"nofollow\">Pathway Tools</a> handled by <a href=\"https://github.com/AuReMe/mpwt\"\
    >Mpwt</a>. Many works have relied on network expansion to study organisms (<a\
    \ href=\"http://doi.wiley.com/10.1111/tpj.12627\" rel=\"nofollow\">here</a>, <a\
    \ href=\"https://dx.plos.org/10.1371/journal.pcbi.1000049\" rel=\"nofollow\">here</a>\
    \ or <a href=\"http://dx.plos.org/10.1371/journal.pcbi.1005276\" rel=\"nofollow\"\
    >there</a>) and communities (<a href=\"https://academic.oup.com/bioinformatics/article/34/17/i934/5093211\"\
    \ rel=\"nofollow\">here</a>, <a href=\"https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-4786-7\"\
    \ rel=\"nofollow\">here</a>, or <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/18546499\"\
    \ rel=\"nofollow\">here</a>). It has been <a href=\"http://www.ncbi.nlm.nih.gov/pubmed/19425125\"\
    \ rel=\"nofollow\">compared</a>, <a href=\"https://www.cambridge.org/core/product/identifier/S1471068418000455/type/journal_article\"\
    \ rel=\"nofollow\">combined</a> to steady-state modelling (Flux Balance Analysis).</p>\n\
    <h2>\n<a id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>License</h2>\n\
    <p>This project is licensed under the GNU General Public License - see the <a\
    \ href=\"https://github.com/AuReMe/metage2metabo/blob/master/LICENSE\">LICENSE.md</a>\
    \ file for details.</p>\n<h2>\n<a id=\"user-content-documentation\" class=\"anchor\"\
    \ href=\"#documentation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Documentation</h2>\n<p>A more detailled documentation\
    \ is available at: <a href=\"https://metage2metabo.readthedocs.io/en/latest/\"\
    \ rel=\"nofollow\">https://metage2metabo.readthedocs.io</a>.</p>\n<h2>\n<a id=\"\
    user-content-technologies\" class=\"anchor\" href=\"#technologies\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Technologies</h2>\n\
    <p>Python 3 (Python 3.6 is tested). M2M uses a certain number of Python dependencies.\
    \ An example of all these dependencies working for Ubuntu 18.04 is available in\
    \ <a href=\"https://github.com/AuReMe/metage2metabo/blob/master/requirements.txt\"\
    >requirements.txt</a>.\nThey can be installed with:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>pip install -r requirements.txt --no-cache-dir</pre></div>\n\
    <p>In particular, m2m relies on:</p>\n<ul>\n<li>\n<a href=\"https://github.com/AuReMe/mpwt\"\
    >mpwt</a> to automatize metabolic network reconstruction with Pathway Tools</li>\n\
    <li>\n<a href=\"https://github.com/AuReMe/padmet\">padmet</a> to manage metabolic\
    \ networks</li>\n<li>\n<a href=\"https://github.com/cfrioux/MeneTools\">menetools</a>\
    \ to analyze individual metabolic capabilities using logic programming</li>\n\
    <li>\n<a href=\"https://github.com/cfrioux/miscoto\">miscoto</a> to analyze collective\
    \ metabolic capabilities and select communities within microbiota using logic\
    \ programming</li>\n</ul>\n<p>Also, m2m_analysis relies on other packages:</p>\n\
    <ul>\n<li>\n<a href=\"https://github.com/networkx/networkx\">networkx</a> to create\
    \ graph from miscoto results</li>\n<li>\n<a href=\"https://github.com/etetoolkit/ete\"\
    >ete3</a> to add taxonomy information on the graph if you used mpwt taxon file</li>\n\
    <li>\n<a href=\"https://github.com/Aluriak/PowerGrASP\">powergrasp</a> to compress\
    \ networkx graph</li>\n</ul>\n<h2>\n<a id=\"user-content-requirements\" class=\"\
    anchor\" href=\"#requirements\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Requirements</h2>\n<ul>\n<li>\n<p><a\
    \ href=\"http://bioinformatics.ai.sri.com/ptools/\" rel=\"nofollow\">Pathway Tools</a>\
    \ version 23.0 or higher (free for <a href=\"https://biocyc.org/download-bundle.shtml\"\
    \ rel=\"nofollow\">academic users</a>) is <strong>required for m2m workflow and\
    \ m2m recon</strong></p>\n<ul>\n<li>\n<p>Pathway Tools requirements</p>\n<ul>\n\
    <li>\n<strong>Linux</strong>: Gnome terminal and Libxm4</li>\n</ul>\n<div class=\"\
    highlight highlight-source-shell\"><pre>apt-get update <span class=\"pl-k\">&amp;&amp;</span>\
    \ apt-get install gnome-terminal libxm4</pre></div>\n<ul>\n<li>\n<strong>All OS</strong>:\
    \ <a href=\"https://www.ncbi.nlm.nih.gov/books/NBK279671/\" rel=\"nofollow\">NCBI\
    \ Blast</a> and a ncbirc file in user's home directory\n<ul>\n<li>Install with\
    \ apt-get</li>\n</ul>\n<div class=\"highlight highlight-source-shell\"><pre>apt-get\
    \ update <span class=\"pl-k\">&amp;&amp;</span> apt-get install gnome-terminal\
    \ libxm4 ncbi-blast+ \n<span class=\"pl-c1\">echo</span> <span class=\"pl-s\"\
    ><span class=\"pl-pds\">\"</span>[ncbi]\\nData=/usr/bin/data<span class=\"pl-pds\"\
    >\"</span></span> <span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">~</span>/.ncbirc</pre></div>\n\
    <ul>\n<li>Install with a dmg installer on MacOS</li>\n</ul>\n</li>\n</ul>\n</li>\n\
    <li>\n<p>Pathway Tools install</p>\n<ul>\n<li><strong>Linux</strong></li>\n</ul>\n\
    <div class=\"highlight highlight-source-shell\"><pre>chmod +x ./pathway-tools-22.5-linux-64-tier1-install\
    \ \n./pathway-tools-22.5-linux-64-tier1-install </pre></div>\n<p>and follow the\
    \ instructions during the interactive install</p>\n<p><em>For a silent install</em>:\
    \ <code>./pathway-tools-22.5-linux-64-tier1-install --InstallDir your/install/directory/pathway-tools\
    \ --PTOOLS_LOCAL_PATH your/chosen/directory/for/data/ptools --InstallDesktopShortcuts\
    \ 0 --mode unattended</code></p>\n<ul>\n<li><strong>MacOS</strong></li>\n</ul>\n\
    <p>Dmg installer with a graphical interface.</p>\n<ul>\n<li><strong>Warning</strong></li>\n\
    </ul>\n<p>/!\\ For all OS, Pathway Tools must be in <code>$PATH</code>.\nOn Linux\
    \ and MacOS: <code>export PATH=$PATH:your/install/directory/pathway-tools</code>.\n\
    Consider adding Pathway Tools in <code>$PATH</code> permanently by running</p>\n\
    <div class=\"highlight highlight-source-shell\"><pre><span class=\"pl-c1\">echo</span>\
    \ <span class=\"pl-s\"><span class=\"pl-pds\">'</span>export PATH=\"$PATH:your/install/directory/pathway-tools:\"\
    <span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">&gt;&gt;</span> <span\
    \ class=\"pl-k\">~</span>/.bashrc</pre></div>\n</li>\n</ul>\n</li>\n<li>\n<p><a\
    \ href=\"http://www.biotec.tu-dresden.de/research/schroeder/powergraphs/download-command-line-tool.html\"\
    \ rel=\"nofollow\">Oog Power Graph Command line tool</a> to create a svg file\
    \ from the compressed graph at the end of m2m_analysis. This tool is a jar file,\
    \ Java is needed to use it.</p>\n</li>\n</ul>\n<h2>\n<a id=\"user-content-installation\"\
    \ class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Installation</h2>\n<p>Developed\
    \ and tested on Linux (Ubuntu, Fedora, Debian) and MacOs (version 10.14) with\
    \ Python3.6.</p>\n<p>Continuous Integration using GitHub Actions with Python3.6\
    \ and Python3.7 on ubuntu-latest, macos-latest and windows-latest (<a href=\"\
    https://docs.github.com/en/free-pro-team@latest/actions/reference/specifications-for-github-hosted-runners#supported-runners-and-hardware-resources\"\
    >corresponding virtual environment</a>).</p>\n<h3>\n<a id=\"user-content-installation-with-pip\"\
    \ class=\"anchor\" href=\"#installation-with-pip\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installation\
    \ with pip</h3>\n<pre><code>pip install Metage2Metabo\n</code></pre>\n<h3>\n<a\
    \ id=\"user-content-availability-on-docker-and-singularity\" class=\"anchor\"\
    \ href=\"#availability-on-docker-and-singularity\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Availability\
    \ on Docker and Singularity</h3>\n<p>Due to Pathway-Tools license, Docker or Singularity\
    \ images are not available publicly.</p>\n<p>But you can create these images by\
    \ using the Dockerfile and Singularity recipes available inside the recipes folder.\n\
    With these files, you can create container with Pathway-Tools and m2m.</p>\n<p>More\
    \ informations in the <a href=\"https://metage2metabo.readthedocs.io/en/latest/install.html#installation-with-docker\"\
    \ rel=\"nofollow\">Docker and Singularity Documentation</a>.</p>\n<h2>\n<a id=\"\
    user-content-m2m-commands\" class=\"anchor\" href=\"#m2m-commands\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>M2M\
    \ commands</h2>\n<p>M2M commands are listed in the <a href=\"https://metage2metabo.readthedocs.io/en/latest/command.html\"\
    \ rel=\"nofollow\">Commands Documentation</a>.</p>\n<pre><code>Copyright (C) Dyliss\
    \ &amp; Pleiade\nLicense GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;\n\
    m2m is free software: you are free to change and redistribute it.\nThere is NO\
    \ WARRANTY, to the extent permitted by law.\n\n\nusage: m2m [-h] [-v]\n      \
    \  {recon,iscope,cscope,addedvalue,mincom,seeds,workflow,metacom,test}\n     \
    \   ...\n\nFrom metabolic network reconstruction with annotated genomes to metabolic\n\
    capabilities screening to identify organisms of interest in a large\nmicrobiota.\
    \ For specific help on each subcommand use: m2m {cmd} --help\n\noptional arguments:\n\
    -h, --help            show this help message and exit\n-v, --version         show\
    \ program's version number and exit\n\nsubcommands:\nvalid subcommands:\n\n{recon,iscope,cscope,addedvalue,mincom,seeds,workflow,metacom,test}\n\
    \    recon               metabolic network reconstruction\n    iscope        \
    \      individual scope computation\n    cscope              community scope computation\n\
    \    addedvalue          added value of microbiota's metabolism over\n       \
    \                 individual's\n    mincom              minimal communtity selection\n\
    \    seeds               creation of seeds SBML file\n    workflow           \
    \ whole workflow\n    metacom             whole metabolism community analysis\n\
    \    test                test on sample data from rumen experiments\n\nRequires:\
    \ Pathway Tools installed and in $PATH, and NCBI Blast\n</code></pre>\n<h2>\n\
    <a id=\"user-content-analysis-of-the-minimal-solutions\" class=\"anchor\" href=\"\
    #analysis-of-the-minimal-solutions\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Analysis of the minimal solutions</h2>\n\
    <p>M2M performs a community minimization to find the union and intersection of\
    \ the minimal communities. But it is possible to analyze all the minimal communities.\n\
    M2M has a second command-line, named m2m_analysis that performs this analysis.\
    \ This method is slower than m2m as all sollutions are enumerated.\nThen it creates\
    \ a solutions graph and compresses it in a powergraph. Then it creates visualization\
    \ (html file and optionnaly svg files).</p>\n<p>More information about this command\
    \ in the <a href=\"https://metage2metabo.readthedocs.io/en/latest/m2m_analysis.html\"\
    \ rel=\"nofollow\">m2m_analysis Documentation</a>.</p>\n<pre><code>usage: m2m_analysis\
    \ [-h] [-v] {enum,graph,powergraph,workflow} ...\n\nDetection of key species among\
    \ communities.\n For specific help on each subcommand use: m2m_analysis {cmd}\
    \ --help\n\noptional arguments:\n  -h, --help            show this help message\
    \ and exit\n  -v, --version         show program's version number and exit\n\n\
    subcommands:\n  valid subcommands:\n\n  {enum,graph,powergraph,workflow}\n   \
    \ enum                enumeration using miscoto\n    graph               graph\
    \ creation with enumeration solution\n    powergraph          powergraph creation\
    \ and visualization\n    workflow            whole workflow\n\nOog jar file (http://www.biotec.tu-dresden.de/research/schroeder/powergraphs/download-command-line-tool.html)\
    \ for powergraph svg creation.\n</code></pre>\n<h2>\n<a id=\"user-content-release-notes\"\
    \ class=\"anchor\" href=\"#release-notes\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Release Notes</h2>\n<p>Changes\
    \ between version are listed on the <a href=\"https://github.com/AuReMe/metage2metabo/releases\"\
    >release page</a>.</p>\n<h2>\n<a id=\"user-content-additional-features\" class=\"\
    anchor\" href=\"#additional-features\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Additional features</h2>\n<p>M2M\
    \ relies on packages that can also be used independantly with more features:</p>\n\
    <ul>\n<li>\n<a href=\"https://github.com/AuReMe/mpwt\">mpwt</a>: command-line\
    \ and multi-process solutions to run Pathway Tools. Suitable to multiple reconstruction,\
    \ for example genomes of a microbiota</li>\n<li>\n<a href=\"https://github.com/cfrioux/MeneTools\"\
    >menetools</a>: individual metabolic capabilities analysis using graph-based producibility\
    \ criteria</li>\n<li>\n<a href=\"https://github.com/cfrioux/miscoto\">miscoto</a>:\
    \ community selection and metabolic screening in large-scal microbiotas, with\
    \ or without taking a host into account</li>\n</ul>\n<h2>\n<a id=\"user-content-citation\"\
    \ class=\"anchor\" href=\"#citation\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Citation</h2>\n<p>Belcour* A,\
    \ Frioux* C, Aite M, Bretaudeau A, Hildebrand F, Siegel A. Metage2Metabo, microbiota-scale\
    \ metabolic complementarity for the identification of key species. eLife 2020;9:e61968\
    \ <a href=\"https://doi.org/10.7554/eLife.61968\" rel=\"nofollow\">https://doi.org/10.7554/eLife.61968</a>.</p>\n\
    <h2>\n<a id=\"user-content-article-data\" class=\"anchor\" href=\"#article-data\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Article data</h2>\n<p>Data used to create figures and tables are listed\
    \ in the <a href=\"https://github.com/AuReMe/metage2metabo/tree/master/article_data\"\
    >article_data</a> folder, it contains:</p>\n<ul>\n<li>\n<a href=\"https://github.com/AuReMe/metage2metabo/tree/master/article_data/gsmn_characteristics\"\
    >gsmn_characteristics</a>: scripts and tables to show the characteristics of draft\
    \ metabolic networks created by M2M for gut, rumen and diabetes dataset.</li>\n\
    <li>\n<a href=\"https://github.com/AuReMe/metage2metabo/tree/master/article_data/diabetes_study\"\
    >diabetes_study</a>: scripts and tables to create the figures of the diabetes\
    \ analyses in the article.</li>\n</ul>\n<h2>\n<a id=\"user-content-authors\" class=\"\
    anchor\" href=\"#authors\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Authors</h2>\n<p><a href=\"https://cfrioux.github.io/\"\
    \ rel=\"nofollow\">Cl\xE9mence Frioux</a> and <a href=\"https://arnaudbelcour.github.io/blog/\"\
    \ rel=\"nofollow\">Arnaud Belcour</a>, Univ Rennes, Inria, CNRS, IRISA, Rennes,\
    \ France.</p>\n<h2>\n<a id=\"user-content-acknowledgement\" class=\"anchor\" href=\"\
    #acknowledgement\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Acknowledgement</h2>\n<p>People of Pathway Tools (SRI\
    \ International) for their help integrating Pathway Tools with command line and\
    \ multiprocessing in the <a href=\"https://github.com/AuReMe/mpwt\">mpwt</a> package,\
    \ used in M2M.</p>\n"
  stargazers_count: 18
  subscribers_count: 4
  topics:
  - bioinformatics
  - bioinformatics-pipeline
  - metabolic-models
  updated_at: 1621957476.0
ConferencePaperSubmission/RegularizationCocktail:
  data_format: 2
  description: 'Regularization is all you Need: Simple Neural Nets can Excel on Tabular
    Data'
  filenames:
  - AutoPyTorch/scripts/Singularity
  full_name: ConferencePaperSubmission/RegularizationCocktail
  latest_release: null
  readme: '<h1>

    <a id="user-content-regularization-is-all-you-need-simple-neural-nets-can-excel-on-tabular-data"
    class="anchor" href="#regularization-is-all-you-need-simple-neural-nets-can-excel-on-tabular-data"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Regularization
    is all you Need: Simple Neural Nets can Excel on Tabular Data</h1>

    <p>Tabular datasets are the last "unconquered castle" by deep learning and traditional
    ML methods like Gradient-Boosted Decision Trees still perform strongly even against
    recent specialized neural architectures. In this paper, we hypothesize that the
    key to boosting the performance of neural networks lies in rethinking the joint
    and simultaneous application of a large set of modern regularization techniques.
    As a result, we propose regularizing plain Multilayer Perceptron (MLP) networks
    by searching for the optimal combination/cocktail of 13 regularization techniques
    for each dataset as a Combined Algorithm Selection and Hyperparameter Optimization.
    To validate our hypothesis we empirically assess the impact of the regularization
    cocktails for MLPs on a large-scale empirical study comprising 40 datasets and
    demonstrate that (i) well-regularized plain MLPs significantly outperform recent
    state-of-the-art specialized neural network architectures, and that (ii) our well-regularized
    networks even outperform strong traditional ML methods such as XGBoost on tabular
    datasets.</p>

    <p><strong>Source code for NeurIPS submission 2133</strong></p>

    <p><strong>Our implementation of regularization cocktails is based on a fork of
    AutoPyTorch and this fork is part of the submission to ensure full reproducibility.</strong></p>

    <p><strong>The code for the experiments with the baselines (AutoGluon, XGBoost,
    auto-sklearn, NODE and TabNet) can be found under the baselines folder.</strong></p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1622167921.0
HanLabUNLV/hanlab_singularity_defs:
  data_format: 2
  description: definition files for containers used in Hanlab
  filenames:
  - singularity.SAD/SAD.def
  - singularity.R.3.6.3.phylo/R.3.6.3.phylo.def
  - singularity.Rconda/R.3.6.3.def
  - singularity.R.4.0.2.Bioc/R.4.0.2.Bioc.def
  - singularity.mkl/mkl.def
  - singularity.mkl/mkl.ubuntu.def
  - singularity.py37.ml.openblas/py37.ml.openblas.def
  - singularity.phylo/phylo.def
  - singularity.py37.ml.mkl/py37.ml.mkl.def
  - singularity.R.3.6.3.Bioc/R.3.6.3.Bioc.def
  - singularity.rnaseq/rnaseq.def
  full_name: HanLabUNLV/hanlab_singularity_defs
  latest_release: null
  readme: '<h1>

    <a id="user-content-hpc_mpi_cuda_singu_def_file" class="anchor" href="#hpc_mpi_cuda_singu_def_file"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>hpc_mpi_cuda_singu_def_file</h1>

    <p>A collect of definition files to build images for singularity containers, which
    includes hpc benchmarks and mpis with cuda support.</p>

    <p><a href="https://singularity-hub.org/collections/4181" rel="nofollow"><img
    src="https://camo.githubusercontent.com/a07b23d4880320ac89cdc93bbbb603fa84c215d135e05dd227ba8633a9ff34be/68747470733a2f2f7777772e73696e67756c61726974792d6875622e6f72672f7374617469632f696d672f686f737465642d73696e67756c61726974792d2d6875622d2532336533323932392e737667"
    alt="https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg"
    data-canonical-src="https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg"
    style="max-width:100%;"></a></p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1617130184.0
MontrealSergiy/deformation:
  data_format: 2
  description: null
  filenames:
  - Singularity
  full_name: MontrealSergiy/deformation
  latest_release: null
  readme: '<h1>

    <a id="user-content-deformation-field" class="anchor" href="#deformation-field"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Deformation
    field</h1>

    <p>This PERL script is a wrapper that is calling sequence of commands for generating
    deformation fields scrips

    <a href="https://wiki.mouseimaging.ca/display/MICePub/Generating+deformation+fields"
    rel="nofollow">https://wiki.mouseimaging.ca/display/MICePub/Generating+deformation+fields</a>

    Source code for deformation pipeline and dependencies (MINC):

    <a href="https://github.com/Mouse-Imaging-Centre/generate_deformation_fields">https://github.com/Mouse-Imaging-Centre/generate_deformation_fields</a></p>

    <p>Usage</p>

    <p>./deformation.pl -input ICBM_00100_t1_final.mnc &lt;&lt;this could be any anatomical
    minc file, for a collection of minc files&gt;&gt; -output dummy_hoho -deformation_ratio
    0.6 -coordinate 70 100 70 10 10 10 -tolerance_space 4 &lt;&gt; -blur_determinant
    0.25 &lt;&gt; -error 0.00001 &lt;&gt; -iteration 100</p>

    <p>The output of running this command looks like this:

    ICBM_00100_t1_final_deformed_by_0.4atROIx70-y100-z70dimx10.dimy10.dimz10.mnc.
    </p>

    <p>We will also have a directory dummy_hoho/TMP that will contain the in-between-files.</p>

    <p>$:/dummy_hoho/TMP$ ls</p>

    <p>block.mnc</p>

    <p>blurred0.25determinant_r_0.4x70-y100-z70dimx10.dimy10.dimz10.mnc</p>

    <p>DDDDdilated.mnc</p>

    <p>DDDDring.mnc</p>

    <p>determinant_r_0.4_grid.mnc</p>

    <p>determinant_r_0.4x70-y100-z70dimx10.dimy10.dimz10.mnc</p>

    <p>determinant_r_0.4.xfm</p>

    <p>mask.mnc</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1621950177.0
NIH-HPC/singularity-def-files:
  data_format: 2
  description: definition files and wrapper scripts used by NIH HPC staff to install
    user-facing apps on the Biowulf cluster
  filenames:
  - molecular-modeling-graphics/blender/2.82/blender.def
  - molecular-modeling-graphics/starseqr/0.6.7/starseqr.def
  - molecular-modeling-graphics/chimerax/1.1/chimerax.def
  - molecular-modeling-graphics/chimerax/0.93/chimerax.def
  - systems-biology/cellphonedb/2.1.7/cellphonedb.def
  - systems-biology/cellphonedb/2.1.2/cellphonedb.def
  - sequence-analysis/cicero/1.4.0/cicero.def
  - sequence-analysis/roary/3.13.0/roary.def
  - sequence-analysis/roary/3.12.0/roary.def
  - sequence-analysis/arriba/2.0.0/arriba.def
  - sequence-analysis/arriba/1.2.0/arriba.def
  - sequence-analysis/xhla/2018-04-04/xhla.def
  - sequence-analysis/qtltools/1.3.1/qtltools.def
  - sequence-analysis/glu/1.0b3/glu.def
  - sequence-analysis/annogesic/1.0.2/annogesic.def
  - sequence-analysis/focus/0.6.10/focus.def
  - sequence-analysis/wisexome/20180814/wisexome.def
  - sequence-analysis/anvio/7/anvio.def
  - sequence-analysis/cactus/1.2.3/cactus.def
  - sequence-analysis/bamgineer/2-20200624/bamgineer.def
  - sequence-analysis/svtools/0.5.1/svtools.def
  - sequence-analysis/phaser/1.1.1/phaser.def
  - sequence-analysis/accurity/20210209/accurity.def
  - sequence-analysis/accurity/20180724/accurity.def
  - sequence-analysis/sonicparanoid/1.3.5/sonicparanoid.def
  - sequence-analysis/sonicparanoid/1.3.2/sonicparanoid.def
  - sequence-analysis/orffinder/0.4.3-sing-install/orffinder.def
  - sequence-analysis/vcf-kit/0.1.6/vcf-kit.def
  - sequence-analysis/smoove/0.2.5/smoove.def
  - sequence-analysis/smoove/0.2.1/smoove.def
  - sequence-analysis/m-tools/20210208/m-tools.def
  - sequence-analysis/eukrep/20180308/eukrep.def
  - sequence-analysis/asgal/1.0/asgal.def
  - sequence-analysis/netoglyc/3.1d/netoglyc.def
  - sequence-analysis/saige/0.44.1/saige.def
  - sequence-analysis/intarna/3.2.0/intarna.def
  - sequence-analysis/chipseq_pipeline/1.2.0/chipseq_pipeline.def
  - sequence-analysis/mmarge/1.0/mmarge.def
  - sequence-analysis/acfs/20180316/acfs.def
  - sequence-analysis/ldsc/3d0c4464/ldsc.def
  - sequence-analysis/deepsea/0.94c/deepsea.def
  - sequence-analysis/braker/2/braker.def
  - sequence-analysis/prokka/1.13/prokka.def
  - sequence-analysis/prokka/1.14.6/prokka.def
  - sequence-analysis/htgtsrep/9fe74ff/htgtsrep.def
  - sequence-analysis/glnexus/1.1.11/glnexus.def
  - sequence-analysis/glnexus/1.2.7/glnexus.def
  - sequence-analysis/augustus/3.3.3/augustus.def
  - image-analysis/terastitcher/1.11.10/terastitcher.def
  - image-analysis/terastitcher/1.10.8/terastitcher.def
  - image-analysis/mrtrix/3.0.2-cuda9.1/mrtrix.def
  - image-analysis/mrtrix/3.0.1/mrtrix.def
  - image-analysis/mrtrix/3.0.0/mrtrix.def
  - image-analysis/mriqc/0.16.1/mriqc.def
  - image-analysis/mriqc/0.15.1/mriqc.def
  - image-analysis/mriqc/0.15.2/mriqc.def
  - image-analysis/mriqc/0.15.2-0be03bf/mriqc.def
  - image-analysis/xcpengine/1.2.1/xcpengine.def
  - image-analysis/xcpengine/1.0/xcpengine.def
  - image-analysis/xcpengine/1.2.3/xcpengine.def
  - image-analysis/tesseract/4.1.1/tesseract.def
  - image-analysis/civet/2.1.1/civet.def
  - image-analysis/topaz/0.2.5/topaz.def
  - image-analysis/deepmedic/0.8.0/deepmedic.def
  - image-analysis/deepmedic/0.8.2/deepmedic.def
  - image-analysis/broccoli/1.0.1/broccoli.def
  - image-analysis/qsiprep/0.8.0/qsiprep.def
  - image-analysis/fitlins/0.8.0/fitlins.def
  - image-analysis/fitlins/0.7.0/fitlins.def
  - image-analysis/minc-toolkit/1.9.16/minc-toolkit.def
  - image-analysis/minc-toolkit/1.9.18/minc-toolkit.def
  - image-analysis/resmap/1.95/resmap.def
  - image-analysis/fmriprep/20.2.1/fmriprep.def
  - image-analysis/fmriprep/20.0.5/fmriprep.def
  - image-analysis/fmriprep/20.1.1/fmriprep.def
  - image-analysis/fmriprep/20.1.3/fmriprep.def
  - image-analysis/fmriprep/20.2.0/fmriprep.def
  - image-analysis/baracus/1.1.4/baracus.def
  - computational-chemistry/ampl/f35623d4/ampl.def
  - mass-spectrometry/maxquant/1.6.17.0/maxquant.def
  - mass-spectrometry/maxquant/1.6.3.3/maxquant.def
  - mass-spectrometry/maxquant/1.6.7.0/maxquant.def
  - utilities/sysbench/1.0.11/sysbench.def
  - utilities/sysbench/1.0.20/sysbench.def
  - utilities/uropa/3.5.0/uropa.def
  - utilities/pyega3/3.3.0/pyega3.def
  - utilities/whatshap/0.18/whatshap.def
  - utilities/snp-sites/2.4.1/snp-sites.def
  - utilities/gdc-client/1.5.0/gdc-client.def
  - utilities/datalad/0.13.0rc2/datalad.def
  - utilities/visidata/2.2/visidata.def
  - utilities/ariba/2.14.4/ariba.def
  - utilities/atom/1.13.1/atom.def
  - utilities/xvfb/1.19.6/xvfb.def
  - utilities/longshot/0.3.5/longshot.def
  - utilities/pdf2svg/0.2.3/pdf2svg.def
  - utilities/vcf2db/2020.09.14/vcf2db.def
  - high-throughput-sequencing/pepr/1.1.24/pepr.def
  - high-throughput-sequencing/cicero/0.3.0/cicero.def
  - high-throughput-sequencing/deepsignal/0.1.8/deepsignal.def
  - high-throughput-sequencing/bamutil/1.0.15/bamutil.def
  - high-throughput-sequencing/vagrent/3.3.4/vagrent.def
  - high-throughput-sequencing/metaphlan/3.0/metaphlan.def
  - high-throughput-sequencing/metaphlan/3.0.6/metaphlan.def
  - high-throughput-sequencing/hap.py/0.3.9/hap.py.def
  - high-throughput-sequencing/rilseq/0.75/rilseq.def
  - high-throughput-sequencing/tetoolkit/2.2.1/tetoolkit.def
  - high-throughput-sequencing/tetoolkit/2.1.4/tetoolkit.def
  - high-throughput-sequencing/ascatngs/4.3.4/ascatngs.def
  - high-throughput-sequencing/ascatngs/4.3.3/ascatngs.def
  - high-throughput-sequencing/ascatngs/4.5.0/ascatngs.def
  - high-throughput-sequencing/htseq/0.11.4/htseq.def
  - high-throughput-sequencing/metabat/2.13/metabat.def
  - high-throughput-sequencing/atropos/1.1.18/atropos.def
  - high-throughput-sequencing/epic2/0.0.41/epic2.def
  - high-throughput-sequencing/deeptools/3.4.2/deeptools.def
  - high-throughput-sequencing/deeptools/3.5.0/deeptools.def
  - high-throughput-sequencing/vep/101/vep.def
  - high-throughput-sequencing/vep/103/vep.def
  - high-throughput-sequencing/vep/97/vep.def
  - high-throughput-sequencing/atac_dnase_pipelines/0.3.4-19-gcbd2a00/atac_dnase_pipelines.def
  - high-throughput-sequencing/sve/0.1.0/sve.def
  - high-throughput-sequencing/sicer/2-1.0.2/sicer.def
  - high-throughput-sequencing/salmon/1.4.0/salmon.def
  - high-throughput-sequencing/dropest/0.8.6/dropest.def
  - high-throughput-sequencing/tandemtools/current/tandemtools.def
  - high-throughput-sequencing/multiqc/1.9/multiqc.def
  - high-throughput-sequencing/multiqc/1.10/multiqc.def
  - high-throughput-sequencing/svtk/0.1/svtk.def
  - high-throughput-sequencing/ricopili/2019_Jun_25.001/ricopili.def
  - high-throughput-sequencing/bison/0.4.0/bison.def
  - high-throughput-sequencing/umitools/1.1.1/umitools.def
  - high-throughput-sequencing/eager/1.92/eager.def
  - high-throughput-sequencing/deepvariant/0.10.0/deepvariant.def
  - high-throughput-sequencing/deepvariant/0.9.0/deepvariant.def
  - high-throughput-sequencing/deepvariant/1.1.0/deepvariant.def
  - high-throughput-sequencing/macs/2.2.7.1/macs.def
  - high-throughput-sequencing/medaka/1.0.3/medaka.def
  - high-throughput-sequencing/medaka/0.12.1/medaka.def
  - high-throughput-sequencing/medaka/1.2.0/medaka.def
  - high-throughput-sequencing/svtyper/0.7.1/svtyper.def
  - high-throughput-sequencing/scramble/0.0.20190211.82c78b9/scramble.def
  - high-throughput-sequencing/scramble/1.0.1-32893ef/scramble.def
  - high-throughput-sequencing/parliament/0.1.7/parliament.def
  - high-throughput-sequencing/cutadapt/3.0/cutadapt.def
  - high-throughput-sequencing/cutadapt/2.10/cutadapt.def
  - high-throughput-sequencing/cutadapt/1.18/cutadapt.def
  - high-throughput-sequencing/abruijn/1.0/abruijn.def
  - high-throughput-sequencing/canvas/1.40/canvas.def
  - high-throughput-sequencing/seqlinkage/1.0/seqlinkage.def
  - high-throughput-sequencing/gossamer/ac492a8/gossamer.def
  - high-throughput-sequencing/hicexplorer/3.5.1/hicexplorer.def
  - high-throughput-sequencing/hicpro/2.11.4/hicpro.def
  - high-throughput-sequencing/pvactools/2.0.1/pvactools.def
  - high-throughput-sequencing/pvactools/1.5.5/pvactools.def
  - high-throughput-sequencing/mtoolbox/1.1/mtoolbox.def
  - high-throughput-sequencing/bamsurgeon/1111e5d/bamsurgeon.def
  - high-throughput-sequencing/gridss/2.9.4/gridss.def
  - high-throughput-sequencing/bigscale2/20191119/bigscale2.def
  - high-throughput-sequencing/xengsort/28762aac/xengsort.def
  - high-throughput-sequencing/csvkit/1.0.5/csvkit.def
  - high-throughput-sequencing/cnvkit/0.9.8/cnvkit.def
  - high-throughput-sequencing/cnvkit/0.9.6/cnvkit.def
  - high-throughput-sequencing/fusioninspector/2.5.0/fusioninspector.def
  - high-throughput-sequencing/fusioninspector/2.3.0/fusioninspector.def
  - high-throughput-sequencing/megalodon/2.2.9/megalodon.def
  - high-throughput-sequencing/slamdunk/0.4.3/slamdunk.def
  - high-throughput-sequencing/rsd/1.1.7/rsd.def
  - high-throughput-sequencing/tvc/5.10.1/tvc.def
  - high-throughput-sequencing/maggie/0.3.4/maggie.def
  - high-throughput-sequencing/flye/2.8-1/flye.def
  - high-throughput-sequencing/flye/2.7/flye.def
  - high-throughput-sequencing/tpmcalculator/0.0.4/tpmcalculator.def
  - high-throughput-sequencing/tpmcalculator/0.0.3/tpmcalculator.def
  - high-throughput-sequencing/idep/0.81/idep.def
  - high-throughput-sequencing/transvar/2.5.9/transvar.def
  - high-throughput-sequencing/flappie/1.0.0/flappie.def
  - high-throughput-sequencing/flappie/2.1.3/flappie.def
  - high-throughput-sequencing/cellsnp/0.1.7/cellsnp.def
  - high-throughput-sequencing/cellsnp/0.3.2/cellsnp.def
  - high-throughput-sequencing/crossmap/0.5.2/crossmap.def
  - high-throughput-sequencing/brass/6.3.4/brass.def
  - high-throughput-sequencing/brass/6.1.2/brass.def
  - high-throughput-sequencing/rseqc/4.0.0/rseqc.def
  - high-throughput-sequencing/hail/0.2.61/hail.def
  - high-throughput-sequencing/hail/0.2.56/hail.def
  - high-throughput-sequencing/hail/0.2.3/hail.def
  - high-throughput-sequencing/rmats/4.0.2/rmats.def
  - high-throughput-sequencing/mitosuite/1.0.9b/mitosuite.def
  - high-throughput-sequencing/taiji/1.1.0/taiji.def
  - high-throughput-sequencing/taiji/1.2.0/taiji.def
  - high-throughput-sequencing/humann2/2.8.1/humann2.def
  - high-throughput-sequencing/vireosnp/0.5.1/vireosnp.def
  - high-throughput-sequencing/vireosnp/0.3.2/vireosnp.def
  - high-throughput-sequencing/cnvnator/0.4.1/cnvnator.def
  - high-throughput-sequencing/delly/0.8.7/delly.def
  - high-throughput-sequencing/mageck-vispr/0.5.4/mageck-vispr.def
  - high-throughput-sequencing/guppy/4.2.2/guppy.def
  - high-throughput-sequencing/guppy/3.4.5/guppy.def
  - high-throughput-sequencing/guppy/4.0.15/guppy.def
  - high-throughput-sequencing/cancerit-wgs/2.1.0/cancerit-wgs.def
  - high-throughput-sequencing/repeatmodeler/2.0.1/repeatmodeler.def
  - high-throughput-sequencing/surpi/1.0.67/surpi.def
  - high-throughput-sequencing/bamliquidator/1.3.8/bamliquidator.def
  - high-throughput-sequencing/neusomatic/0.2.1/neusomatic.def
  - high-throughput-sequencing/rnapeg/current/rnapeg.def
  - high-throughput-sequencing/biom-format/2.1.10/biom-format.def
  - high-throughput-sequencing/pcap-core/4.3.5/pcap-core.def
  - high-throughput-sequencing/humann/3.0.0-alpha.3/humann.def
  - high-throughput-sequencing/crispresso/2.0.40/crispresso.def
  - high-throughput-sequencing/crispresso/2.0.45/crispresso.def
  - high-throughput-sequencing/busco/5.0.0/busco.def
  - high-throughput-sequencing/busco/4.1.3/busco.def
  - high-throughput-sequencing/bamreadcount/cram-v0.0.1/bamreadcount.def
  - high-throughput-sequencing/lefse/1.0.8/lefse.def
  - high-throughput-sequencing/lefse/1.0.7/lefse.def
  - high-throughput-sequencing/cgpbattenberg/3.5.3/cgpbattenberg.def
  - high-throughput-sequencing/pychopper/2.4.0/pychopper.def
  - high-throughput-sequencing/freebayes/1.3.5/freebayes.def
  - high-throughput-sequencing/raremetal/4.15.1/raremetal.def
  - high-throughput-sequencing/stream/20180816/stream.def
  - linkage-phylogenetics/bali-phy/3.5/bali-phy.def
  - linkage-phylogenetics/gubbins/2.3.4/gubbins.def
  - structural-biology/parsnip/20180507/parsnip.def
  - structural-biology/rdock/2013.1/rdock.def
  - structural-biology/pymol/2.4.0/pymol.def
  - structural-biology/pymol/2.3.0/pymol_2.3.0.def
  - deep-learning/basset/0.1.0/basset.def
  - deep-learning/deeplab/20180816/deeplab.def
  - deep-learning/caffe2/0.8.1/caffe2.def
  - deep-learning/dextr-pytorch/20180710/dextr-pytorch.def
  - deep-learning/tensorrt/18.09/tensorrt.def
  - deep-learning/clairvoyante/1.0/clairvoyante.def
  - deep-learning/polyrnnpp/20180718/polyrnnpp.def
  - deep-learning/few-shot-ssl/20180723/few-shot-ssl.def
  - deep-learning/digits/6.0/digits.def
  - deep-learning/unet/20180704/unet.def
  - mathematical-statistics/omeclust/1.1.4/omeclust.def
  - mathematical-statistics/omeclust/1.1.6/omeclust.def
  - mathematical-statistics/m2clust/1.1.3/m2clust.def
  - mathematical-statistics/m2clust/0.0.7/m2clust.def
  - mathematical-statistics/m2clust/0.0.8/m2clust.def
  full_name: NIH-HPC/singularity-def-files
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-nih-hpc-singularity-definition-files\" class=\"\
    anchor\" href=\"#nih-hpc-singularity-definition-files\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>NIH HPC Singularity\
    \ Definition Files</h1>\n<p>These definition files and wrapper scripts are used\
    \ by the <a href=\"https://hpc.nih.gov/\" rel=\"nofollow\">NIH HPC (Biowulf)</a>\
    \ staff to install containerized applications using <a href=\"https://github.com/sylabs/singularity\"\
    >Singularity</a>. Each app is installed in a self-contained directory and access\
    \ to the app is controlled through a module system (<a href=\"https://github.com/TACC/Lmod\"\
    >Lmod</a>). This strategy allows users to transparently access apps that are installed\
    \ within containers as though they were installed directly on the host system.\
    \ More details can be found <a href=\"https://hpc.nih.gov/apps/singularity.html#bind-stationary\"\
    \ rel=\"nofollow\">here</a>.</p>\n<p>Typically, apps are installed under in a\
    \ directory structure like so:</p>\n<pre><code>$ tree appname/ver\nappname/ver\n\
    |-- bin\n|   |-- cmd1 -&gt; ../libexec/wrapper.sh\n|   |-- cmd2 -&gt; ../libexec/wrapper.sh\n\
    |   `-- cmd3 -&gt; ../libexec/wrapper.sh\n`-- libexec\n    |-- app.sif\n    `--\
    \ wrapper.sh\n</code></pre>\n<p>Because <code>wrapper.sh</code> is written to\
    \ be introspective, any command symlinked to it will be carried through and executed\
    \ within the associated container. The wrapper script is also sufficiently generic\
    \ that it can be reused across apps with little or no modification.</p>\n<p>Each\
    \ app has its own <code>README.md</code> that contains:</p>\n<ul>\n<li>a link\
    \ to the NIH HPC app page or developer's documentation</li>\n<li>a list of symlinks\
    \ that should be created to the wrapper script to expose executables within the\
    \ container</li>\n<li>any app specific installation notes</li>\n</ul>\n<p>Finally,\
    \ please note that these definition files <strong>are not guaranteed to reproduce\
    \ the same container, or even to produce any container at all</strong>. The internet,\
    \ upon which these definition files are based, is subject to change without notice.\
    \ These definition files are therefore intended to be treated as (potentially)\
    \ helpful suggestions.</p>\n<h2>\n<a id=\"user-content-computational-chemistry\"\
    \ class=\"anchor\" href=\"#computational-chemistry\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a href=\"/computational-chemistry\"\
    >Computational Chemistry</a>\n</h2>\n<ul>\n<li><a href=\"/computational-chemistry/ampl\"\
    >ampl</a></li>\n</ul>\n<h2>\n<a id=\"user-content-deep-learning\" class=\"anchor\"\
    \ href=\"#deep-learning\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a><a href=\"/deep-learning\">Deep Learning</a>\n\
    </h2>\n<ul>\n<li><a href=\"/deep-learning/caffe2\">Caffe2</a></li>\n<li><a href=\"\
    /deep-learning/dextr-pytorch\">DEXTR-PyTorch</a></li>\n<li><a href=\"/deep-learning/polyrnnpp\"\
    >PolyRNNpp</a></li>\n<li><a href=\"/deep-learning/basset\">basset</a></li>\n<li><a\
    \ href=\"/deep-learning/clairvoyante\">clairvoyante</a></li>\n<li><a href=\"/deep-learning/deeplab\"\
    >deeplab</a></li>\n<li><a href=\"/deep-learning/digits\">digits</a></li>\n<li><a\
    \ href=\"/deep-learning/few-shot-ssl\">few-shot-ssl</a></li>\n<li><a href=\"/deep-learning/tensorrt\"\
    >tensorrt</a></li>\n<li><a href=\"/deep-learning/unet\">unet</a></li>\n</ul>\n\
    <h2>\n<a id=\"user-content-high-throughput-sequencing\" class=\"anchor\" href=\"\
    #high-throughput-sequencing\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a><a href=\"/high-throughput-sequencing\"\
    >High Throughput Sequencing</a>\n</h2>\n<ul>\n<li><a href=\"/high-throughput-sequencing/atac_dnase_pipelines\"\
    >ATAC-Seq / DNase-Seq Pipeline</a></li>\n<li><a href=\"/high-throughput-sequencing/ascatngs\"\
    >AscatNGS</a></li>\n<li><a href=\"/high-throughput-sequencing/atropos\">Atropos</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/bamsurgeon\">BAMSurgeon</a></li>\n<li><a\
    \ href=\"/high-throughput-sequencing/brass\">BRASS</a></li>\n<li><a href=\"/high-throughput-sequencing/canvas\"\
    >Canvas</a></li>\n<li><a href=\"/high-throughput-sequencing/maggie\">MAGGIE</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/pcap-core\">PCAP-core</a></li>\n<li><a\
    \ href=\"/high-throughput-sequencing/pepr\">PePr</a></li>\n<li><a href=\"/high-throughput-sequencing/rsd\"\
    >RSD</a></li>\n<li><a href=\"/high-throughput-sequencing/surpi\">SURPI</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/tpmcalculator\">TPMCalculator</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/tvc\">TVC</a></li>\n<li><a href=\"/high-throughput-sequencing/vagrent\"\
    >VAGrENT</a></li>\n<li><a href=\"/high-throughput-sequencing/vep\">VEP</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/abruijn\">abruijn</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/bamliquidator\">bamliquidator</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/bamreadcount\">bamreadcount</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/bamutil\">bamutil</a></li>\n<li><a href=\"/high-throughput-sequencing/bigscale2\"\
    >bigscale2</a></li>\n<li><a href=\"/high-throughput-sequencing/biom-format\">biom-format</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/bison\">bison</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/busco\">busco</a></li>\n<li><a href=\"/high-throughput-sequencing/cancerit-wgs\"\
    >cancerit-wgs</a></li>\n<li><a href=\"/high-throughput-sequencing/cellsnp\">cellsnp</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/cgpbattenberg\">cgpBattenberg</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/cicero\">cicero</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/cnvkit\">cnvkit</a></li>\n<li><a href=\"/high-throughput-sequencing/cnvnator\"\
    >cnvnator</a></li>\n<li><a href=\"/high-throughput-sequencing/crispresso\">crispresso</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/crossmap\">crossmap</a></li>\n<li><a\
    \ href=\"/high-throughput-sequencing/csvkit\">csvkit</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/cutadapt\">cutadapt</a></li>\n<li><a href=\"/high-throughput-sequencing/deepsignal\"\
    >deepsignal</a></li>\n<li><a href=\"/high-throughput-sequencing/deeptools\">deeptools</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/deepvariant\">deepvariant</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/delly\">delly</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/dropest\">dropest</a></li>\n<li><a href=\"/high-throughput-sequencing/eager\"\
    >eager</a></li>\n<li><a href=\"/high-throughput-sequencing/epic2\">epic2</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/flappie\">flappie</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/flye\">flye</a></li>\n<li><a href=\"/high-throughput-sequencing/freebayes\"\
    >freebayes</a></li>\n<li><a href=\"/high-throughput-sequencing/fusioninspector\"\
    >fusioninspector</a></li>\n<li><a href=\"/high-throughput-sequencing/gossamer\"\
    >gossamer</a></li>\n<li><a href=\"/high-throughput-sequencing/gridss\">gridss</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/guppy\">guppy</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/hail\">hail</a></li>\n<li><a href=\"/high-throughput-sequencing/hap.py\"\
    >hap.py</a></li>\n<li><a href=\"/high-throughput-sequencing/hicexplorer\">hicexplorer</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/hicpro\">hicpro</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/htseq\">htseq</a></li>\n<li><a href=\"/high-throughput-sequencing/humann2\"\
    >humann2</a></li>\n<li><a href=\"/high-throughput-sequencing/idep\">idep</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/lefse\">lefse</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/macs\">macs</a></li>\n<li><a href=\"/high-throughput-sequencing/mageck-vispr\"\
    >mageck-vispr</a></li>\n<li><a href=\"/high-throughput-sequencing/medaka\">medaka</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/megalodon\">megalodon</a></li>\n<li><a\
    \ href=\"/high-throughput-sequencing/metabat\">metabat</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/metaphlan\">metaphlan</a></li>\n<li><a href=\"/high-throughput-sequencing/mitosuite\"\
    >mitosuite</a></li>\n<li><a href=\"/high-throughput-sequencing/mtoolbox\">mtoolbox</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/multiqc\">multiqc</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/neusomatic\">neusomatic</a></li>\n<li><a href=\"/high-throughput-sequencing/parliament\"\
    >parliament</a></li>\n<li><a href=\"/high-throughput-sequencing/pvactools\">pvactools</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/pychopper\">pychopper</a></li>\n<li><a\
    \ href=\"/high-throughput-sequencing/raremetal\">raremetal</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/repeatmodeler\">repeatmodeler</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/ricopili\">ricopili</a></li>\n<li><a href=\"/high-throughput-sequencing/rilseq\"\
    >rilseq</a></li>\n<li><a href=\"/high-throughput-sequencing/rmats\">rmats</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/rnapeg\">rnapeg</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/rseqc\">rseqc</a></li>\n<li><a href=\"/high-throughput-sequencing/salmon\"\
    >salmon</a></li>\n<li><a href=\"/high-throughput-sequencing/scramble\">scramble</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/seqlinkage\">seqlinkage</a></li>\n<li><a\
    \ href=\"/high-throughput-sequencing/sicer\">sicer</a></li>\n<li><a href=\"/high-throughput-sequencing/slamdunk\"\
    >slamdunk</a></li>\n<li><a href=\"/high-throughput-sequencing/stream\">stream</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/sve\">sve</a></li>\n<li><a href=\"/high-throughput-sequencing/svtk\"\
    >svtk</a></li>\n<li><a href=\"/high-throughput-sequencing/svtyper\">svtyper</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/taiji\">taiji</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/tandemtools\">tandemtools</a></li>\n<li><a href=\"\
    /high-throughput-sequencing/tetoolkit\">tetoolkit</a></li>\n<li><a href=\"/high-throughput-sequencing/transvar\"\
    >transvar</a></li>\n<li><a href=\"/high-throughput-sequencing/umitools\">umitools</a></li>\n\
    <li><a href=\"/high-throughput-sequencing/vireosnp\">vireosnp</a></li>\n<li><a\
    \ href=\"/high-throughput-sequencing/xengsort\">xengsort</a></li>\n</ul>\n<h2>\n\
    <a id=\"user-content-image-analysis\" class=\"anchor\" href=\"#image-analysis\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a><a href=\"/image-analysis\">Image Analysis</a>\n</h2>\n<ul>\n<li><a\
    \ href=\"/image-analysis/resmap\">ResMap</a></li>\n<li><a href=\"/image-analysis/terastitcher\"\
    >TeraStitcher</a></li>\n<li><a href=\"/image-analysis/baracus\">baracus</a></li>\n\
    <li><a href=\"/image-analysis/broccoli\">broccoli</a></li>\n<li><a href=\"/image-analysis/civet\"\
    >civet</a></li>\n<li><a href=\"/image-analysis/ctf\">ctf</a></li>\n<li><a href=\"\
    /image-analysis/deepmedic\">deepmedic</a></li>\n<li><a href=\"/image-analysis/fitlins\"\
    >fitlins</a></li>\n<li><a href=\"/image-analysis/fmriprep\">fmriprep</a></li>\n\
    <li><a href=\"/image-analysis/minc-toolkit\">minc-toolkit</a></li>\n<li><a href=\"\
    /image-analysis/mriqc\">mriqc</a></li>\n<li><a href=\"/image-analysis/mrtrix\"\
    >mrtrix</a></li>\n<li><a href=\"/image-analysis/qsiprep\">qsiprep</a></li>\n<li><a\
    \ href=\"/image-analysis/tesseract\">tesseract</a></li>\n<li><a href=\"/image-analysis/topaz\"\
    >topaz</a></li>\n<li><a href=\"/image-analysis/xcpengine\">xcpengine</a></li>\n\
    </ul>\n<h2>\n<a id=\"user-content-linkage-phylogenetics\" class=\"anchor\" href=\"\
    #linkage-phylogenetics\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a><a href=\"/linkage-phylogenetics\">Linkage Phylogenetics</a>\n\
    </h2>\n<ul>\n<li><a href=\"/linkage-phylogenetics/bali-phy\">bali-phy</a></li>\n\
    <li><a href=\"/linkage-phylogenetics/gubbins\">gubbins</a></li>\n</ul>\n<h2>\n\
    <a id=\"user-content-mass-spectrometry\" class=\"anchor\" href=\"#mass-spectrometry\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a><a href=\"/mass-spectrometry\">Mass Spectrometry</a>\n</h2>\n<ul>\n\
    <li><a href=\"/mass-spectrometry/maxquant\">maxquant</a></li>\n</ul>\n<h2>\n<a\
    \ id=\"user-content-mathematicalstatistics\" class=\"anchor\" href=\"#mathematicalstatistics\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a><a href=\"/mathematical-statistics\">Mathematical/Statistics</a>\n\
    </h2>\n<ul>\n<li><a href=\"/mathematical-statistics/m2clust\">m2clust</a></li>\n\
    <li><a href=\"/mathematical-statistics/omeclust\">omeClust</a></li>\n</ul>\n<h2>\n\
    <a id=\"user-content-molecular-modeling-graphics\" class=\"anchor\" href=\"#molecular-modeling-graphics\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a><a href=\"/molecular-modeling-graphics\">Molecular Modeling Graphics</a>\n\
    </h2>\n<ul>\n<li><a href=\"/molecular-modeling-graphics/chimerax\">ChimeraX</a></li>\n\
    <li><a href=\"/molecular-modeling-graphics/blender\">blender</a></li>\n<li><a\
    \ href=\"/molecular-modeling-graphics/starseqr\">starseqr</a></li>\n</ul>\n<h2>\n\
    <a id=\"user-content-sequence-analysis\" class=\"anchor\" href=\"#sequence-analysis\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a><a href=\"/sequence-analysis\">Sequence Analysis</a>\n</h2>\n<ul>\n\
    <li><a href=\"/sequence-analysis/acfs\">ACFS</a></li>\n<li><a href=\"/sequence-analysis/annogesic\"\
    >ANNOgesic</a></li>\n<li><a href=\"/sequence-analysis/asgal\">ASGAL</a></li>\n\
    <li><a href=\"/sequence-analysis/accurity\">Accurity</a></li>\n<li><a href=\"\
    /sequence-analysis/eukrep\">EukRep</a></li>\n<li><a href=\"/sequence-analysis/glu\"\
    >GLU</a></li>\n<li><a href=\"/sequence-analysis/htgtsrep\">HTGTSrep</a></li>\n\
    <li><a href=\"/sequence-analysis/orffinder\">ORFfinder</a></li>\n<li><a href=\"\
    /sequence-analysis/saige\">SAIGE</a></li>\n<li><a href=\"/sequence-analysis/vcf-kit\"\
    >VCF-kit</a></li>\n<li><a href=\"/sequence-analysis/anvio\">anvio</a></li>\n<li><a\
    \ href=\"/sequence-analysis/arriba\">arriba</a></li>\n<li><a href=\"/sequence-analysis/augustus\"\
    >augustus</a></li>\n<li><a href=\"/sequence-analysis/bamgineer\">bamgineer</a></li>\n\
    <li><a href=\"/sequence-analysis/braker\">braker</a></li>\n<li><a href=\"/sequence-analysis/cactus\"\
    >cactus</a></li>\n<li><a href=\"/sequence-analysis/chipseq_pipeline\">chipseq_pipeline</a></li>\n\
    <li><a href=\"/sequence-analysis/cicero\">cicero</a></li>\n<li><a href=\"/sequence-analysis/deepsea\"\
    >deepsea</a></li>\n<li><a href=\"/sequence-analysis/focus\">focus</a></li>\n<li><a\
    \ href=\"/sequence-analysis/glnexus\">glnexus</a></li>\n<li><a href=\"/sequence-analysis/intarna\"\
    >intarna</a></li>\n<li><a href=\"/sequence-analysis/ldsc\">ldsc</a></li>\n<li><a\
    \ href=\"/sequence-analysis/m-tools\">m-tools</a></li>\n<li><a href=\"/sequence-analysis/mmarge\"\
    >mmarge</a></li>\n<li><a href=\"/sequence-analysis/netoglyc\">netOglyc</a></li>\n\
    <li><a href=\"/sequence-analysis/phaser\">phaser</a></li>\n<li><a href=\"/sequence-analysis/prokka\"\
    >prokka</a></li>\n<li><a href=\"/sequence-analysis/qtltools\">qtltools</a></li>\n\
    <li><a href=\"/sequence-analysis/roary\">roary</a></li>\n<li><a href=\"/sequence-analysis/smoove\"\
    >smoove</a></li>\n<li><a href=\"/sequence-analysis/sonicparanoid\">sonicparanoid</a></li>\n\
    <li><a href=\"/sequence-analysis/svtools\">svtools</a></li>\n<li><a href=\"/sequence-analysis/wisexome\"\
    >wisexome</a></li>\n<li><a href=\"/sequence-analysis/xhla\">xHLA</a></li>\n</ul>\n\
    <h2>\n<a id=\"user-content-structural-biology\" class=\"anchor\" href=\"#structural-biology\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a><a href=\"/structural-biology\">Structural Biology</a>\n</h2>\n<ul>\n\
    <li><a href=\"/structural-biology/parsnip\">parsnip</a></li>\n<li><a href=\"/structural-biology/pymol\"\
    >pymol</a></li>\n<li><a href=\"/structural-biology/rdock\">rDock</a></li>\n</ul>\n\
    <h2>\n<a id=\"user-content-systems-biology\" class=\"anchor\" href=\"#systems-biology\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a><a href=\"/systems-biology\">Systems Biology</a>\n</h2>\n<ul>\n<li><a\
    \ href=\"/systems-biology/cellphonedb\">cellphonedb</a></li>\n</ul>\n<h2>\n<a\
    \ id=\"user-content-utilities\" class=\"anchor\" href=\"#utilities\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a><a\
    \ href=\"/utilities\">Utilities</a>\n</h2>\n<ul>\n<li><a href=\"/utilities/xvfb\"\
    >Xvfb</a></li>\n<li><a href=\"/utilities/ariba\">ariba</a></li>\n<li><a href=\"\
    /utilities/atom\">atom</a></li>\n<li><a href=\"/utilities/datalad\">datalad</a></li>\n\
    <li><a href=\"/utilities/gdc-client\">gdc-client</a></li>\n<li><a href=\"/utilities/longshot\"\
    >longshot</a></li>\n<li><a href=\"/utilities/pdf2svg\">pdf2svg</a></li>\n<li><a\
    \ href=\"/utilities/pyega3\">pyega3</a></li>\n<li><a href=\"/utilities/snp-sites\"\
    >snp-sites</a></li>\n<li><a href=\"/utilities/sysbench\">sysbench</a></li>\n<li><a\
    \ href=\"/utilities/uropa\">uropa</a></li>\n<li><a href=\"/utilities/vcf2db\"\
    >vcf2db</a></li>\n<li><a href=\"/utilities/visidata\">visidata</a></li>\n<li><a\
    \ href=\"/utilities/whatshap\">whatshap</a></li>\n</ul>\n"
  stargazers_count: 7
  subscribers_count: 6
  topics: []
  updated_at: 1622225605.0
NOAA-GFDL/AM4:
  data_format: 2
  description: null
  filenames:
  - container/Singularity.intel_netcdf
  - container/Singularity.intel_am4
  - container/Singularity.gnu
  full_name: NOAA-GFDL/AM4
  latest_release: '2021.02'
  readme: '<h1>

    <a id="user-content-gfdl-am4-model" class="anchor" href="#gfdl-am4-model" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>GFDL AM4 Model</h1>

    <p><a href="https://zenodo.org/badge/latestdoi/102487636" rel="nofollow"><img
    src="https://camo.githubusercontent.com/878db836b9000fd7d9ff531257cade7343f3a3fdf8f764b5a7f1e8ef6ccc6abe/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3130323438373633362e737667"
    alt="DOI" data-canonical-src="https://zenodo.org/badge/102487636.svg" style="max-width:100%;"></a></p>

    <p>This repository includes the public release of the GFDL AM4 model

    code.  The AM4 model is described in the

    <a href="https://doi.org/10.1002/2017MS001208" rel="nofollow">two</a>

    <a href="https://doi.org/10.1002/2017MS001209" rel="nofollow">articles</a> published
    in the

    <a href="https://agupubs.onlinelibrary.wiley.com/journal/19422466" rel="nofollow">Journal
    of Advances in Modeling Earth Systems

    (JAMES)</a>.

    More information on the model and access to the output is available on

    the <a href="http://data1.gfdl.noaa.gov/nomads/forms/am4.0/" rel="nofollow">AM4
    data and code

    site</a> at the

    <a href="https://www.gfdl.noaa.gov" rel="nofollow">Geophysical Fluid Dynamics
    Laboratory

    (GFDL)</a>.</p>

    <p>The layout of this package includes the following directories:</p>

    <ul>

    <li>src - The source code for the AM4 model</li>

    <li>exec - The build directory with Makefiles for building the model executable</li>

    <li>run - Sample run script and updated files needed for running</li>

    <li>analysis - Sample analysis scripts</li>

    </ul>

    <h2>

    <a id="user-content-cloning-instructions" class="anchor" href="#cloning-instructions"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Cloning
    Instructions</h2>

    <p>This repository uses <a href="https://git-scm.com/book/en/v2/Git-Tools-Submodules"
    rel="nofollow">git

    submodules</a> to

    point to other repositories.  Thus, care should be taken when cloning,

    and updating the source to ensure all source.  To obtain all source,

    use the following git command</p>

    <pre><code>git clone --recursive https://github.com/NOAA-GFDL/AM4.git

    </code></pre>

    <p>The <code>--recursive</code> option to <code>git clone</code> instructs git
    to recursively

    clone all submodules.  In the event the repository was not cloned

    using the <code>--recursive</code> option, the following step must be taken to

    obtain all sources:</p>

    <pre><code># From within the AM4 parent directory

    git submodule update --init --recursive

    </code></pre>

    <h2>

    <a id="user-content-source-code" class="anchor" href="#source-code" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Source Code</h2>

    <p>All model source is contained in the <a href="src">src</a> directory.  GFDL

    tracks code using the git version control system.  This package

    includes a single version of the following GFDL model components.  The

    git hash listed corresponds to the commit hash in the internal GFDL

    git repository.</p>

    <table>

    <thead>

    <tr>

    <th>Component</th>

    <th>Commit Hash</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>atmos_drivers</td>

    <td>5ee95d6abf0879594551dd7e6635dff4004c4010</td>

    </tr>

    <tr>

    <td>atmos_param</td>

    <td>2e94acfd8621e85216bf822c395a8c3f15a511a5</td>

    </tr>

    <tr>

    <td>atmos_shared</td>

    <td>a557d4d7bab033ef1ad1d400a62fe07a97ccb477</td>

    </tr>

    <tr>

    <td>ice_param</td>

    <td>1553c8bc4f9a66791c89367b6f327147523155ed</td>

    </tr>

    <tr>

    <td>ice_sis</td>

    <td>ccc7328dcd79706dd5c17c8bab660222886fc80b</td>

    </tr>

    <tr>

    <td>land_lad2</td>

    <td>a220288ecb289bf9d793d051fc5076072874ce07</td>

    </tr>

    </tbody>

    </table>

    <p>The following components are available in the

    <a href="https://github.com/NOAA-GFDL">NOAA-GFDL</a> github organization:</p>

    <ul>

    <li><a href="https://github.com/NOAA-GFDL/MOM6">MOM6</a></li>

    <li><a href="https://github.com/NOAA-GFDL/coupler">coupler</a></li>

    <li>

    <a href="https://github.com/NOAA-GFDL/FMS">FMS</a> (as <a href="src/shared">shared</a>)</li>

    <li>

    <a href="https://github.com/NOAA-GFDL/GFDL_atmos_cubed_sphere">GFDL_atmos_cubed_sphere
    (tag AM4.0)</a> (as <a href="src/atmos_cubed_sphere">atmos_cubed_sphere</a>)</li>

    </ul>

    <h2>

    <a id="user-content-building-am4" class="anchor" href="#building-am4" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building AM4</h2>

    <p>The <a href="exec">exec</a> directory contains Makefiles that can be used to

    build the AM4 executable.  These Makefiles were generated using the

    <a href="https://github.com/NOAA-GFDL/mkmf">Make Makefile (mkmf)</a> program.

    Included in the exec direcgtory is a sample make template file for the

    Intel compilers (<a href="exec/templates/intel.mk">intel.mk</a>).  This make

    template can be used on any system with a relatively recent version of

    the Intel compilers, the netCDF 4 library and the MPICH2 MPI library.

    Included in the <a href="exec/templates/intel.mk">intel.mk</a> file are

    additional settings that can be modified during the build.</p>

    <p>To run the default build (-O3 -msse2), go to the exec directory and

    enter the command</p>

    <pre><code>make

    </code></pre>

    <p>If you would like to change some of the compiler options, there are several
    different

    options to add to the make command.  For example</p>

    <pre><code>make ISA=-xhost BLD_TYPE=REPRO

    </code></pre>

    <p>will replace -msse with -xhost and -O3 with -O2.  The three options for

    <code>BLD_TYPE</code> are<br>

    <code>PROD</code> (-O3)<br>

    <code>REPRO</code> (-O2)<br>

    <code>DEBUG</code> (-O0 and other traps)<br>

    All of the make line options can be

    found in the <a href="exec/templates/intel.mk">intel.mk</a> file.</p>

    <h2>

    <a id="user-content-obtaining-the-input-data" class="anchor" href="#obtaining-the-input-data"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Obtaining
    the input data</h2>

    <p>The input data required for running the AM4 model can be found on

    <a href="http://data1.gfdl.noaa.gov/nomads/forms/am4.0/" rel="nofollow">GFDL''s
    data

    portal</a> .</p>

    <p>The file <code>AM4.tar.gz</code> contains a configured run directory to run
    a

    sample experiment of the AM4 model.  Included in the tar file is a

    README.AM4_run with more instructions on how to configure the AM4 run

    directory.</p>

    <p>On Linux systems, the <code>wget</code> command is usually sufficient to download
    the data

    file:</p>

    <pre><code>wget ftp://nomads.gfdl.noaa.gov/users/Ming.Zhao/AM4Documentation/GFDL-AM4.0/inputData/AM4_run.tar.gz

    </code></pre>

    <p>To ensure the file downloaded is complete and not corrupted, download one of
    the two files:</p>

    <pre><code>wget ftp://nomads.gfdl.noaa.gov/users/Ming.Zhao/AM4Documentation/GFDL-AM4.0/inputData/AM4_run.tar.gz.sha256

    wget ftp://nomads.gfdl.noaa.gov/users/Ming.Zhao/AM4Documentation/GFDL-AM4.0/inputData/AM4_run.tar.gz.sig

    </code></pre>

    <p>and run the following command that corresponds to the signature file downloaded:</p>

    <pre><code>sha256sum -c AM4_run.tar.gz.sha256

    </code></pre>

    <pre><code>gpg --verify AM4_run.tar.gz.sig

    </code></pre>

    <h2>

    <a id="user-content-running-am4" class="anchor" href="#running-am4" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running AM4</h2>

    <p>Included in the run directory is a sample run script for reference.

    To run the AM4 sample experiment, first download the data file

    mentioned in <a href="#obtaining-the-input-data">Obtaining the Input data</a>

    section.  Replace diag_table and input.nml in the top level of the

    untar''d directory with the corresponding files in the run directory

    of this repository. Modify the variables in the configuration section

    in the sample run script, and then run the script.</p>

    <p>The sample data and run script are configured to run on 216

    processors.  To run on a different number of processors, or modify the

    experiment, refer to the <code>README.AM4_run</code> file included in the AM4

    data tarball.</p>

    <p>Note: The <code>input.nml</code> file (found in the AM4 data tarball) contains

    Fortran namelists and namelist variables that modify, at run time, the

    model.  To learn more about the settings in the <code>input.nml</code> file,

    please refer to source code where the namelist/variable are defined.</p>

    <h2>

    <a id="user-content-analysis-scripts" class="anchor" href="#analysis-scripts"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Analysis
    Scripts</h2>

    <p>Some of the climate analysis scripts run at NOAA GFDL and used in the

    AM4 documentation papers are located in the analysis directory.

    Within each analysis suite, is a <a href="https://jupyter-notebook.readthedocs.io/en/stable/"
    rel="nofollow">jupyter

    notebook</a>, both

    readable and runnable from your local jupyter environment, provided

    all dependencies are installed.</p>

    <p>E.g.</p>

    <ul>

    <li><a href="analysis/cjs1/radiation_atmos_av_mon/radiation_atmos_av_mon.ipynb">Radiation
    processor</a></li>

    <li><a href="analysis/bw/bw_atmos_cru_ts_a1r/bw_atmos_monthly_cru_ts.1980-2014.ipynb">Long-term
    DJF seasonal mean</a></li>

    <li><a href="analysis/bw/bw_atmos_zm_atl_pac_a1r/bw_atmos_atl_pac.1980-2014.ipynb">Zonal_mean_zonal_wind_stress</a></li>

    <li><a href="analysis/pcmdimetrics/portraitPlot-AM4.AMIP.ipynb">PCMDI Metrics
    Portrait Plot</a></li>

    </ul>

    <h2>

    <a id="user-content-model-output-and-other-references" class="anchor" href="#model-output-and-other-references"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Model
    output and Other References</h2>

    <p>Please refer to the <a href="http://data1.gfdl.noaa.gov/nomads/forms/am4.0/"
    rel="nofollow">AM4 data and code

    site</a> for details

    about where to find model and OBS data used in the papers.</p>

    <p>For all analysis figures and pertaining data, please use the AM4

    documentation papers as the original reference.</p>

    <p>Please direct your questions and feedback to

    <a href="mailto:gfdl.climate.model.info@noaa.gov">gfdl.climate.model.info@noaa.gov</a></p>

    <h2>

    <a id="user-content-disclaimer" class="anchor" href="#disclaimer" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an ''as is'' basis and the user assumes responsibility for

    its use.  DOC has relinquished control of the information and no

    longer has responsibility to protect the integrity, confidentiality,

    or availability of the information.  Any claims against the Department

    of Commerce stemming from the use of its GitHub project will be

    governed by all applicable Federal law.  Any reference to specific

    commercial products, processes, or services by service mark,

    trademark, manufacturer, or otherwise, does not constitute or imply

    their endorsement, recommendation or favoring by the Department of

    Commerce.  The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    <p>This project code is made available through GitHub but is managed by

    NOAA-GFDL at <a href="https://gitlab.gfdl.noaa.gov" rel="nofollow">https://gitlab.gfdl.noaa.gov</a>.</p>

    '
  stargazers_count: 9
  subscribers_count: 6
  topics:
  - fortran
  - jupyter-notebook
  - shell-script
  - ncl
  updated_at: 1622048423.0
NOAA-GFDL/CM4:
  data_format: 2
  description: null
  filenames:
  - containers/Singularity.intel_netcdf
  - containers/Singularity.intel_cm4
  - containers/Singularity.cm4
  full_name: NOAA-GFDL/CM4
  latest_release: '2021.01'
  readme: '<h1>

    <a id="user-content-gfdl-cm4-model" class="anchor" href="#gfdl-cm4-model" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>GFDL CM4 Model</h1>

    <p><a href="https://www.gfdl.noaa.gov" rel="nofollow">Geophysical Fluid Dynamics
    Laboratory

    (GFDL)</a>.</p>

    <p>The layout of this package includes the following directories:</p>

    <ul>

    <li>src - The source code for the CM4 model</li>

    <li>exec - The build directory with Makefiles for building the model executable</li>

    <li>run - Sample run script</li>

    </ul>

    <h2>

    <a id="user-content-cloning-instructions" class="anchor" href="#cloning-instructions"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Cloning
    Instructions</h2>

    <p>This repository uses <a href="https://git-scm.com/book/en/v2/Git-Tools-Submodules"
    rel="nofollow">git

    submodules</a> to

    point to other repositories.  Thus, care should be taken when cloning,

    and updating the source to ensure all source.  To obtain all source,

    use the following git command</p>

    <pre><code>git clone --recursive https://github.com/NOAA-GFDL/CM4.git

    </code></pre>

    <p>The <code>--recursive</code> option to <code>git clone</code> instructs git
    to recursively

    clone all submodules.  In the event the repository was not cloned

    using the <code>--recursive</code> option, the following step must be taken to

    obtain all sources:</p>

    <pre><code># From within the CM4 parent directory

    git submodule update --init --recursive

    </code></pre>

    <h2>

    <a id="user-content-source-code" class="anchor" href="#source-code" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Source Code</h2>

    <p>All model source is contained in the <a href="src">src</a> directory.  GFDL

    tracks code using the git version control system.  This package

    includes a single version of the following GFDL model components.  The

    git hash listed corresponds to the commit hash in the internal GFDL

    git repository.</p>

    <table>

    <thead>

    <tr>

    <th>Component</th>

    <th>Commit Hash</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td>atmos_cubed_sphere</td>

    <td>b8b05bf650c0d3293b538bdaceb894ba0fd6910b</td>

    </tr>

    <tr>

    <td>atmos_drivers</td>

    <td>3be6ed406de2db29766746a69115fd6a47048692</td>

    </tr>

    <tr>

    <td>atmos_param</td>

    <td>4fe4ca54a0224ef5c4cf9ebf1010d5b869930a3f</td>

    </tr>

    <tr>

    <td>atmos_shared</td>

    <td>2e9d8b770cdb2d70d8d9264e4b2de24213ae21bd</td>

    </tr>

    <tr>

    <td>land_lad2</td>

    <td>154bd2b4bf523f3e699de5017679b156242ec13f</td>

    </tr>

    </tbody>

    </table>

    <p>The following components are available in the

    <a href="https://github.com/NOAA-GFDL">NOAA-GFDL</a> github organization:</p>

    <ul>

    <li><a href="https://github.com/NOAA-GFDL/MOM6">MOM6</a></li>

    <li><a href="https://github.com/NOAA-GFDL/SIS2">SIS2</a></li>

    <li>

    <a href="https://github.com/NOAA-GFDL/GFDL_atmos_cubed_sphere/tree/AM4.0">GFDL_atmos_cubed_sphere</a>
    (as <a href="src/atmos_cubed_sphere">atmos_cubed_sphere</a>)</li>

    <li><a href="https://github.com/NOAA-GFDL/icebergs">icebergs</a></li>

    <li><a href="https://github.com/NOAA-GFDL/ice_param">ice_param</a></li>

    <li><a href="https://github.com/NOAA-GFDL/ocean_BGC">ocean_BGC</a></li>

    <li><a href="https://github.com/NOAA-GFDL/FMScoupler">coupler</a></li>

    <li>

    <a href="https://github.com/NOAA-GFDL/FMS">FMS</a> (as <a href="src/shared">shared</a>)</li>

    <li><a href="https://github.com/NOAA-GFDL/mocsy">mocsy</a></li>

    </ul>

    <h2>

    <a id="user-content-building-cm4" class="anchor" href="#building-cm4" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Building CM4</h2>

    <p>The <a href="exec">exec</a> directory contains Makefiles that can be used to

    build the CM4 executable.  These Makefiles were generated using the

    <a href="https://github.com/NOAA-GFDL/mkmf">Make Makefile (mkmf)</a> program.

    Included in the exec direcgtory is a sample make template file for the

    Intel compilers (<a href="exec/templates/intel.mk">intel.mk</a>).  This make

    template can be used on any system with a relatively recent version of

    the Intel compilers, the netCDF 4 library and the MPICH2 MPI library.

    Included in the <a href="exec/templates/intel.mk">intel.mk</a> file are

    additional settings that can be modified during the build.</p>

    <p>To run the default build (-O3 -msse2), go to the exec directory and

    enter the command</p>

    <pre><code>make HDF_INCLUDE=-I/path/to/hdf5/include

    </code></pre>

    <p>Where <em>/path/to/hdf5/include</em> is the path to your HDF5 include folder
    where hdf5.mod

    is.</p>

    <p>If you would like to change some of the compiler options, there are several
    different

    options to add to the make command.  For example</p>

    <pre><code>make ISA=-xhost REPRO=on

    </code></pre>

    <p>will replace -msse with -xhost and -O3 with -O2.  The three options for

    building are<br>

    <code>PROD=on</code> (-O3) Default

    <code>REPRO=on</code> (-O2)<br>

    <code>DEBUG=on</code> (-O0 and other traps)<br>

    All of the make line options can be

    found in the <a href="exec/templates/intel.mk">intel.mk</a> file.</p>

    <p>To build with GNU compilers, add <code>gcc=on</code> to the <code>make</code>
    line. The make line

    options can be found in the <a href="exec/templates/gnu.mk">gnu.mk</a> file.</p>

    <h2>

    <a id="user-content-obtaining-the-input-data" class="anchor" href="#obtaining-the-input-data"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Obtaining
    the input data</h2>

    <p>The input data required for running the CM4 model can be found on

    <a href="http://data1.gfdl.noaa.gov/nomads/forms/cm4/" rel="nofollow">GFDL''s
    data

    portal</a> .</p>

    <p>The file <code>CM4_runDir.tar.gz</code> contains a configured run directory
    to run a

    sample experiment of the CM4 model.  Included in the tar file is a

    README.CM4 with more instructions on how to configure the CM4 run

    directory.</p>

    <h2>

    <a id="user-content-running-cm4" class="anchor" href="#running-cm4" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running CM4</h2>

    <p>Included in the run directory is a sample run script for reference.

    To run the CM4 sample experiment, first download the data file

    mentioned in <a href="#obtaining-the-input-data">Obtaining the Input data</a>

    section.  Modify the variables in the configuration section in the

    sample run script, and then run the script.</p>

    <p>The sample data and run script are configured to run on a total of 8127

    processors (864 cores 4 threads for the atmosphere and 4671 ocean cores).<br>

    To run on a different number of processors, or modify the

    experiment, refer to the <code>README.CM4</code> file included in the CM4

    data tarball.</p>

    <p>Note: The <code>input.nml</code> file (found in the CM4 data tarball) contains

    Fortran namelists and namelist variables that modify, at run time, the

    model.  To learn more about the settings in the <code>input.nml</code> file,

    please refer to source code where the namelist/variable are defined.</p>

    <h2>

    <a id="user-content-model-output-and-other-references" class="anchor" href="#model-output-and-other-references"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Model
    output and Other References</h2>

    <p>Please refer to the <a href="http://data1.gfdl.noaa.gov/nomads/forms/cm4/"
    rel="nofollow">CM4 data and code

    site</a> for details

    about where to find model and OBS data used in the papers.</p>

    <p>For all analysis figures and pertaining data, please use the CM4

    documentation papers as the original reference.</p>

    <p>Please direct your questions and feedback to

    <a href="mailto:gfdl.climate.model.info@noaa.gov">gfdl.climate.model.info@noaa.gov</a></p>

    <h2>

    <a id="user-content-disclaimer" class="anchor" href="#disclaimer" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is

    provided on an ''as is'' basis and the user assumes responsibility for

    its use.  DOC has relinquished control of the information and no

    longer has responsibility to protect the integrity, confidentiality,

    or availability of the information.  Any claims against the Department

    of Commerce stemming from the use of its GitHub project will be

    governed by all applicable Federal law.  Any reference to specific

    commercial products, processes, or services by service mark,

    trademark, manufacturer, or otherwise, does not constitute or imply

    their endorsement, recommendation or favoring by the Department of

    Commerce.  The Department of Commerce seal and logo, or the seal and

    logo of a DOC bureau, shall not be used in any manner to imply

    endorsement of any commercial product or activity by DOC or the United

    States Government.</p>

    <p>This project code is made available through GitHub but is managed by

    NOAA-GFDL at <a href="https://gitlab.gfdl.noaa.gov" rel="nofollow">https://gitlab.gfdl.noaa.gov</a>.</p>

    '
  stargazers_count: 1
  subscribers_count: 4
  topics: []
  updated_at: 1622054482.0
NOAA-GFDL/ESM4:
  data_format: 2
  description: null
  filenames:
  - containers/Singularity.intel_netcdf
  - containers/Singularity.esm4
  - containers/Singularity.intel_esm4
  full_name: NOAA-GFDL/ESM4
  latest_release: '2021.02'
  readme: '<h1>

    <a id="user-content-earth-system-model-4" class="anchor" href="#earth-system-model-4"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Earth
    System Model 4</h1>

    <h2>

    <a id="user-content-what-is-included" class="anchor" href="#what-is-included"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>What
    Is Included</h2>

    <ul>

    <li>[src/]((<a href="https://github.com/NOAA-GFDL/ESM4/tree/master/src">https://github.com/NOAA-GFDL/ESM4/tree/master/src</a>)
    source code for the ESM4 model (all code is in submodules)</li>

    <li>[exec/]((<a href="https://github.com/NOAA-GFDL/ESM4/tree/master/exec">https://github.com/NOAA-GFDL/ESM4/tree/master/exec</a>)
    Makefiles to compile the code</li>

    <li>[run/]((<a href="https://github.com/NOAA-GFDL/ESM4/tree/master/run">https://github.com/NOAA-GFDL/ESM4/tree/master/run</a>)
    Simple run script</li>

    </ul>

    <h2>

    <a id="user-content-cloning" class="anchor" href="#cloning" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Cloning</h2>

    <p>To clone the ESM4 model please use the recursive option</p>

    <div class="highlight highlight-source-shell"><pre>git clone --recursive git@github.com:NOAA-GFDL/ESM4.git
    </pre></div>

    <p>or</p>

    <div class="highlight highlight-source-shell"><pre>git clone --recursive https://github.com/NOAA-GFDL/ESM4.git</pre></div>

    <h2>

    <a id="user-content-compiling" class="anchor" href="#compiling" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Compiling</h2>

    <p>This model was originally compiled and run with the intel16 compiler.

    It is recommended that you compile with an intel compiler.</p>

    <p>Compiling assumes that you have an intel compiler, MPI (impi, mpich,

    openmpi, etc), netcdf, and hdf5 in your LD_LIBRARY_PATH and LIBRARY_PATH.

    It is also assumed that nf-config and nc-config are in your path.

    If you work on a machine with modules, you may need to load these

    packages into your environment.</p>

    <p>Makefiles have been included in the

    <a href="https://github.com/NOAA-GFDL/ESM4/tree/master/exec">exec/</a> folder.

    There are several option for compiling, which can be found in the

    <a href="https://github.com/NOAA-GFDL/ESM4/blob/master/exec/templates/intel.mk">template/intel.mk</a>.<br>

    You may need to edit the template/intel.mk to update the compiler names

    or add any CPPDEF options specific for your system.

    The most common compile with optimizations on and with openmp would be</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">cd</span>
    <span class="pl-c1">exec</span>

    make OPENMP=on</pre></div>

    <p>If you would like to compile with <em>-O2</em> instead of <em>-O3</em> do</p>

    <div class="highlight highlight-source-shell"><pre>make REPRO=on OPENMP=on</pre></div>

    <p>To compile with <em>-O0</em> and debug flags do</p>

    <div class="highlight highlight-source-shell"><pre>make DEBUG=on OPENMP=on</pre></div>

    <p>Compiling with openMP is optional.</p>

    <p>Here are examples of how to compile the model on various systems:</p>

    <p>gaea (NOAA RDHPCS cray system)</p>

    <div class="highlight highlight-source-shell"><pre>module load intel

    module load cray-netcdf

    module load cray-hdf5

    git clone --recursive git@github.com:NOAA-GFDL/ESM4.git

    <span class="pl-c1">cd</span> ESM4/exec

    make MKL_LIBS=<span class="pl-s"><span class="pl-pds">"</span>none<span class="pl-pds">"</span></span>
    OPENMP=y</pre></div>

    <p>Compiling on orion (MSU)</p>

    <div class="highlight highlight-source-shell"><pre>module load intel impi netcdf
    hdf5

    <span class="pl-k">export</span> LIBRARY_PATH=<span class="pl-smi">${LIBRARY_PATH}</span>:<span
    class="pl-smi">${LD_LIBRARY_PATH}</span>

    git clone --recursive git@github.com:NOAA-GFDL/ESM4.git

    <span class="pl-c1">cd</span> ESM4/exec

    make OPENMP=on</pre></div>

    <h2>

    <a id="user-content-model-running" class="anchor" href="#model-running" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Model running</h2>

    <p>A work directory needed for running the model can be obtained from

    <a href="ftp://data1.gfdl.noaa.gov/users/ESM4/ESM4Documentation/GFDL-ESM4/inputData/ESM4_rundir.tar.gz"
    rel="nofollow">ftp://data1.gfdl.noaa.gov/users/ESM4/ESM4Documentation/GFDL-ESM4/inputData/ESM4_rundir.tar.gz</a></p>

    <p>The directory contains input.nml as the namelist, various input tables needed

    for running the model, and model input files in a folder called INPUT/.  There

    is also a directory named RESTART/ that should be empty at the beginning of

    each run.</p>

    <p>There is a skeleton of a run script named <a href="https://github.com/NOAA-GFDL/ESM4/blob/master/run/ESM4_run.sh">run/ESM4_run.sh</a>.  You
    must update this

    script to run the model.  Include a path to the work directory and the executable.

    You should also update the program you need to run the model on your system.  The

    default for this script is <code>srun</code>.</p>

    <h2>

    <a id="user-content-disclaimer" class="anchor" href="#disclaimer" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Disclaimer</h2>

    <p>The United States Department of Commerce (DOC) GitHub project code is provided

    on an ''as is'' basis and the user assumes responsibility for its use. DOC has

    relinquished control of the information and no longer has responsibility to

    protect the integrity, confidentiality, or availability of the information. Any

    claims against the Department of Commerce stemming from the use of its GitHub

    project will be governed by all applicable Federal law. Any reference to

    specific commercial products, processes, or services by service mark,

    trademark, manufacturer, or otherwise, does not constitute or imply their

    endorsement, recommendation or favoring by the Department of Commerce. The

    Department of Commerce seal and logo, or the seal and logo of a DOC bureau,

    shall not be used in any manner to imply endorsement of any commercial product

    or activity by DOC or the United States Government.</p>

    '
  stargazers_count: 3
  subscribers_count: 5
  topics:
  - gfdl
  - ems
  - ems4
  - fms
  - climate
  - model
  - fortran
  updated_at: 1622050940.0
Nahuel-Mk2/def-space:
  data_format: 2
  description: Def File of Singularity
  filenames:
  - def/lafin.def
  - def/wav2pix.def
  - def/contextual-attention.def
  - def/singan.def
  - def/stargan.def
  - def/edge-connect.def
  - def/vae-mnist.def
  - def/sc-fegan.def
  full_name: Nahuel-Mk2/def-space
  latest_release: null
  readme: '<h1>

    <a id="user-content-def-space" class="anchor" href="#def-space" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>def-space</h1>

    <p>This repository is def-space for Singularity</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1606189900.0
Samip1211/MongoImage:
  data_format: 2
  description: null
  filenames:
  - Singularity
  full_name: Samip1211/MongoImage
  latest_release: null
  readme: '<h1>

    <a id="user-content-singularity-cudaxgboost" class="anchor" href="#singularity-cudaxgboost"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>singularity-cudaxgboost</h1>

    <p>Singularity container definition for XGBoost/hipe4ml environment</p>

    <p>This is a minimal container for running Hipe4ML (<a href="https://github.com/hipe4ml/hipe4ml">https://github.com/hipe4ml/hipe4ml</a>)
    with XGBoost, including NVidia GPU support with CUDA 11.0. Based on the official
    CUDA image from NVidia, <a href="https://hub.docker.com/r/nvidia/cuda" rel="nofollow">https://hub.docker.com/r/nvidia/cuda</a>.</p>

    <p>NOTE: If using a GPU method in XGBoost such as "gpu_tree", the container must
    be run with the --nv switch (e.g. "singularity exec --nv [COMMAND]") in order
    to access the driver binaries on the host machine.</p>

    <p>This environment is also compatible with CPU-only running of Hipe4ML on any
    host machine, without any additional setup.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1565456485.0
Samip1211/flaskrestful_mongo:
  data_format: 2
  description: null
  filenames:
  - Singularity
  full_name: Samip1211/flaskrestful_mongo
  latest_release: null
  readme: '<h1>

    <a id="user-content-singularity-cudaxgboost" class="anchor" href="#singularity-cudaxgboost"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>singularity-cudaxgboost</h1>

    <p>Singularity container definition for XGBoost/hipe4ml environment</p>

    <p>This is a minimal container for running Hipe4ML (<a href="https://github.com/hipe4ml/hipe4ml">https://github.com/hipe4ml/hipe4ml</a>)
    with XGBoost, including NVidia GPU support with CUDA 11.0. Based on the official
    CUDA image from NVidia, <a href="https://hub.docker.com/r/nvidia/cuda" rel="nofollow">https://hub.docker.com/r/nvidia/cuda</a>.</p>

    <p>NOTE: If using a GPU method in XGBoost such as "gpu_tree", the container must
    be run with the --nv switch (e.g. "singularity exec --nv [COMMAND]") in order
    to access the driver binaries on the host machine.</p>

    <p>This environment is also compatible with CPU-only running of Hipe4ML on any
    host machine, without any additional setup.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1502317691.0
UPPMAX/install-methods:
  data_format: 2
  description: Install methods for UPPMAX modules plus some helper scripts
  filenames:
  - singularity_info/metaWRAP_1.3.2/Singularity.metaWRAP
  - singularity_info/bonito/Singularity.bonito
  - singularity_info/gapseq-RT-227932/Singularity.gapseq
  full_name: UPPMAX/install-methods
  latest_release: null
  readme: '<h1>

    <a id="user-content-module-installation-methods" class="anchor" href="#module-installation-methods"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Module
    Installation Methods</h1>

    <p>This is a collection of READMEs generated during installation of software

    applications on Uppmax clusters.  It is incomplete in terms of modules

    available on Uppmax, and the individual READMEs may also be incomplete in terms

    of what was actually done to install the modules.  We are publicising these in

    the hopes that they can be helpful.</p>

    <h2>

    <a id="user-content-example-workflow-of-a-basic-installation" class="anchor" href="#example-workflow-of-a-basic-installation"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Example
    workflow of a basic installation</h2>

    <ol>

    <li>Clone the install methods git repo (<code>git clone https://github.com/UPPMAX/install-methods.git</code>)</li>

    <li>Add the repo to your <code>$PATH</code> and source the <code>uppmax_functions.sh</code>
    file to get access to the functions.</li>

    <li>Run <code>run_makeroom</code> with at least <code>-t</code> and <code>-v</code>,
    to generate a <code>.sh</code> (<code>makeroom_toolname_version.sh</code>) file
    that will create the directory structure needed in <code>/sw</code>

    </li>

    <li>Run the <code>.sh</code> file created in the directory you are standing to
    create the directory structure (<code>/sw/category/toolname/</code> and <code>/sw/mf/common/category</code>)
    and template files.</li>

    <li>Put the source code for the program in <code>/sw/category/toolname/version/src</code>

    </li>

    <li>Compile and/or install the tool in <code>/sw/category/toolname/version/cluster/bin</code>
    etc.</li>

    <li>Edit the readme file, explaining how you did the installation, in <code>/sw/category/toolname/toolname-version_install-README.md</code>

    </li>

    <li>Edit the template module file <code>/sw/category/toolname/mf/version</code>
    to do what you want when the module loads.</li>

    <li>Copy the module file to the live location, <code>/sw/mf/common/category/[section]/toolname</code>

    </li>

    <li>Run <code>all_mflink toolname version</code> to create links for all clusters
    to the module file in <code>/sw/mf/common/category/[section]/toolname</code>

    </li>

    <li>Run <code>fixup /sw/category/toolname/version /sw/mf/common/category/[section]/toolname</code>
    to make sure the ownership and permissions are ok.</li>

    </ol>

    <h2>

    <a id="user-content-scripts" class="anchor" href="#scripts" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Scripts</h2>

    <p><code>gather-READMEs.sh</code> - bash script to scan installation directories,
    looking for

    README files having a particular filename format that we create during

    installation of tools</p>

    <p><code>fixup</code> - bash script fixing up permissions and group membership
    within

    installation trees; our local installation group is <code>sw</code>. With the
    <code>-g</code> option,

    this script will <code>chmod g+s</code> directories in the tree, too.</p>

    <p><code>uppmax_functions.sh</code> - bash helper functions for SLURM job viewing
    and various

    module-related tasks, mostly to do with setting up mf files for loading

    modules; the latter require appexpert privileges.  Source these from <code>.bashrc</code>.</p>

    <h2>

    <a id="user-content-installation-directories" class="anchor" href="#installation-directories"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installation
    directories</h2>

    <p>The directories contain software installations in major subject areas.</p>

    <h3>

    <a id="user-content-apps" class="anchor" href="#apps" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>apps/</h3>

    <p>General applications.</p>

    <h3>

    <a id="user-content-appsbioinfo" class="anchor" href="#appsbioinfo" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>apps/bioinfo/</h3>

    <p>Bioinformatics applications.</p>

    <h3>

    <a id="user-content-libs" class="anchor" href="#libs" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>libs/</h3>

    <p>Libraries.</p>

    <h3>

    <a id="user-content-comp" class="anchor" href="#comp" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>comp/</h3>

    <p>Compilers, interpreters, build tools.</p>

    <h2>

    <a id="user-content-database-directories" class="anchor" href="#database-directories"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Database
    directories</h2>

    <p>These directories cover installations of databases updated either manually,
    or via update scripts.</p>

    <h3>

    <a id="user-content-data_uppnex" class="anchor" href="#data_uppnex" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>data_uppnex/</h3>

    <p>Installation instructions for databases under <code>/sw/data/uppnex/</code>.  Database

    directories containing <code>*-install-README.md</code> files are updated manually.

    Database directories containing <code>*-db-README.md</code> files and scripts
    (currently,

    <code>Kraken</code>, <code>diamond_databases</code> and <code>RTG</code>) are
    updated monthly via crontab entries.</p>

    <p>Blast database updates are included here, and involve multiple scripts, crontab

    entries and a test directory.  These are updated monthly via crontab entries.</p>

    <h3>

    <a id="user-content-data_other" class="anchor" href="#data_other" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>data_other/</h3>

    <p>Installation instructions for databases under other locations, currently just

    <code>BUSCO</code> lineage sets, which are kept in the module installation directory.

    These are updated monthly via crontab entries.</p>

    '
  stargazers_count: 3
  subscribers_count: 5
  topics: []
  updated_at: 1622024893.0
achennings/neurodocker:
  data_format: 2
  description: Custom implementation of neurodocker (https://github.com/ReproNim/neurodocker)
  filenames:
  - Singularity
  full_name: achennings/neurodocker
  latest_release: null
  readme: '<h1>

    <a id="user-content-neurodocker" class="anchor" href="#neurodocker" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>neurodocker</h1>

    <p>Custom implementation of neurodocker (<a href="https://github.com/ReproNim/neurodocker">https://github.com/ReproNim/neurodocker</a>)</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1622304898.0
aleks96n/BioInfoKallisto:
  data_format: 2
  description: 'Benchmark kallisto against HISAT2 + featureCounts in eQTL mapping '
  filenames:
  - qtlmap/Singularity
  full_name: aleks96n/BioInfoKallisto
  latest_release: null
  readme: '<h1>

    <a id="user-content-bioinfokallisto" class="anchor" href="#bioinfokallisto" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>BioInfoKallisto</h1>

    <p>Benchmark kallisto against HISAT2 + featureCounts in eQTL mapping</p>

    <h1>

    <a id="user-content-step-1---installing-kallisto" class="anchor" href="#step-1---installing-kallisto"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Step
    1 - installing kallisto</h1>

    <p>It is highly encouraged to use <a href="https://hpc.ut.ee/en/guides/slurm/"
    rel="nofollow">HPC</a>. Not only will this speed up the analysis, but will also
    give access to some important files that you cannot get easily without the use
    of HPC.</p>

    <p>Install <a href="https://docs.conda.io/en/latest/miniconda.html" rel="nofollow">miniconda</a>
    for Linux, newest Python version (version 3.9 as of this edit).</p>

    <p>Put it in your HCP using the following bash command (alternatively, use FileZilla).
    Once it is in place, run the second command to install miniconda</p>

    <div class="highlight highlight-source-shell"><pre>scp <span class="pl-k">&lt;</span>filename<span
    class="pl-k">&gt;</span> user@rocket.hpc.ut.ee:directoy

    bash <span class="pl-k">&lt;</span>conda file<span class="pl-k">&gt;</span></pre></div>

    <p>Restart HPC before doing executing any more commands. After restarting, run
    the following command to install kallisto.</p>

    <div class="highlight highlight-source-shell"><pre>conda install -c bioconda kallisto</pre></div>

    <h1>

    <a id="user-content-step-2---creating-the-transcript-file-for-kallisto" class="anchor"
    href="#step-2---creating-the-transcript-file-for-kallisto" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Step 2 - creating the
    transcript file for kallisto</h1>

    <p>Copy the genotype transcripts file to your work directory (where the makeTranscript.sh
    is located). Note that you can change the name of the transcripts.fa file, however,
    you will have to modify bash script for parallezation.</p>

    <div class="highlight highlight-source-shell"><pre>cp /gpfs/hpc/projects/genomic_references/annotations/eQTLCatalogue/v0.1/gencode.v30.transcripts.fa
    gencode.v30.transcripts.fa</pre></div>

    <p>Create a separate stage for your HPC</p>

    <div class="highlight highlight-source-shell"><pre>ssh stage1

    screen</pre></div>

    <p>If you want to be notified when the transcript file is created, modify the
    makeTranscript.sh file by adding the following two lines right after #SBATCH --mem=32G</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#</span>SBATCH
    --mail-type=END</span>


    <span class="pl-c"><span class="pl-c">#</span>SBATCH --mail-user=&lt;YOUR_EMAIL@EMAIL.DOMAIN&gt;</span></pre></div>

    <p>Run the bash script for parallelization, which is provided in the github repository.
    This process takes about 15 minutes. After it is finished, you should see a transcript.idx
    file in your work directory.</p>

    <div class="highlight highlight-source-shell"><pre>sbatch makeTranscript.sh</pre></div>

    <h1>

    <a id="user-content-step-3---creating-fastq-somethings-jens-you-got-this" class="anchor"
    href="#step-3---creating-fastq-somethings-jens-you-got-this" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Step 3 - Creating fastQ
    somethings (Jens you got this)</h1>

    <p>It is recommended to get acquainted with <a href="https://github.com/AlasooLab/onboarding/blob/main/resources/nextflow.md">nextflow</a>
    before moving further. However, it is optional.</p>

    <p>Run the following two commands (hopefully still on a separate stage) to create
    fastQ somethings. This takes approximately 3 and a half hours.</p>

    <div class="highlight highlight-source-shell"><pre>module load java-1.8.0_40

    ./nextflow makeFastq.nf --studyFile study_file.txt</pre></div>

    <p>Run the python script to create an out.tsv somethings and move it to the qtlmap
    testdata folder.</p>

    <div class="highlight highlight-source-shell"><pre>module load python

    python makeMatrix.py ResultsQ

    mv out.tsv qtlmap/testdata/out.tsv</pre></div>

    <h1>

    <a id="user-content-step-4---running-the-eqtl-analysis" class="anchor" href="#step-4---running-the-eqtl-analysis"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Step
    4 - Running the eQTL analysis</h1>

    <p>Navigate to the qtlmap directory</p>

    <div class="highlight highlight-source-shell"><pre><span class="pl-c1">cd</span>
    qtlmap</pre></div>

    <p>Finally, run the eQTL analysis using the following command (still on a separate
    stage). Note the end of the command asks for your email - this is for notifying
    when the work is done.</p>

    <div class="highlight highlight-source-shell"><pre>module load java-1.8.0_40

    module load singularity/3.5.3


    nextflow run main.nf -resume --run_permutation -profile tartu_hpc   --studyFile
    testdata/multi_test.tsv --vcf_has_R2_field FALSE    --varid_rsid_map_file testdata/varid_rsid_map.tsv.gz
    --n_batches 200 --run_nominal <span class="pl-c1">false</span> --email <span class="pl-s"><span
    class="pl-pds">"</span>sinu@email.com<span class="pl-pds">"</span></span></pre></div>

    <p>This should create a "results" folder. Most notable file is results/sumstats/GEUVADIS_test_ge.permuted.tsv.</p>

    <h1>

    <a id="user-content-step-5---comparing-with-other-results" class="anchor" href="#step-5---comparing-with-other-results"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Step
    5 - comparing with other results</h1>

    <p>Note that you require the kallisto file that you got from Step 4 and another
    .tsv file for comparison. In order to create the comparison, modify the "eQTLcomparison.r"
    script by adding appropriate file paths.</p>

    <div class="highlight highlight-source-shell"><pre>hisat <span class="pl-k">&lt;</span>-  read.csv(<span
    class="pl-s"><span class="pl-pds">"</span>&lt;comparison_file.tsv&gt;<span class="pl-pds">"</span></span>,
    sep = <span class="pl-s"><span class="pl-pds">''</span>\t<span class="pl-pds">''</span></span>,
    header = TRUE)

    kallista <span class="pl-k">&lt;</span>- read.csv(<span class="pl-s"><span class="pl-pds">"</span>&lt;kallisto.tsv&gt;<span
    class="pl-pds">"</span></span>, sep = <span class="pl-s"><span class="pl-pds">''</span>\t<span
    class="pl-pds">''</span></span>, header = TRUE)</pre></div>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1622297189.0
baxpr/bedpost-singularity:
  data_format: 2
  description: null
  filenames:
  - Singularity
  full_name: baxpr/bedpost-singularity
  latest_release: null
  readme: '<p>Runs FSL''s bedpostx on the input DWI data set, and creates a PDF report
    of the results.

    Quite simple - see /opt/src/pipeline.sh for the main script.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1621804490.0
cibiobcg/PaCBAM:
  data_format: 2
  description: Fast and scalable NGS data processing
  filenames:
  - Singularity
  full_name: cibiobcg/PaCBAM
  latest_release: null
  readme: '<h1>

    <a id="user-content-pacbam" class="anchor" href="#pacbam" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>PaCBAM</h1>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1578735123.0
clemsonciti/singularity-images:
  data_format: 2
  description: Scripts for building Singularity images
  filenames:
  - tensorflow/ubuntu.def
  - mxnet/ubuntu.def
  - caffe2/ubuntu.def
  - dl/ubuntu.def
  - circuitscape/ubuntu.def
  - caffe/ubuntu.def
  full_name: clemsonciti/singularity-images
  latest_release: null
  readme: '<h1>

    <a id="user-content-singularity-image-scripts" class="anchor" href="#singularity-image-scripts"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Singularity
    image scripts</h1>

    <p>Scripts to generate singularity images

    for running different software on Palmetto cluster.</p>

    '
  stargazers_count: 10
  subscribers_count: 5
  topics: []
  updated_at: 1597386388.0
deepakagg123/singularity_test:
  data_format: 2
  description: null
  filenames:
  - Singularity
  full_name: deepakagg123/singularity_test
  latest_release: null
  readme: '<h1>

    <a id="user-content-singularity_test" class="anchor" href="#singularity_test"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>singularity_test</h1>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1622100688.0
edg1983/WGS_pipeline:
  data_format: 2
  description: null
  filenames:
  - singularity/Singularity.align_dedup.v1.0
  - singularity/Singularity.bcftools.v1.10.2
  - singularity/Singularity.sv_call.v1.0
  - singularity/Singularity.expansion_hunter.v3.2.2
  - singularity/Singularity.vcf_processing.v1.0
  - singularity/Singularity.qcbam.v1.0
  - singularity/Singularity.sv_processing.v1.0
  full_name: edg1983/WGS_pipeline
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-wgs-analysis-pipeline\" class=\"anchor\" href=\"\
    #wgs-analysis-pipeline\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>WGS analysis pipeline</h1>\n<p>WGS analysis\
    \ pipeline. Can handle both WGS and WES data.</p>\n<p>The whole pipeline use singularity\
    \ images and will pull images from singularity libraries when needed</p>\n<h2>\n\
    <a id=\"user-content-how-to-run\" class=\"anchor\" href=\"#how-to-run\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How\
    \ to run</h2>\n<p>The pipeline can be run directly using Nextflow &gt;= v20.10.</p>\n\
    <pre><code>nextflow WGS_analysis.nf -profile cluster --operation align --input\
    \ input_file.txt --mode WGS --ped ped_file.ped --cohort_id cohort_name --outdir\
    \ results\n</code></pre>\n<p>The pipeline automatically infer the number of samples\
    \ in the cohort from your input file. When more than one sample is present, small\
    \ variants and structural variants from all samples are merged in cohort wide\
    \ VCF files.</p>\n<p>Eventually update <code>singularity_cachedir</code> variable\
    \ in <code>nextflow.config</code> to point to a proper folder where singularity\
    \ images are stored / will be downloaded</p>\n<p>A bash script <code>Run_pipeline.sh</code>\
    \ is provided for convenience to set environmental variables for singularity cache\
    \ and temp directories. The <code>singularity_dir</code> variable in the script\
    \ must match <code>singularity_cachedir</code> variable in <code>nextflow.config</code>.</p>\n\
    <h3>\n<a id=\"user-content-arguments\" class=\"anchor\" href=\"#arguments\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Arguments</h3>\n\
    <pre><code>operation   :   align or call_variants\nmode        :   WGS or WES\n\
    input       :   tab-separated file describing input files. \n                The\
    \ exact format depends on operation requested (see below)\nped         :   standard\
    \ PED file containing all samples\ncohort_id   :   a arbitrary name for the cohort\
    \ files generated\noutdir      :   output folder for results\n</code></pre>\n\
    <h2>\n<a id=\"user-content-input-files-format\" class=\"anchor\" href=\"#input-files-format\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Input files format</h2>\n<h3>\n<a id=\"user-content-ped-file\" class=\"\
    anchor\" href=\"#ped-file\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>PED file</h3>\n<p>A standard tab-separated PED\
    \ file without header, describing all samples provided in the input file. All\
    \ sample IDs must match between ped and input file. All samples must have sex\
    \ defined.</p>\n<pre><code>family_ID   individual_ID   father_ID   mother_ID \
    \  sex(1=M,2=F)    status(1=unaff,2=aff,0=unknown)\n</code></pre>\n<h3>\n<a id=\"\
    user-content-input-file\" class=\"anchor\" href=\"#input-file\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>input\
    \ file</h3>\n<p>Note that all files need to be specified using <strong>absolute\
    \ paths</strong></p>\n<h4>\n<a id=\"user-content-operation-align\" class=\"anchor\"\
    \ href=\"#operation-align\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Operation: align</h4>\n<p>A 3 columns tab-separated\
    \ file without header</p>\n<pre><code>sampleID1   s1_lane1_R1.fastq.gz    s1_lane1_R2.fastq.gz\n\
    sampleID1   s1_lane2_R1.fastq.gz    s1_lane2_R2.fastq.gz\nsampleID2   s2_lane2_R1.fastq.gz\
    \    s2_lane2_R2.fastq.gz\n</code></pre>\n<p>Note that if a sample has been sequenced\
    \ with multiple pairs of fastq files you need to add multiple lines for each pair\
    \ of fastq files using the same sampleID. The pipeline will take care of the merge.</p>\n\
    <h4>\n<a id=\"user-content-operation-call_variants\" class=\"anchor\" href=\"\
    #operation-call_variants\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Operation: call_variants</h4>\n<p>A 5 columns\
    \ tab-separated file without header.\nThis file is automatically generated when\
    \ using <code>--operation align</code> (bam_files.txt)</p>\n<pre><code>sampleID1\
    \   main_bam.bam    disc.bam    split.bam\nsampleID2   main_bam.bam    disc.bam\
    \    split.bam\nsampleID3   main_bam.bam    disc.bam    split.bam\n</code></pre>\n\
    <h2>\n<a id=\"user-content-pipeline-components\" class=\"anchor\" href=\"#pipeline-components\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Pipeline components</h2>\n<ol>\n<li>Alignement and duplicate marking\n\
    <ul>\n<li>BWA + samblaster + samtools</li>\n</ul>\n</li>\n<li>QC and coverage\
    \ from BAM files\n<ul>\n<li>fastqc: reads stats</li>\n<li>mosdepth: coverage</li>\n\
    <li>samtools flagstat / mapstat: alignment stats</li>\n<li>somalier: ancestry,\
    \ relatedness, sex check reports</li>\n<li>multiqc: interactive report</li>\n\
    </ul>\n</li>\n<li>small variants\n<ul>\n<li>deepvariant: single sample calls</li>\n\
    <li>glnexus: gvcf merge</li>\n</ul>\n</li>\n<li>structural variants\n<ul>\n<li>lumpy:\
    \ structural variants events</li>\n<li>CNVnator: CNV estimation</li>\n<li>svtools:\
    \ combine, merge and classify</li>\n</ul>\n</li>\n<li>repeat expansion detection\n\
    <ul>\n<li>expansion hunter</li>\n</ul>\n</li>\n<li>ROH regions\n<ul>\n<li>bcftools\
    \ ROH</li>\n</ul>\n</li>\n</ol>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1622127855.0
fzimmermann89/idi:
  data_format: 2
  description: Simulating, Reconstructing and Analysing Data for FEL IDI Experiments
  filenames:
  - Singularity.simple
  - Singularity.py38
  - Singularity
  full_name: fzimmermann89/idi
  latest_release: '210531'
  readme: '<p>CAVE: Hic sunt dracones</p>

    <p><em>The code is a mess, undocumented and only certain code paths are tested.</em></p>

    <h1>

    <a id="user-content-idi---incoherent-diffraction-imaging" class="anchor" href="#idi---incoherent-diffraction-imaging"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>IDI
    - INCOHERENT DIFFRACTION IMAGING</h1>

    <p><a href="https://singularity-hub.org/collections/4824" rel="nofollow"><img
    src="https://camo.githubusercontent.com/a07b23d4880320ac89cdc93bbbb603fa84c215d135e05dd227ba8633a9ff34be/68747470733a2f2f7777772e73696e67756c61726974792d6875622e6f72672f7374617469632f696d672f686f737465642d73696e67756c61726974792d2d6875622d2532336533323932392e737667"
    alt="https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg"
    data-canonical-src="https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg"
    style="max-width:100%;"></a>

    <a href="https://github.com/fzimmermann89/idi/actions/workflows/test.yml/badge.svg"
    target="_blank" rel="noopener noreferrer"><img src="https://github.com/fzimmermann89/idi/actions/workflows/test.yml/badge.svg"
    alt="tests" style="max-width:100%;"></a>

    <a href="https://camo.githubusercontent.com/a1aa13bc475e383774716a28c54db51e680a438815882cb99e8443eb94a873db/68747470733a2f2f7777772e7472617669732d63692e636f6d2f667a696d6d65726d616e6e38392f6964692e7376673f6272616e63683d6d6173746572"
    target="_blank" rel="nofollow"><img src="https://camo.githubusercontent.com/a1aa13bc475e383774716a28c54db51e680a438815882cb99e8443eb94a873db/68747470733a2f2f7777772e7472617669732d63692e636f6d2f667a696d6d65726d616e6e38392f6964692e7376673f6272616e63683d6d6173746572"
    alt="Build Status" data-canonical-src="https://www.travis-ci.com/fzimmermann89/idi.svg?branch=master"
    style="max-width:100%;"></a></p>

    <p>Singularity Image now at <a href="https://cloud.sylabs.io/library/_container/607b669a4ad4aa1fdea0c43c"
    rel="nofollow">library://fzimmermann89/idi/idi</a></p>

    <p>Conda Pacakges at <a href="https://anaconda.org/zimmf/idi" rel="nofollow">zimmf/idi</a></p>

    <p>PIP Source at <a href="https://pypi.org/project/idi/" rel="nofollow">idi</a></p>

    <p>Wheels at <a href="https://github.com/fzimmermann89/idi/releases/latest">Releases</a></p>

    <h2>

    <a id="user-content-content-of-the-repo" class="anchor" href="#content-of-the-repo"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>content
    of the repo</h2>

    <ul>

    <li>ipynb: example notebooks</li>

    <li>simulation: simulation of incoherent images</li>

    <li>reconstruction: direct and ft based reconstruction</li>

    <li>util: some small utilities for data analysis, geometry and random distributions,
    etc.</li>

    </ul>

    <h2>

    <a id="user-content-preparation-for-slac-sdf" class="anchor" href="#preparation-for-slac-sdf"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>preparation
    for slac sdf:</h2>

    <p>Use Singulariy, if using OOD launcher, use the following to start a jupyterhub</p>

    <pre><code>    function jupyter() { singularity run --app jupyter --nv -B /sdf,/gpfs,/scratch,/lscratch
    library://fzimmermann89/idi/idi $@; }

    </code></pre>

    <h2>

    <a id="user-content-preparation-for-sacla" class="anchor" href="#preparation-for-sacla"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>preparation
    for sacla:</h2>

    <ul>

    <li>Download and install miniconda, setup ssh tunnel for web access.</li>

    <li><code>conda create -n local3 python=3.7 numpy mkl mkl-dev ipython ipykernel
    cython jinja2 numba numexpr matplotlib six scipy jupyterlab</code></li>

    <li><code>conda activate local3</code></li>

    <li><code>pip install https://github.com/fzimmermann89/idi/</code></li>

    <li><code>python -m ipykernel install --user --name local-simulation-env3 --display-name
    "local simulation(py37)"</code></li>

    </ul>

    <p>(C) Felix Zimmermann</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - idi
  - reconstruction
  - simulation
  - xray
  - incoherent-images
  - fel
  updated_at: 1622507797.0
gipert/Singularity.def:
  data_format: 2
  description: My Singularity recipe files
  filenames:
  - bat/Singularity.def
  - asciinema/Singularity.def
  - arch-base/Singularity.def
  - centos-base/Singularity.def
  - lilypond/Singularity.def
  - gerda-tgsend/Singularity.def
  - root-cern/Singularity.def
  - julia/Singularity.def
  - itunes/Singularity.def
  - texlive/Singularity.def
  full_name: gipert/Singularity.def
  latest_release: null
  readme: '<h1>

    <a id="user-content-singularity-recipe-files" class="anchor" href="#singularity-recipe-files"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Singularity
    recipe files</h1>

    <p><a href="https://github.com/sylabs/singularity">Singularity</a> containers
    I use the most on HPC clusters.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics:
  - singularity
  - containers
  updated_at: 1587858477.0
halbakri/singularity-vim:
  data_format: 2
  description: Singularity recipe for vm
  filenames:
  - Singularity
  full_name: halbakri/singularity-vim
  latest_release: null
  readme: '<h1>

    <a id="user-content-singularity-vim" class="anchor" href="#singularity-vim" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>singularity-vim</h1>

    <p>Vim is a clone, with additions, of Bill Joy''s vi text editor program for Unix.</p>

    <hr>

    <p><a href="http://www.psc.edu" rel="nofollow">Pittsburgh Supercomputing Center</a>
    in the <a href="https://www.cmu.edu/mcs/" rel="nofollow">Mellon College of Science</a>
    at <a href="http://www.cmu.edu" rel="nofollow">Carnegie Mellon University</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1622145600.0
hariszaf/pema:
  data_format: 2
  description: 'PEMA: a flexible Pipeline for Environmental DNA Metabarcoding Analysis
    of the 16S/18S rRNA, ITS and COI marker genes'
  filenames:
  - Singularity
  - singularity/Singularity.latest
  - singularity/Singularity.v.1.3.1
  - singularity/Singularity.v.2.0.3
  - singularity/Singularity.v.1.1
  - singularity/Singularity.v.2.1.0
  - singularity/Singularity.v.2.0.2
  - singularity/Singularity.v.2.1.3
  - singularity/Singularity.v.1.3
  - singularity/Singularity.v.1.3.2
  full_name: hariszaf/pema
  latest_release: v1.2
  readme: "<p align=\"center\">\n  <a href=\"https://camo.githubusercontent.com/762c1129f266494bbbb3faff3d673040cf7b1f19d45c6e13f49b08de12f5116a/68747470733a2f2f692e70617374652e706963732f38373031383966616466363638613935386338616163383366333865373939632e706e67\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/762c1129f266494bbbb3faff3d673040cf7b1f19d45c6e13f49b08de12f5116a/68747470733a2f2f692e70617374652e706963732f38373031383966616466363638613935386338616163383366333865373939632e706e67\"\
    \ width=\"300\" align=\"left\" data-canonical-src=\"https://i.paste.pics/870189fadf668a958c8aac83f38e799c.png\"\
    \ style=\"max-width:100%;\"></a>\n</p>\n<h1>\n<a id=\"user-content-pema\" class=\"\
    anchor\" href=\"#pema\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>PEMA:</h1>\n<h2>\n<a id=\"user-content-a-flexible-pipeline-for-environmental-dna-metabarcoding-analysis-of-the-16s18s-rrna-its-and-coi-marker-genes\"\
    \ class=\"anchor\" href=\"#a-flexible-pipeline-for-environmental-dna-metabarcoding-analysis-of-the-16s18s-rrna-its-and-coi-marker-genes\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>a flexible Pipeline for Environmental DNA Metabarcoding Analysis of\
    \ the 16S/18S rRNA, ITS and COI marker genes</h2>\n<p><em>PEMA is reposited in</em>\
    \ <a href=\"https://hub.docker.com/r/hariszaf/pema\" rel=\"nofollow\"><em>Docker\
    \ Hub</em></a> <em>as well as in</em> <a href=\"https://singularity-hub.org/collections/2295\"\
    \ rel=\"nofollow\"><em>Singularity Hub</em></a></p>\n<h4>\n<a id=\"user-content-a-pema-tutorial-can-be-found-here\"\
    \ class=\"anchor\" href=\"#a-pema-tutorial-can-be-found-here\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>A\
    \ PEMA tutorial can be found <a href=\"https://docs.google.com/presentation/d/1lVH23DPa2NDNBhVvOTRoip8mraw8zfw8VQwbK4vkB1U/edit?fbclid=IwAR14PpWfPtxB8lLBBnoxs7UbG3IJfkArrJBS5f2kRA__kvGDUb8wiJ2Cy_s#slide=id.g57f092f54d_1_21\"\
    \ rel=\"nofollow\"><strong>here</strong></a>.</h4>\n<h4>\n<a id=\"user-content-for-any-troubles-you-may-have-when-running-pema-or-for-any-potential-improvevments-you-would-like-to-suggest-please-share-on-the-pema-gitter-community\"\
    \ class=\"anchor\" href=\"#for-any-troubles-you-may-have-when-running-pema-or-for-any-potential-improvevments-you-would-like-to-suggest-please-share-on-the-pema-gitter-community\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>For any troubles you may have when running PEMA or for any potential\
    \ improvevments you would like to suggest, please share on the <a href=\"https://gitter.im/pema-helpdesk/community\"\
    \ rel=\"nofollow\">PEMA Gitter community</a>.</h4>\n\n<p><a href=\"https://gitter.im/pema-helpdesk/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/7385c04b449351f12fb57a4bd6f9791ebd68a483493399e50a8f096fadde4246/68747470733a2f2f6261646765732e6769747465722e696d2f70656d612d68656c706465736b2f636f6d6d756e6974792e737667\"\
    \ alt=\"Gitter\" data-canonical-src=\"https://badges.gitter.im/pema-helpdesk/community.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://www.gnu.org/licenses/gpl-3.0\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/400c4e52df43f6a0ab8a89b74b1a78d1a64da56a7848b9110c9d2991bb7c3105/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d47504c76332d626c75652e737667\"\
    \ alt=\"License: GPL v3\" data-canonical-src=\"https://img.shields.io/badge/License-GPLv3-blue.svg\"\
    \ style=\"max-width:100%;\"></a></p>\n<h1>\n<a id=\"user-content-table-of-contents\"\
    \ class=\"anchor\" href=\"#table-of-contents\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Table of Contents</h1>\n<ul>\n\
    <li><a href=\"#pema-biodiversity-in-all-its-different-levels\">PEMA: biodiversity\
    \ in all its different levels</a></li>\n<li><a href=\"#a-container-based-tool\"\
    > A container-based tool</a></li>\n<li>\n<a href=\"#how-to-run-pema\">How to run\
    \ PEMA</a>\n<ul>\n<li><a href=\"#parameters-file\">Parameters' file</a></li>\n\
    </ul>\n</li>\n<li>\n<a href=\"#pema-on-hpc\">PEMA on HPC</a>\n<ul>\n<li><a href=\"\
    #prerequisites-1\">Prerequisites</a></li>\n<li><a href=\"#installing-1\">Installing</a></li>\n\
    <li>\n<a href=\"#running-pema-1\">Running PEMA</a>\n<ul>\n<li><a href=\"#example\"\
    >Example</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<a href=\"#pema-on-a-simple-pc\"\
    >PEMA on a simple PC</a>\n<ul>\n<li><a href=\"#prerequisites\">Prerequisites</a></li>\n\
    <li><a href=\"#installing\">Installing</a></li>\n<li>\n<a href=\"#running-pema\"\
    >Running PEMA</a>\n<ul>\n<li><a href=\"#step-1---build-a-docker-container\">Step\
    \ 1 - Build a Docker container</a></li>\n<li><a href=\"#step-2---run-pema\">Step\
    \ 2 - Run PEMA</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#the-phyloseq-r-package\"\
    >phyloseq - for a downstream ecological analysis</a></li>\n<li><a href=\"#acknowledgments\"\
    >Acknowledgments</a></li>\n<li><a href=\"#license\">License</a></li>\n<li><a href=\"\
    #citation\">Citation</a></li>\n</ul>\n<div class=\"highlight highlight-source-diff\"\
    ><pre><span class=\"pl-mi1\"><span class=\"pl-mi1\">+</span> convertion of the\
    \ Illumina raw data is now implemented in the framework of PEMA</span>\n<span\
    \ class=\"pl-mi1\"><span class=\"pl-mi1\">+</span> PEMA now supports 2 extra marker\
    \ genes, 18S rRNA and ITS. </span>\n<span class=\"pl-mi1\"><span class=\"pl-mi1\"\
    >+</span> PEMA is now available for macOS!</span>\n<span class=\"pl-mi1\"><span\
    \ class=\"pl-mi1\">+</span> for anything feel free to contact me at: haris-zaf@hcmr.gr</span></pre></div>\n\
    \n<h1>\n<a id=\"user-content-pema-biodiversity-in-all-its-different-levels\" class=\"\
    anchor\" href=\"#pema-biodiversity-in-all-its-different-levels\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>PEMA:\
    \ biodiversity in all its different levels</h1>\n<p>PEMA supports the metabarcoding\
    \ analysis of four marker genes, <strong>16S rRNA</strong> (Bacteria), <strong>ITS</strong>\
    \ (Fungi) as well as <strong>COI</strong> and <strong>18S rRNA</strong> (metazoa).\
    \ As input, PEMA accepts .fastq.gz files as returned by Illumina sequencing platforms.</p>\n\
    <p>PEMA processes the reads from each sample and <strong>returns an OTU- or an\
    \ ASV-table with the taxonomies</strong> of the taxa found and their abundances\
    \ in each sample. It also returns statistics and a FASTQC diagram about the quality\
    \ of the reads for each sample. Finally, PEMA supports <strong>downstream ecological\
    \ analysis</strong> of the profiles retrieved, facilitated by the <a href=\"http://joey711.github.io/phyloseq/index.html\"\
    \ rel=\"nofollow\">phyloseq</a> R package.</p>\n<p>PEMA supports both OTU clustering\
    \ (thanks to VSEARCH and CROP algorithms) and ASV inference (via SWARM) for all\
    \ four marker genes.</p>\n<p>For the case of the 16S rRNA marker gene, PEMA includes\
    \ two separate approaches for taxonomy assignment: alignment-based and phylogenetic-based.\
    \ For the latter, a reference tree of 1000 taxa was created using SILVA_132_SSURef,\
    \ EPA-ng and RaxML-ng.</p>\n<p>PEMA has been implemented in <a href=\"https://pcingola.github.io/BigDataScript/\"\
    \ rel=\"nofollow\">BigDataScript</a> programming language. BDS\u2019s ad hoc task\
    \ parallelism and task synchronization, supports heavyweight computation. Thus,\
    \ PEMA inherits such features and it also supports roll-back checkpoints and on-demand\
    \ partial pipeline execution. In addition, PEMA takes advantage of all the computational\
    \ power available on a specific machine; for example, if PEMA is executed on a\
    \ personal laptop with 4 cores, it is going to use all four of them.</p>\n<p>Finally,\
    \ container-based technologies such as Docker and Singularity, make PEMA easy\
    \ accessible for all operating systems.\nAs you can see in the <a href=\"https://github.com/hariszaf/pema/blob/master/help_files/GitHub%20tutorial.pdf\"\
    >PEMA_tutorial.pdf</a>, once you have either Docker or Singularity on your computational\
    \ environment (see below which suits your case better), running PEMA is cakewalk.\
    \ You can also find the <a href=\"https://docs.google.com/presentation/d/1lVH23DPa2NDNBhVvOTRoip8mraw8zfw8VQwbK4vkB1U/edit?usp=sharing\"\
    \ rel=\"nofollow\"><strong>PEMA tutorial</strong></a> as a Google Slides file.</p>\n\
    \n<h1>\n<a id=\"user-content-a-container-based-tool\" class=\"anchor\" href=\"\
    #a-container-based-tool\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>A container-based tool</h1>\n<p>PEMA can run\
    \ either on a HPC environment (server, cluster etc) or on a simple PC. However,\
    \ we definitely suggest to run it on an HPC environment to exploit the full potential\
    \ of PEMA. Running on a powerful server or a cluster can be time-saving since\
    \ it would require significantly less computational time than in a common PC.\
    \ However, for analyses with a small number of samples, a common PC can suffice.</p>\n\
    <p>There is one <strong>major difference</strong> between running PEMA on a common\
    \ PC than running it on a HPC environment. In the first case, PEMA runs through\
    \ <a href=\"https://www.docker.com/\" rel=\"nofollow\"><strong>Docker</strong></a>,\
    \ while in the latter one, it runs through <a href=\"https://sylabs.io/singularity/\"\
    \ rel=\"nofollow\"><strong>Singularity</strong></a>.</p>\n<p>On the following\
    \ chapters, you can find how to install PEMA both in Docker and Singlularity including\
    \ examples.</p>\n<p>Running PEMA is exactly <strong>the same</strong> procedure\
    \ in both of those cases.</p>\n\n<h2>\n<a id=\"user-content-how-to-run-pema\"\
    \ class=\"anchor\" href=\"#how-to-run-pema\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>How to run PEMA</h2>\n<p>Assuming\
    \ you have either Docker or Singularity on your system (see below how to get them).\n\
    You need to create a directory where you will have everything PEMA needs - we\
    \ will call it <em><strong>analysis directory</strong></em>.</p>\n<p>In this directory,\
    \ you need to add the following <strong>mandatory</strong> files:</p>\n<ul>\n\
    <li>the <a href=\"https://github.com/hariszaf/pema/blob/master/analysis_directory/parameters.tsv\"\
    ><em><strong>parameters.tsv</strong></em></a> file (you can download it from this\
    \ repository and then <strong>complete it</strong> according to the needs of your\
    \ analysis)</li>\n<li>a subdirectory called <em><strong>mydata</strong></em> where\
    \ your .fastq.gz files will be located <br>\n</li>\n</ul>\n<p>If your need to\
    \ perform phyloseq, in the analysis directory you also need to add the following\
    \ <strong>optionally</strong> files:</p>\n<ul>\n<li>the <a href=\"https://github.com/hariszaf/pema/blob/master/analysis_directory/phyloseq_in_PEMA.R\"\
    ><em><strong>phyloseq_in_PEMA.R</strong></em></a> which you can also download\
    \ from this repository and set it the way you want (that is an R script which\
    \ we have implemented and has some main features that need to stay always the\
    \ same in order to be executed as part of PEMA and some parts where the user can\
    \ set what exactly needs to get from the phyloseq package)</li>\n<li>the <a href=\"\
    https://raw.githubusercontent.com/hariszaf/pema/master/analysis_directory/metadata.csv\"\
    \ rel=\"nofollow\"><em><strong>metadata.csv</strong></em></a> file which has to\
    \ be in a <strong>comma separated</strong> format (you can find an example of\
    \ this file on PEMA's GitHub repository).</li>\n</ul>\n<h3>\n<a id=\"user-content-attention--\"\
    \ class=\"anchor\" href=\"#attention--\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a><strong>Attention!</strong> \
    \ <br>\n</h3>\n<p>PEMA will <strong>fail</strong> unless you name the aforementioned\
    \ files and directories <strong>exactly</strong> as described above.\n<br></p>\n\
    <p>Here is an example of how your <em>analysis directory</em> should be in case\
    \ you do want a phyloseq analysis:</p>\n<pre><code>user@home-PC:~/Desktop/analysis_directory$\
    \ ls\nmydata  parameters.tsv  phyloseq_in_PEMA.R  metadata.csv\n</code></pre>\n\
    <p>and in case you do not:</p>\n<pre><code>user@home-PC:~/Desktop/analysis_directory$\
    \ ls\nmydata  parameters.tsv \n</code></pre>\n<p><a href=\"https://github.com/hariszaf/pema/tree/master/analysis_directory\"\
    ><strong>Here</strong></a> you can find an example of an <em>analysis directory</em>.</p>\n\
    <p>After you have prepared this <em>analysis directory</em> you are ready to run\
    \ PEMA (see below).</p>\n<p><strong>An extended list with PEMA's ouput can be\
    \ found <a href=\"https://github.com/hariszaf/pema/blob/master/help_files/PEMA's%20output%20files.md\"\
    ><strong>here</strong></a>.</strong></p>\n\n<h1>\n<a id=\"user-content-parameters-file\"\
    \ class=\"anchor\" href=\"#parameters-file\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Parameters' file</h1>\n<p>The\
    \ most crucial component in running PEMA is the parameters file. This file must\
    \ be located <strong>in</strong> the <em>analysis directory</em> and the user\
    \ needs to fill it <strong>every time</strong> PEMA is about to be called. If\
    \ you need more than one analyses to run, then you need to make copies of the\
    \ parameters' file and have one of those in eah of the analysis directrories you\
    \ create.</p>\n<p>So, here is the <a href=\"https://github.com/hariszaf/pema/blob/master/analysis_directory/parameters.tsv\"\
    ><em><strong>parameters.tsv</strong></em></a> file as it looks like, in a study\
    \ case of our own.</p>\n\n<h1>\n<a id=\"user-content-pema-on-hpc\" class=\"anchor\"\
    \ href=\"#pema-on-hpc\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>PEMA on HPC</h1>\n<p>PEMA is best to run on\
    \ HPC (server, cluster, cloud). Usually environmental data are quite large and\
    \ the whole process has huge computational demands. To get PEMA running on your\
    \ HPC you (actually your system administrator) need to install Singularity as\
    \ described below.</p>\n<h2>\n<a id=\"user-content-prerequisites\" class=\"anchor\"\
    \ href=\"#prerequisites\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Prerequisites</h2>\n<p><strong><a href=\"https://www.sylabs.io/guides/3.0/user-guide/quick_start.html#quick-installation-steps\"\
    \ rel=\"nofollow\">Singularity</a></strong>  is a free, cross-platform and open-source\
    \ computer program that performs operating-system-level virtualization also known\
    \ as containerization. One of the main uses of Singularity is to bring containers\
    \ and reproducibility to scientific computing and the high-performance computing\
    \ (HPC) world.</p>\n<p>Singularity needs a Linux/Unix system to run.</p>\n<h2>\n\
    <a id=\"user-content-installing\" class=\"anchor\" href=\"#installing\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Installing</h2>\n\
    <p>After you install Singularity in your environment and open it, you need to\
    \ download PEMA's image from Singularity Hub, by running the command:</p>\n<pre><code>\
    \ singularity pull shub://hariszaf/pema:v.1.1\n</code></pre>\n<p>Now you have\
    \ PEMA on your environment. But there is still one really <strong>important</strong>\
    \ thing that you need to do! Please <strong>download</strong> the <a href=\"https://github.com/hariszaf/pema/blob/master/analysis_directory/parameters.tsv\"\
    ><em>parameters.tsv</em></a> file and move it or copy it to the same directory\
    \ with your raw data.</p>\n<p>Now you are ready to go!</p>\n<h2>\n<a id=\"user-content-running-pema\"\
    \ class=\"anchor\" href=\"#running-pema\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running PEMA</h2>\n<p>Singularity\
    \ permits the use of a job scheduler that allocates computional resources on clusters\
    \ and at the same time, works as a queuing system, as <strong><a href=\"https://slurm.schedmd.com/overview.html\"\
    \ rel=\"nofollow\">Slurm</a></strong>. This way you are able to create a job as\
    \ you usually do in your system and after editing the parameters file as needed,\
    \ run PEMA as a job on your cluster.</p>\n<h3>\n<a id=\"user-content-example\"\
    \ class=\"anchor\" href=\"#example\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Example</h3>\n<pre><code>#SBATCH\
    \ --partition=batch\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=20\n#SBATCH\
    \ --mem=\n# Memory per node specification is in MB. It is optional.\n# The default\
    \ limit is 3000MB per core.\n#SBATCH --job-name=\"testPema\"\n#SBATCH --output=PEMA.output\n\
    #SBATCH --mail-user=haris-zafr@hcmr.gr\n#SBATCH --mail-type=ALL\n#SBATCH --requeue\n\
    \n\nsingularity run -B /&lt;path&gt;/&lt;of&gt;/&lt;input&gt;/&lt;directory&gt;/:/mnt/analysis\
    \ /&lt;path&gt;/&lt;of&gt;/&lt;PEMA_container&gt;\n\n</code></pre>\n<p>In the\
    \ above example, we set the cluster \"Zorba\", to run PEMA in 1 node, with 20\
    \ cores.</p>\n<p>For further information, you can always check <a href=\"https://docs.google.com/presentation/d/1lVH23DPa2NDNBhVvOTRoip8mraw8zfw8VQwbK4vkB1U/edit?fbclid=IwAR14PpWfPtxB8lLBBnoxs7UbG3IJfkArrJBS5f2kRA__kvGDUb8wiJ2Cy_s#slide=id.g57f092f54d_1_21\"\
    \ rel=\"nofollow\">PEMA's tutorial</a>.</p>\n\n<h1>\n<a id=\"user-content-pema-on-a-simple-pc\"\
    \ class=\"anchor\" href=\"#pema-on-a-simple-pc\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>PEMA on a simple PC</h1>\n<h2>\n\
    <a id=\"user-content-prerequisites-1\" class=\"anchor\" href=\"#prerequisites-1\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Prerequisites</h2>\n<p>To run PEMA in a simple PC on your own environment,\
    \ you first need to install <a href=\"https://docs.docker.com/install/\" rel=\"\
    nofollow\">Docker</a>, in case you do not already have it.</p>\n<p>You should\
    \ check your software version. A version of Docker is avalable for all Windows,\
    \ Mac and Linux. If you have Windows 10 Pro or your Mac's hardware in after 2010,\
    \ then you can insall Docker straightforward. Otherwise, you need to install the\
    \ <a href=\"https://docs.docker.com/toolbox/\" rel=\"nofollow\">Docker toolbox</a>\
    \ instead. You can check if your System Requirements are according to the ones\
    \ mentioned below in order to be sure what you need to do.</p>\n<p><strong>System\
    \ Requirements</strong></p>\n<pre><code>**__Windows 10 64bit__**:\nPro, Enterprise\
    \ or Education (1607 Anniversary Update, Build 14393 or later).\nVirtualization\
    \ is enabled in BIOS. Typically, virtualization is enabled by default.\nThis is\
    \ different from having Hyper-V enabled. For more detail see Virtualization must\
    \ be enabled in Troubleshooting.\nCPU SLAT-capable feature.\nAt least 4GB of RAM.\n\
    \n**__Mac__**\nMac hardware must be a 2010 or newer model, with Intel\u2019s hardware\
    \ support for memory management unit (MMU)\nvirtualization, including Extended\
    \ Page Tables (EPT) and Unrestricted Mode. You can check to see if your machine\n\
    has this support by running the following command in a terminal:\nsysctl kern.hv_support\
    \ macOS El Capitan 10.11 and newer macOS releases are supported.\nWe recommend\
    \ upgrading to the latest version of macOS.\nAt least 4GB of RAM\nVirtualBox prior\
    \ to version 4.3.30 must NOT be installed (it is incompatible with Docker for\
    \ Mac).\nIf you have a newer version of VirtualBox installed, it\u2019s fine.\n\
    </code></pre>\n<h2>\n<a id=\"user-content-installing-1\" class=\"anchor\" href=\"\
    #installing-1\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon\
    \ octicon-link\"></span></a>Installing</h2>\n<p>After you install Docker in your\
    \ environment and run it, the only thing you need to do, is to download PEMA's\
    \ image, by running the command:</p>\n<pre><code>docker pull hariszaf/pema\n</code></pre>\n\
    <p>The PEMA image file is a quite large (~3Gb), so it will take a while until\
    \ it is downloaded in your computer system.</p>\n<h2>\n<a id=\"user-content-running-pema-1\"\
    \ class=\"anchor\" href=\"#running-pema-1\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Running PEMA</h2>\n<p>Running\
    \ PEMA has two discrete steps.</p>\n<h3>\n<a id=\"user-content-step-1---build-a-docker-container\"\
    \ class=\"anchor\" href=\"#step-1---build-a-docker-container\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Step\
    \ 1 - Build a Docker container</h3>\n<p>At first, you need to let Docker have\
    \ access in your dataset. To provide access you need to run the following command\
    \ and specifying the path to where your data is stored, i.e. changing the &lt;path_to_analysis_directory&gt;\
    \ accordingly:</p>\n<pre><code>docker run -it -v /&lt;path_to_analysis_directory&gt;/:/mnt/analysis\
    \ hariszaf/pema\n</code></pre>\n<p>After you run the command above, you have now\
    \ built a Docker container, in which you can run PEMA!</p>\n<h3>\n<a id=\"user-content-step-2---run-pema\"\
    \ class=\"anchor\" href=\"#step-2---run-pema\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Step 2 - Run PEMA</h3>\n<p>Now,\
    \ being inside the PEMA container, the only thing remaining to do, is to run PEMA</p>\n\
    <pre><code>./PEMA_v1.bds\n</code></pre>\n<p>PEMA is now running. The runtime of\
    \ PEMA depends on the computational features of your environment, on the size\
    \ of your data, as well as the parameters you chose.</p>\n<p>Please, keep in mind\
    \ that when you need to copy a whole directory, then you always have to put \"\
    /\" in the end of the path that describes where the directory is located.</p>\n\
    <p>Finally, you will find the PEMA output in the analysis directory on your computer.\
    \ <br>\nAs the output directory is mounted into the built Docker container, you\
    \ can copy its contents wherever you want. However, in case you want to remove\
    \ it permanently, you need to do this as a sudo user.</p>\n\n<h1>\n<a id=\"user-content-the-phyloseq-r-package\"\
    \ class=\"anchor\" href=\"#the-phyloseq-r-package\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>The \"phyloseq\"\
    \ R package</h1>\n<p><strong>for a downstream ecological analysis of OTUs/ASVs\
    \ retrieved</strong></p>\n<p>PEMA performs all the basic functions of the \"phyloseq\"\
    \ R package. In addition, it performs certain functions of the <a href=\"https://cran.r-project.org/web/packages/vegan/index.html\"\
    \ rel=\"nofollow\"><em><strong>vegan</strong></em></a> R package.</p>\n<p>When\
    \ the user asks for a downstream analysis using the \"phyloseq\" R package, then\
    \ an extra input file called <a href=\"https://github.com/hariszaf/pema/blob/master/analysis_directory/phyloseq_in_PEMA.R\"\
    ><em><strong>\"phyloseq_script.R\"</strong></em></a> needs to be imported in the\
    \ \"analysis_directory\". In PEMA's main repository, you can find a template of\
    \ this file; this file needs to be as it would run on your own computer, as you\
    \ would run <em>phyloseq</em> in any case. PEMA will create the <em>\"phyloseq\
    \ object\"</em> automatically and then it will perform the analysis as asked.\
    \ The output will be placed in an extra subfolder in the main output directory\
    \ of PEMA called <em>phyloseq_analysis</em>.</p>\n<p>In addition, the <em><strong>metadata.tsv</strong></em>\
    \ file is also required when the phyloseq option has been selected. An example\
    \ of this file you can find <a href=\"https://raw.githubusercontent.com/hariszaf/pema/master/analysis_directory/metadata.csv\"\
    \ rel=\"nofollow\">here</a>.</p>\n<h1>\n<a id=\"user-content-acknowledgments\"\
    \ class=\"anchor\" href=\"#acknowledgments\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Acknowledgments</h1>\n<p>PEMA\
    \ uses a series of tools, datasets as well as Big Data Script language. We thank\
    \ all the groups that developed them.\nThe tools &amp; databases that PEMA uses\
    \ are:</p>\n<ul>\n<li>BigDataScript programming language - <a href=\"https://pcingola.github.io/BigDataScript/\"\
    \ rel=\"nofollow\">https://pcingola.github.io/BigDataScript/</a>\n</li>\n<li>FASTQC\
    \ - <a href=\"https://www.bioinformatics.babraham.ac.uk/projects/fastqc/\" rel=\"\
    nofollow\">https://www.bioinformatics.babraham.ac.uk/projects/fastqc/</a>\n</li>\n\
    <li>\u03A4rimmomatic - <a href=\"http://www.usadellab.org/cms/?page=trimmomatic\"\
    \ rel=\"nofollow\">http://www.usadellab.org/cms/?page=trimmomatic</a>\n</li>\n\
    <li>Cutadapt - <a href=\"https://cutadapt.readthedocs.io/en/stable/\" rel=\"nofollow\"\
    >https://cutadapt.readthedocs.io/en/stable/</a>\n</li>\n<li>BayesHammer - included\
    \ in SPAdes - <a href=\"http://cab.spbu.ru/software/spades/\" rel=\"nofollow\"\
    >http://cab.spbu.ru/software/spades/</a>\n</li>\n<li>PANDAseq - <a href=\"https://github.com/neufeld/pandaseq\"\
    >https://github.com/neufeld/pandaseq</a>\n</li>\n<li>OBITools - <a href=\"https://pythonhosted.org/OBITools/welcome.html\"\
    \ rel=\"nofollow\">https://pythonhosted.org/OBITools/welcome.html</a>\n</li>\n\
    <li>BLAST Command Line Applications - <a href=\"https://www.ncbi.nlm.nih.gov/books/NBK52640/\"\
    \ rel=\"nofollow\">https://www.ncbi.nlm.nih.gov/books/NBK52640/</a>\n</li>\n<li>VSEARCH-2.9.1\
    \ - <a href=\"https://github.com/torognes/vsearch/releases/tag/v2.9.1\">https://github.com/torognes/vsearch/releases/tag/v2.9.1</a>\n\
    </li>\n<li>SWARM - <a href=\"https://github.com/torognes/swarm\">https://github.com/torognes/swarm</a>\n\
    </li>\n<li>CROP - <a href=\"https://github.com/tingchenlab/CROP\">https://github.com/tingchenlab/CROP</a>\n\
    </li>\n<li>CREST - <a href=\"https://github.com/lanzen/CREST\">https://github.com/lanzen/CREST</a>\n\
    </li>\n<li>RDPClassifier - <a href=\"https://github.com/rdpstaff/classifier\"\
    >https://github.com/rdpstaff/classifier</a>\n(RPDtools are required in order to\
    \ execute RDPClassifier)</li>\n<li>SILVA db - <a href=\"https://www.arb-silva.de/no_cache/download/archive/current/Exports/\"\
    \ rel=\"nofollow\">https://www.arb-silva.de/no_cache/download/archive/current/Exports/</a>\n\
    </li>\n<li>MIDORI db - <a href=\"http://reference-midori.info/index.html\" rel=\"\
    nofollow\">http://reference-midori.info/index.html</a>\n</li>\n<li>\"phat\" algorithm,\
    \ from the \"gappa\" package - <a href=\"https://github.com/lczech/gappa/wiki/Subcommand:-phat\"\
    >https://github.com/lczech/gappa/wiki/Subcommand:-phat</a>\n</li>\n<li>MAFFT -\
    \ <a href=\"https://mafft.cbrc.jp/alignment/software/\" rel=\"nofollow\">https://mafft.cbrc.jp/alignment/software/</a>\n\
    </li>\n<li>RAxML -ng - <a href=\"https://github.com/amkozlov/raxml-ng\">https://github.com/amkozlov/raxml-ng</a>\n\
    </li>\n<li>PaPaRa - <a href=\"https://cme.h-its.org/exelixis/web/software/papara/index.html\"\
    \ rel=\"nofollow\">https://cme.h-its.org/exelixis/web/software/papara/index.html</a>\n\
    </li>\n<li>EPA-ng - <a href=\"https://github.com/Pbdas/epa-ng\">https://github.com/Pbdas/epa-ng</a>\n\
    </li>\n<li>phyloseq R package - <a href=\"http://joey711.github.io/phyloseq/index.html\"\
    \ rel=\"nofollow\">http://joey711.github.io/phyloseq/index.html</a>\n</li>\n<li>vegan\
    \ R package - <a href=\"https://cran.r-project.org/web/packages/vegan/index.html\"\
    \ rel=\"nofollow\">https://cran.r-project.org/web/packages/vegan/index.html</a>\n\
    </li>\n</ul>\n<p>And of course the container-based technologies:</p>\n<ul>\n<li>Docker\
    \ - <a href=\"https://www.docker.com/\" rel=\"nofollow\">https://www.docker.com/</a>\n\
    </li>\n<li>Singularity - <a href=\"https://sylabs.io/singularity/\" rel=\"nofollow\"\
    >https://sylabs.io/singularity/</a>\n</li>\n</ul>\n<h1>\n<a id=\"user-content-license\"\
    \ class=\"anchor\" href=\"#license\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>License</h1>\n<p>PEMA is under\
    \ the GNU GPLv3 license (for 3rd party components separate licenses apply).</p>\n\
    <h1>\n<a id=\"user-content-citation\" class=\"anchor\" href=\"#citation\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Citation</h1>\n\
    <p>Haris Zafeiropoulos, Ha Quoc Viet, Katerina Vasileiadou, Antonis Potirakis,\
    \ Christos Arvanitidis, Pantelis Topalis, Christina Pavloudi, Evangelos Pafilis,\
    \ PEMA: a flexible Pipeline for Environmental DNA Metabarcoding Analysis of the\
    \ 16S/18S ribosomal RNA, ITS, and COI marker genes, GigaScience, Volume 9, Issue\
    \ 3, March 2020, giaa022, <a href=\"https://doi.org/10.1093/gigascience/giaa022\"\
    \ rel=\"nofollow\">https://doi.org/10.1093/gigascience/giaa022</a></p>\n<p>&lt;&lt;&lt;&lt;&lt;&lt;&lt;\
    \ HEAD</p>\n\n<p>=======</p>\n \n<blockquote>\n<blockquote>\n<blockquote>\n<blockquote>\n\
    <blockquote>\n<blockquote>\n<blockquote>\n<p>rearchitecturing</p>\n</blockquote>\n\
    </blockquote>\n</blockquote>\n</blockquote>\n</blockquote>\n</blockquote>\n</blockquote>\n"
  stargazers_count: 12
  subscribers_count: 3
  topics: []
  updated_at: 1622303297.0
hmgu-itg/man_qq_annotate:
  data_format: 2
  description: Creates Manhattan and QQ plots with annotated peaks.
  filenames:
  - Singularity
  full_name: hmgu-itg/man_qq_annotate
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-man_qq_annotate\" class=\"anchor\" href=\"#man_qq_annotate\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>man_qq_annotate</h1>\n<p>Creates Manhattan and QQ plots with annotated\
    \ peaks for sequencing-based GWAS outputs, by thinning the dataset to what the\
    \ eye can see.</p>\n<h2>\n<a id=\"user-content-installation\" class=\"anchor\"\
    \ href=\"#installation\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Installation</h2>\n<p>Clone the repository and\
    \ install using <code>devtools</code></p>\n<div class=\"highlight highlight-source-shell\"\
    ><pre>git clone https://github.com/hmgu-itg/man_qq_annotate.git\n<span class=\"\
    pl-c1\">cd</span> man_qq_annotate\n\n<span class=\"pl-c\"><span class=\"pl-c\"\
    >#</span> Install devtools if you don't have it</span>\n<span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> R -e 'install.packages('devtools')</span>\nR -e <span\
    \ class=\"pl-s\"><span class=\"pl-pds\">'</span>library(devtools) ; install()<span\
    \ class=\"pl-pds\">'</span></span></pre></div>\n<h2>\n<a id=\"user-content-usage\"\
    \ class=\"anchor\" href=\"#usage\" aria-hidden=\"true\"><span aria-hidden=\"true\"\
    \ class=\"octicon octicon-link\"></span></a>Usage</h2>\n<p>You can either use\
    \ the CLI or load the package into your R environment.</p>\n<h3>\n<a id=\"user-content-command-line-interface-cli\"\
    \ class=\"anchor\" href=\"#command-line-interface-cli\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Command Line\
    \ Interface (CLI)</h3>\n<p>Once installed, you can use the <code>run_manqq.R</code>\
    \ script in the base of the repository as a command line tool.<br>\nFor a GCTA\
    \ output, use the following:</p>\n<pre><code>./run_manqq.R --chr-col Chr --pval-col\
    \ p --pos-col bp --a1 A1 --a2 A2 --build 38 --image png --af-col Freq input.assoc.txt.gz\
    \ output.prefix\n</code></pre>\n<p>You can add <code>run_manqq.R</code> to your\
    \ <code>PATH</code> variable for convenient execution:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre><span class=\"pl-k\">export</span> PATH=<span\
    \ class=\"pl-s\"><span class=\"pl-pds\">\"</span>/path/to/man_qq_annotate:<span\
    \ class=\"pl-smi\">$PATH</span><span class=\"pl-pds\">\"</span></span>\n<span\
    \ class=\"pl-c\"><span class=\"pl-c\">#</span> Or to make this permanent:</span>\n\
    <span class=\"pl-c1\">echo</span> <span class=\"pl-s\"><span class=\"pl-pds\"\
    >'</span>export PATH=\"/path/to/man_qq_annotate:$PATH\"<span class=\"pl-pds\"\
    >'</span></span> <span class=\"pl-k\">&gt;&gt;</span> <span class=\"pl-k\">~</span>/.bashrc</pre></div>\n\
    <p>Input files can be gzipped or plain. Run without arguments for a list of options,\
    \ run with <code>--help</code> for detailed options:</p>\n<div class=\"highlight\
    \ highlight-source-shell\"><pre>usage: ./run_manqq.R [-h] [--chr-col [character]]\
    \ [--pval-col [character]]\n                     [--pos-col [character]] [--a1\
    \ [character]]\n                     [--a2 [character]] [--build [integer]]\n\
    \                     [--image [character]] [--af-col [character]]\n         \
    \            [--maf-filter [double]] [--sig [double]]\n                     [--maxpeaks\
    \ [integer]] [--no-qq] [--no-man] [--no-annot]\n                     [--no-distance]\
    \ [--man-height [integer]]\n                     [--upper-margin [double]] [--annot-cex\
    \ [double]]\n                     [--axes-cex [double]] [--ylim [double]]\n  \
    \                   infile outfile\n\nA program to plot Manhattan and QQ plots\n\
    \npositional arguments:\n  infile                Input file name, must be gzip\
    \ file\n  outfile               Output file name (with no file extension)\n\n\
    optional arguments:\n  <span class=\"pl-k\">-h</span>, --help            show\
    \ this <span class=\"pl-c1\">help</span> message and <span class=\"pl-c1\">exit</span>\n\
    \  --chr-col [character]\n                        The column NAME <span class=\"\
    pl-k\">for</span> the chromosome column, default chr\n  --pval-col [character]\n\
    \                        The column NAME <span class=\"pl-k\">for</span> the chromosome\
    \ column, default\n                        p_score\n  --pos-col [character]\n\
    \                        The column NAME <span class=\"pl-k\">for</span> the chromosome\
    \ column, default ps\n  --a1 [character]      The column NAME <span class=\"pl-k\"\
    >for</span> the effect allele column, default\n                        allele1\n\
    \  --a2 [character]      The column NAME <span class=\"pl-k\">for</span> the non-effect\
    \ column, default\n                        allele0\n  --build [integer]     The\
    \ genome build the positions refer to\n  --image [character]   The filetype to\
    \ save plots to (png or pdf)\n  --af-col [character]  The column NAME <span class=\"\
    pl-k\">for</span> the allele frequency column,\n                        default\
    \ af\n  --maf-filter [double]\n                        The significance threshold\
    \ <span class=\"pl-k\">for</span> MAF filter, default\n                      \
    \  0.0.\n  --sig [double]        The significance threshold to use <span class=\"\
    pl-k\">for</span> peak annotation\n  --maxpeaks [integer]  The maximum number\
    \ of peaks to annotate\n  --no-qq               Don<span class=\"pl-s\"><span\
    \ class=\"pl-pds\">'</span>t plot QQ.</span>\n<span class=\"pl-s\">  --no-man\
    \              Don<span class=\"pl-pds\">'</span></span>t plot Manhattan.\n  --no-annot\
    \            Disable peak annotation even <span class=\"pl-k\">if</span> peaks\
    \ are present.\n  --no-distance         Don<span class=\"pl-s\"><span class=\"\
    pl-pds\">'</span>t add very useful distance to gene info.</span>\n<span class=\"\
    pl-s\">  --man-height [integer]</span>\n<span class=\"pl-s\">                \
    \        Force height of Manhattan in inches. Can have</span>\n<span class=\"\
    pl-s\">                        unpredictable consequences (some of which you may</span>\n\
    <span class=\"pl-s\">                        regret).</span>\n<span class=\"pl-s\"\
    >  --upper-margin [double]</span>\n<span class=\"pl-s\">                     \
    \   Y limit of Manhattan plot in units of maximum data</span>\n<span class=\"\
    pl-s\">                        points. Even more unpredictable than the above.</span>\n\
    <span class=\"pl-s\">  --annot-cex [double]  Size factor for annotations.</span>\n\
    <span class=\"pl-s\">  --axes-cex [double]   Size factor for axes and labels.</span>\n\
    <span class=\"pl-s\">  --ylim [double]       The y-axis limit (-log10(p))</span>\n\
    <span class=\"pl-s\"></span></pre></div>\n<h3>\n<a id=\"user-content-loading-the-package\"\
    \ class=\"anchor\" href=\"#loading-the-package\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>Loading the package</h3>\n<p>You\
    \ can load the package into your R environment and use the available functions.</p>\n\
    <div class=\"highlight highlight-source-r\"><pre>library(<span class=\"pl-smi\"\
    >manqq</span>)\nls(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>package:manqq<span\
    \ class=\"pl-pds\">'</span></span>)</pre></div>\n<pre><code>[1] \"run_manqq\"\
    \      \"run_manqq.gcta\"\n</code></pre>\n<p>Currently, only two functions are\
    \ exported and available for users. The other functions are all hidden and only\
    \ used internally within the package. If there are any particular functionality\
    \ you wish to use from the package, please make a request in the <a href=\"https://github.com/hmgu-itg/man_qq_annotate/issues\"\
    >issue page</a>.</p>\n<h2>\n<a id=\"user-content-development\" class=\"anchor\"\
    \ href=\"#development\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>Development</h2>\n<p>You can use <code>devtools</code>\
    \ to load all the functions into your environment for development/debugging:</p>\n\
    <div class=\"highlight highlight-source-r\"><pre>library(<span class=\"pl-smi\"\
    >devtools</span>)\nsetwd(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>/base/of/the/repo/man_qq_annotate<span\
    \ class=\"pl-pds\">'</span></span>)\nload_all()\ntest() <span class=\"pl-c\"><span\
    \ class=\"pl-c\">#</span> Use testthat's test function to run the testsuite</span></pre></div>\n"
  stargazers_count: 1
  subscribers_count: 3
  topics: []
  updated_at: 1622250961.0
icaoberg/singularity-bedtools:
  data_format: 2
  description: A powerful toolset for genome arithmetic
  filenames:
  - Singularity
  full_name: icaoberg/singularity-bedtools
  latest_release: v2.29.2
  readme: "<h1>\n<a id=\"user-content-singularity-bedtools\" class=\"anchor\" href=\"\
    #singularity-bedtools\" aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"\
    octicon octicon-link\"></span></a>singularity-bedtools</h1>\n<p><a href=\"https://cloud.sylabs.io/library/icaoberg/default/bedtools\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/2747e70595bc577024d908f158c1c8b1d458085960e3bdd70770858769cdf396/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f686f737465642d73796c6162732e696f2d677265656e2e737667\"\
    \ alt=\"Hosted\" data-canonical-src=\"https://img.shields.io/badge/hosted-sylabs.io-green.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://camo.githubusercontent.com/8025f5254ec80610d1aa2daad722b5f63139d443fc969f0e566b87230d2519c5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d76322e32392e322d677265656e2e737667\"\
    \ target=\"_blank\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/8025f5254ec80610d1aa2daad722b5f63139d443fc969f0e566b87230d2519c5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d76322e32392e322d677265656e2e737667\"\
    \ alt=\"Release\" data-canonical-src=\"https://img.shields.io/badge/release-v2.29.2-green.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://travis-ci.org/icaoberg/singularity-bedtools\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/4bd5a5797e0eea5576a22f0d6438bb219e7e9d1165583a395f84114bcdf8d56e/68747470733a2f2f7472617669732d63692e6f72672f6963616f626572672f73696e67756c61726974792d626564746f6f6c732e7376673f6272616e63683d6d6173746572\"\
    \ alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/icaoberg/singularity-bedtools.svg?branch=master\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/icaoberg/singularity-bedtools/issues\"\
    ><img src=\"https://camo.githubusercontent.com/8daa37ea52a8b910d7804b0dea5e36dc1ea51550f4d4d7e83fa044b7785964a3/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f6963616f626572672f73696e67756c61726974792d626564746f6f6c732e737667\"\
    \ alt=\"GitHub issues\" data-canonical-src=\"https://img.shields.io/github/issues/icaoberg/singularity-bedtools.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/icaoberg/singularity-bedtools/network\"\
    ><img src=\"https://camo.githubusercontent.com/ea5237be05f56a481118a0905c976d88658d70a95b16af6c060101aea4e73a98/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f6963616f626572672f73696e67756c61726974792d626564746f6f6c732e737667\"\
    \ alt=\"GitHub forks\" data-canonical-src=\"https://img.shields.io/github/forks/icaoberg/singularity-bedtools.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://github.com/icaoberg/singularity-bedtools/stargazers\"\
    ><img src=\"https://camo.githubusercontent.com/192b2d7fbd67aa10f3c8f5535205f7be9d07653cb29eb16d34176d9dc6b541a0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6963616f626572672f73696e67756c61726974792d626564746f6f6c732e737667\"\
    \ alt=\"GitHub stars\" data-canonical-src=\"https://img.shields.io/github/stars/icaoberg/singularity-bedtools.svg\"\
    \ style=\"max-width:100%;\"></a>\n<a href=\"https://www.gnu.org/licenses/quick-guide-gplv3.en.html\"\
    \ rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/0b6758422f85bc2599288b346c7de30c6b7b217112c0a877ae4b25a7009722e4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d47504c76332d626c75652e737667\"\
    \ alt=\"GitHub license\" data-canonical-src=\"https://img.shields.io/badge/license-GPLv3-blue.svg\"\
    \ style=\"max-width:100%;\"></a></p>\n<p><a href=\"images/logo.png\" target=\"\
    _blank\" rel=\"noopener noreferrer\"><img src=\"images/logo.png\" alt=\"Logo\"\
    \ style=\"max-width:100%;\"></a></p>\n<p>Collectively, the <a href=\"https://bedtools.readthedocs.io/en/latest/\"\
    \ rel=\"nofollow\">bedtools</a> utilities are a swiss-army knife of tools for\
    \ a wide-range of genomics analysis tasks. The most widely-used tools enable genome\
    \ arithmetic: that is, set theory on the genome. For example, bedtools allows\
    \ one to intersect, merge, count, complement, and shuffle genomic intervals from\
    \ multiple files in widely-used genomic file formats such as BAM, BED, GFF/GTF,\
    \ VCF. While each individual tool is designed to do a relatively simple task (e.g.,\
    \ intersect two interval files), quite sophisticated analyses can be conducted\
    \ by combining multiple bedtools operations on the UNIX command line.</p>\n<h2>\n\
    <a id=\"user-content-pre-requisites\" class=\"anchor\" href=\"#pre-requisites\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>Pre-requisites</h2>\n<ul>\n<li>\n<a href=\"https://sylabs.io/docs/\"\
    \ rel=\"nofollow\">Singularity v3.5.+</a>.</li>\n</ul>\n<h2>\n<a id=\"user-content-building-the-image-using-the-recipe\"\
    \ class=\"anchor\" href=\"#building-the-image-using-the-recipe\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Building\
    \ the image using the recipe</h2>\n<h3>\n<a id=\"user-content-to-build-the-image-locally\"\
    \ class=\"anchor\" href=\"#to-build-the-image-locally\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To build the\
    \ image locally</h3>\n<p>Run the script <code>build.sh</code> to build image locally.</p>\n\
    <pre><code>bash ./build.sh\n</code></pre>\n<h3>\n<a id=\"user-content-to-build-the-image-remotely-remotely\"\
    \ class=\"anchor\" href=\"#to-build-the-image-remotely-remotely\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>To\
    \ build the image remotely remotely</h3>\n<p>Run the script <code>rbuild.sh</code>\
    \ to build image remotely.</p>\n<pre><code>bash ./rbuild.sh\n</code></pre>\n<p>You\
    \ will need to edit the script above to match your account on <a href=\"https://sylabs.io/\"\
    \ rel=\"nofollow\">SyLabs.io</a>.</p>\n<h3>\n<a id=\"user-content-pulling-from-the-repository\"\
    \ class=\"anchor\" href=\"#pulling-from-the-repository\" aria-hidden=\"true\"\
    ><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Pulling\
    \ from the repository</h3>\n<p>If you have the client installed and cannot build\
    \ the image locally nor remotely, simply run</p>\n<pre><code>singularity pull\
    \ --arch amd64 library://icaoberg/default/bedtools:v2.29.2\n</code></pre>\n<h2>\n\
    <a id=\"user-content-disclaimer\" class=\"anchor\" href=\"#disclaimer\" aria-hidden=\"\
    true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>Disclaimer</h2>\n\
    <p>I am nothing but a humble programmer creating the container for this wonderful\
    \ app. <a href=\"https://bedtools.readthedocs.io/en/latest/\" rel=\"nofollow\"\
    >bedtools</a> is developed in the <a href=\"http://quinlanlab.org/\" rel=\"nofollow\"\
    >Quinlan laboratory</a> at the <a href=\"https://www.utah.edu/\" rel=\"nofollow\"\
    >University of Utah</a> and benefits from fantastic contributions made by scientists\
    \ worldwide.</p>\n<hr>\n<p><a href=\"http://www.cbd.cmu.edu\" rel=\"nofollow\"\
    ><img src=\"https://camo.githubusercontent.com/47fafd631a30ef553735a724705fea74cb02d1bb0b9eab22c64aca8c41885f3d/687474703a2f2f7777772e6362642e636d752e6564752f77702d636f6e74656e742f75706c6f6164732f323031372f30372f776f726470726573732d64656661756c742e706e67\"\
    \ alt=\"CBD\" data-canonical-src=\"http://www.cbd.cmu.edu/wp-content/uploads/2017/07/wordpress-default.png\"\
    \ style=\"max-width:100%;\"></a></p>\n<p>Copyleft \xA9 2019-2020 <a href=\"http://www.andrew.cmu.edu/~icaoberg\"\
    \ rel=\"nofollow\">icaoberg</a> at the <a href=\"http://www.cbd.cmu.edu\" rel=\"\
    nofollow\">Computational Biology Department</a> in <a href=\"http://www.cmu.edu\"\
    \ rel=\"nofollow\">Carnegie Mellon University</a></p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - singularity
  - singularity-container
  - bedtools
  updated_at: 1584374962.0
icaoberg/singularity-vim:
  data_format: 2
  description: Singularity recipe for vim
  filenames:
  - Singularity
  full_name: icaoberg/singularity-vim
  latest_release: null
  readme: '<h1>

    <a id="user-content-singularity-vim" class="anchor" href="#singularity-vim" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>singularity-vim</h1>

    <p>Vim is a clone, with additions, of Bill Joy''s vi text editor program for Unix.</p>

    <hr>

    <p><a href="http://www.psc.edu" rel="nofollow"><img src="https://camo.githubusercontent.com/ee7cb50ef5a31fe25a8e149b0a09b50a8523d5e11a27311af8e63f22a8c915b2/687474703a2f2f7777772e616e647265772e636d752e6564752f757365722f6963616f626572672f696d616765732f6c6f676f732f7073632e706e67"
    alt="PSC" data-canonical-src="http://www.andrew.cmu.edu/user/icaoberg/images/logos/psc.png"
    style="max-width:100%;"></a></p>

    <p>icaoberg at the <a href="http://www.psc.edu" rel="nofollow">Pittsburgh Supercomputing
    Center</a> in the <a href="https://www.cmu.edu/mcs/" rel="nofollow">Mellon College
    of Science</a> at <a href="http://www.cmu.edu" rel="nofollow">Carnegie Mellon
    University</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1621975845.0
ifurther/flair-def:
  data_format: 2
  description: singularity def file for flair(fluka)
  filenames:
  - flair.def
  - flair-cern.def
  full_name: ifurther/flair-def
  latest_release: null
  readme: '<h1>

    <a id="user-content-singularity-recipe-files" class="anchor" href="#singularity-recipe-files"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Singularity
    recipe files</h1>

    <p><a href="https://github.com/sylabs/singularity">Singularity</a> containers
    I use the most on HPC clusters.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1619686613.0
intel/HPC-containers-from-Intel:
  data_format: 2
  description: Intel HPC Containers using Singularity
  filenames:
  - definitionFiles/WRF/wrfRun.def
  - definitionFiles/WRF/wrfBuild.def
  - definitionFiles/gromacs/gromacsBuild.def
  - definitionFiles/gromacs/gromacsRun.def
  - definitionFiles/namd/namdBuild.def
  - definitionFiles/namd/namdRun.def
  - definitionFiles/lammps/lammpsRun.def
  - definitionFiles/lammps/lammpsBuild.def
  - definitionFiles/base/base.def
  full_name: intel/HPC-containers-from-Intel
  latest_release: null
  readme: '<h1>

    <a id="user-content-goal" class="anchor" href="#goal" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Goal:</h1>

    <p>Create containers using Singularity definition file for HPC apps and run them
    on the cloud or bare metal for Single and Cluster runs.</p>

    <p>This repo should have definition files only for few HPC applications. Users
    can utilize them to generate containers.</p>

    <h2>

    <a id="user-content-get-help" class="anchor" href="#get-help" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Get Help</h2>

    <ul>

    <li>

    <a href="https://github.com/intel/HPC-containers-from-Intel/issues">Post an issue</a>
    if you face any problem building or running a container</li>

    </ul>

    '
  stargazers_count: 16
  subscribers_count: 9
  topics:
  - hpc
  - cluster
  - singularity-containers
  - cloud
  updated_at: 1619711561.0
jolars/ReproduciblePythonProject:
  data_format: 2
  description: null
  filenames:
  - Singularity
  full_name: jolars/ReproduciblePythonProject
  latest_release: null
  readme: '<h1>

    <a id="user-content-reproduciblepythonproject" class="anchor" href="#reproduciblepythonproject"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>ReproduciblePythonProject</h1>

    <p>A template for reproducible projects using python, singularity, and c++ (via

    pybind11).</p>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1621946266.0
kb2623/singularity-builds:
  data_format: 2
  description: Singlularity containers
  filenames:
  - singularity/Singularity
  full_name: kb2623/singularity-builds
  latest_release: null
  readme: '<h1>

    <a id="user-content-singularity-builds" class="anchor" href="#singularity-builds"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>singularity-builds</h1>

    <p>Singlularity containers</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1622472468.0
lukegun/BIOMEC:
  data_format: 2
  description: Bayesian Inference and Optimisation for the Monash Electrochemical
    Simulator
  filenames:
  - Singularity.def
  full_name: lukegun/BIOMEC
  latest_release: null
  readme: '<p><a href="https://singularity-hub.org/collections/4983" rel="nofollow"><img
    src="https://camo.githubusercontent.com/a07b23d4880320ac89cdc93bbbb603fa84c215d135e05dd227ba8633a9ff34be/68747470733a2f2f7777772e73696e67756c61726974792d6875622e6f72672f7374617469632f696d672f686f737465642d73696e67756c61726974792d2d6875622d2532336533323932392e737667"
    alt="https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg"
    data-canonical-src="https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg"
    style="max-width:100%;"></a></p>

    <h1>

    <a id="user-content-biomec" class="anchor" href="#biomec" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>BIOMEC</h1>

    <p>Bayesian Inference and Optimisation for the Monash electrochemical Simulator
    (MECSim) is the application developed by the

    monash electrochemistry group with the assistance of Assosiate Professor Jie Zhang,
    Emeratious Professor Alan Bond and technical assistance from Gareth Kennedy And
    Martin Robinson.</p>

    <p>It is an automatic plaform for parameterisation that uses mathmatical optimisation
    and Bayesian Inference to calculate parameters involved in the electrochemical
    simulation.

    Built around <a href="http://www.garethkennedy.net/MECSim.html" rel="nofollow">MECSim</a>
    and first applied in the PAPER. BIOMEC allows for automated parameterisation of
    DC and FTAC voltammetery, allowing highly dimensional fits of the posteriour distrabution.</p>

    <p>BIOMEC uses <a href="https://github.com/pints-team/pints">PINTS</a> for univariant
    Bayesian inference.</p>

    <p>For information of current uses see the original <a href="https://chemistry-europe.onlinelibrary.wiley.com/doi/abs/10.1002/celc.202100391"
    rel="nofollow">BIOMEC paper</a>, the <a href="https://doi.org/10.1002/celc.201700678"
    rel="nofollow">original Bayesian inference paper</a> for AC voltammetry or our
    most recent <a href="https://doi.org/10.1039/D0CC07549C" rel="nofollow">featured
    article</a>.</p>

    <h2>

    <a id="user-content-installing-biomec-image" class="anchor" href="#installing-biomec-image"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installing
    BIOMEC image</h2>

    <p>The code is run in a singularity container which works for Ubuntu/UNIX and
    MAC (untested) OS systems.

    Singularity will need to be installed to use the image. Where the guide is seen
    in the following <a href="https://sylabs.io/guides/3.6/user-guide/quick_start.html"
    rel="nofollow">website</a> or downloaded from connected singularity hub.</p>

    <p>Once singularity has been installed, download the BIOMEC file and run the code
    to create the BIOMEC container (which should be around 580MB).</p>

    <pre><code>$ sudo singularity build BIOMEC.simg Singularity.def

    </code></pre>

    <p>Once the image is built the imput file (input.txt) can be passed to the image
    by using the following command.</p>

    <pre><code>$ ./BIOMEC.simg input.txt

    </code></pre>

    <p>This will generate and ouput file with plots and results once completed.</p>

    <h2>

    <a id="user-content-generating-input-files" class="anchor" href="#generating-input-files"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Generating
    input files</h2>

    <p>inputwritter.py can guide users unfamilaur with generating input files to create
    an input file for the BIOMEC container, this program is contained in the BIOMEC_inputwritter.

    Simply run the file using the following command and follow the prompts and an
    input file will be generated.</p>

    <pre><code>$ python3 inputwritter.py

    </code></pre>

    <p>The output of this file will then be of the form &lt;input.txt&gt; though other
    names will work.

    It is important that a copy of the MECSim Master.inp file is present in the folder
    you run inputwritter.py as the MECSim input file is required for BIOMEC to run.</p>

    <p>Once comfortable with writting the input file it is recommended to use any
    text editor.</p>

    <h2>

    <a id="user-content-running-biomec" class="anchor" href="#running-biomec" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running BIOMEC</h2>

    <p>PDF tutorial or youtube videos to come.</p>

    <h2>

    <a id="user-content-supporting-code" class="anchor" href="#supporting-code" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Supporting Code</h2>

    <ul>

    <li>BIOMEC_inputwritter: Basic terminal/ .exe code for guiding uses in writting
    the input files for BIOMEC</li>

    <li>MCMC PLOTTER: code to plot the mcmc output chains from the Iter_log.txt to
    images</li>

    </ul>

    <h2>

    <a id="user-content-known-issues" class="anchor" href="#known-issues" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Known Issues</h2>

    <ul>

    <li>Custom waveforms have not been tested and Estart and End cannot equal zero.</li>

    <li>Number of data poins in experimental data must be a multiple of two.</li>

    </ul>

    <h2>

    <a id="user-content-citing" class="anchor" href="#citing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Citing</h2>

    <p>Please, cite the original <a href="https://chemistry-europe.onlinelibrary.wiley.com/doi/abs/10.1002/celc.202100391"
    rel="nofollow">BIOMEC paper</a> if you have used this package in a publication.</p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>BIOMEC analysis/python code is open source under the GPL-3.0 License, with
    MECSim developed by Gareth Kennedy and contaned in the mecsim.cpython-37m-x86_64-linux-gnu.so
    shared object is under the Creative Commons Attribution-NonCommercial-ShareAlike
    4.0 International License.</p>

    <h2>

    <a id="user-content-get-in-touch" class="anchor" href="#get-in-touch" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Get in touch</h2>

    <p>For Questions/Bugs Email me at <a href="mailto:luke.gundry1@monash.edu">luke.gundry1@monash.edu</a>.</p>

    '
  stargazers_count: 0
  subscribers_count: 3
  topics:
  - baysian-inference
  - optimization
  - voltammetry
  - electrochemistry
  updated_at: 1622080196.0
manuel-munoz-aguirre/singularity-pytorch-gpu:
  data_format: 2
  description: Singularity image for a deep learning (pytorch) environment + GPU support
  filenames:
  - Singularity.1.0.0
  full_name: manuel-munoz-aguirre/singularity-pytorch-gpu
  latest_release: null
  readme: '<h1>

    <a id="user-content-singularity-pytorch-gpu" class="anchor" href="#singularity-pytorch-gpu"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>singularity-pytorch-gpu</h1>

    <p><a href="https://singularity-hub.org/collections/4969" rel="nofollow"><img
    src="https://camo.githubusercontent.com/a07b23d4880320ac89cdc93bbbb603fa84c215d135e05dd227ba8633a9ff34be/68747470733a2f2f7777772e73696e67756c61726974792d6875622e6f72672f7374617469632f696d672f686f737465642d73696e67756c61726974792d2d6875622d2532336533323932392e737667"
    alt="https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg"
    data-canonical-src="https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg"
    style="max-width:100%;"></a></p>

    <p>Singularity image for a deep learning (pytorch) environment + GPU support (cuda-10.2).
    Contains libraries to perform common ML tasks. <code>Openslide</code> is included
    to manipulate whole-slide histology images, <code>imagemagick</code> for general
    image manipulation. <code>JupyterLab</code> and <code>code-server</code> (VS Code)
    are also included in the image. This image has been tested in an HPC (SGE) with
    distributed pytorch applications.</p>

    <h2>

    <a id="user-content-installing-singularity" class="anchor" href="#installing-singularity"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installing
    singularity</h2>

    <p>To install singularity, see the <a href="https://sylabs.io/guides/3.6/admin-guide/installation.html#installation-on-linux"
    rel="nofollow">official docs</a>.</p>

    <h2>

    <a id="user-content-buildingdownloading-the-image" class="anchor" href="#buildingdownloading-the-image"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building/downloading
    the image</h2>

    <p>To build an image called <code>torchenv.sif</code> based on the definition
    file <code>Singularity.1.0.0</code>, an NVIDIA GPU and <code>cuda-10.2</code>
    drivers must be available on the host system. Clone this repository, move into
    it and run the singularity build command.</p>

    <pre><code>git clone https://github.com/manuel-munoz-aguirre/singularity-pytorch-gpu.git
    &amp;&amp; \

    cd singularity-pytorch-gpu &amp;&amp; \

    sudo singularity build torchenv.sif Singularity.1.0.0

    </code></pre>

    <p>Otherwise, the image can be pulled directly from singularity hub:</p>

    <pre><code>singularity pull torchenv.sif shub://manuel-munoz-aguirre/singularity-pytorch-gpu:1.0.0

    </code></pre>

    <h2>

    <a id="user-content-using-the-container" class="anchor" href="#using-the-container"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using
    the container</h2>

    <p>To spawn an interactive shell within the container, use the command below.
    The <code>--nv</code> flag setups the container to use NVIDIA GPUs (read more
    <a href="https://sylabs.io/guides/3.6/user-guide/gpu.html" rel="nofollow">here</a>).</p>

    <pre><code>singularity shell --nv torchenv.sif

    </code></pre>

    <p>To run a script (for example, <code>script.py</code>) using the container without
    starting an interactive shell:</p>

    <pre><code>singularity exec --nv torchenv.sif python3 script.py

    </code></pre>

    <p>The container can also be launched and used on a system without a GPU, but
    upon startup it will display a warning about missing NVIDIA binaries on the host.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - singularity
  - pytorch
  - deep-learning
  - machine-learning
  - environment
  updated_at: 1622471136.0
mattocci27/r-containers:
  data_format: 2
  description: docker and singularity containers for R
  filenames:
  - images/rstan_4.1.0/Singularity.def
  - images/rmd-light_4.1.0/Singularity.def
  - images/myenv_4.1.0/Singularity.def
  full_name: mattocci27/r-containers
  latest_release: null
  readme: '<h1>

    <a id="user-content-docker-and-singularity-images-for-r" class="anchor" href="#docker-and-singularity-images-for-r"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Docker
    and singularity images for R</h1>

    <p><a href="https://opensource.org/licenses/MIT" rel="nofollow"><img src="https://camo.githubusercontent.com/45b4ffbd594af47fe09a3432f9f8e122c6518aa6352b4ce453a1a2563da2905c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d677265656e2e737667"
    alt="GitHub License" data-canonical-src="https://img.shields.io/badge/license-MIT-green.svg"
    style="max-width:100%;"></a></p>

    <h2>

    <a id="user-content-images" class="anchor" href="#images" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Images</h2>

    <table>

    <thead>

    <tr>

    <th>docker</th>

    <th>singularity</th>

    <th>description</th>

    <th>r-ver</th>

    </tr>

    </thead>

    <tbody>

    <tr>

    <td><a href="https://hub.docker.com/repository/docker/mattocci/rstan" rel="nofollow">rstan</a></td>

    <td><a href="https://cloud.sylabs.io/library/mattocci27/default/rstan" rel="nofollow">rstan</a></td>

    <td>adds rstan on <a href="https://hub.docker.com/r/rocker/geospatial" rel="nofollow">geospatial</a>

    </td>

    <td>3.6.3, 4.0.5</td>

    </tr>

    <tr>

    <td><a href="https://hub.docker.com/repository/docker/mattocci/myenv" rel="nofollow">myenv</a></td>

    <td><a href="https://cloud.sylabs.io/library/mattocci27/default/myenv" rel="nofollow">myenv</a></td>

    <td>adds a bunch of packages on ''rstan''</td>

    <td>3.6.3, 4.0.5</td>

    </tr>

    <tr>

    <td><a href="https://hub.docker.com/repository/docker/mattocci/rmd-light" rel="nofollow">rmd-light</a></td>

    <td>-</td>

    <td>R markdown + TinyTex + pandoc-crossref without Rstudio and Tidyverse</td>

    <td>4.0.5</td>

    </tr>

    </tbody>

    </table>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1621951768.0
maxemil/ALE-pipeline:
  data_format: 2
  description: nextflow pipeline to automate analysis using ALE (https://github.com/ssolo/ALE)
  filenames:
  - Singularity
  full_name: maxemil/ALE-pipeline
  latest_release: null
  readme: '<h1>

    <a id="user-content-ale-pipeline" class="anchor" href="#ale-pipeline" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>ALE-pipeline</h1>

    <ul>

    <li>this is supposed to be a nice pipeline for running ALE on several gene clusters
    and collecting the results</li>

    <li>it can also test several species trees at the same time</li>

    <li>all parameters in the nextflow.config file can be changed on the command line,
    e.g. the name of the outgroup taxa</li>

    <li>you need to add the Python_lib repo to your Pythonpath</li>

    <li>For typical usage and a small tutorial, see TUTORIAL.md</li>

    <li>I use to code the names for species both in the species and in the gene tree
    to avoid that source of errors</li>

    </ul>

    <h1>

    <a id="user-content-troubleshooting" class="anchor" href="#troubleshooting" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Troubleshooting</h1>

    <ul>

    <li>If you get an Error ''Can''t root with myself'' or similar, this usually means
    that the outgroup you specified for the species tree is not monophyletic in that
    tree. Try rerooting by hand first...</li>

    <li>ALE sometime simply crashes, then the pipeline can be resumed by adding <code>-resume</code>
    to the invocation</li>

    </ul>

    '
  stargazers_count: 0
  subscribers_count: 4
  topics:
  - nextflow
  - evolution
  - bioinformatics
  - singularity-container
  - pipeline
  updated_at: 1622468753.0
mlell/tapas:
  data_format: 2
  description: 'Evaluate the effectiveness of any short read mapper and its parameters
    using artificially generated reads. See the "releases" page for download: https://github.com/mlell/tapas/releases.
    The manual can be found at https://mlell.github.io/tapas.'
  filenames:
  - Singularity
  full_name: mlell/tapas
  latest_release: null
  readme: '<h1>

    <a id="user-content-tapas" class="anchor" href="#tapas" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>TAPAS</h1>

    <p>This software package is meant for comparing NGS short read mappers.</p>

    <p>Artificial reads can be generated from genome sequences such that their true

    mapping positions are known (<code>scripts/uniform</code>). Artificial point mutations

    (<code>scripts/multiple_mutate</code>) and indels (<code>scripts/indel</code>)
    can be introduced.

    By comparing the original read locations to the positions the reads were

    assigned to by the mapper, the sensitivity and specificity of the mapper can

    be assessed.</p>

    <p>By running the mapper with different combinations of parameters, an optimal

    parameter set can be found (<code>scripts/cross_tab</code> and <code>scripts/table2calls</code>).

    TAPAS is compatible with all short read mappers by through a simple text

    file which contains the mapping command and the relevant parameters. Instead

    of the parameter values, bash variables (<code>${variablename}</code>) are used.
    They

    are replaced with the mapping parameter values to be tested by TAPAS.</p>

    <p>Additionally, reads can be mutated in a pattern similar to typical damage found

    in ancient DNA (aDNA) (<code>scripts/mapdamage2geomparam</code>). The effect of
    this

    mutations can be inspected as well.</p>

    <p>All the scripts are designed with the UNIX philosophy "do one thing and do
    it

    well" in mind. Therefore an analysis consists of a pipeline of these scripts.</p>

    <p>The universal data format is the text table, a simple text file containing
    data

    in whitespace- or tab-separated columns. The first line serves as header line

    with column names.</p>

    <h2>

    <a id="user-content-the-manual" class="anchor" href="#the-manual" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>The manual</h2>

    <p>The availabe tools are described in-depth in the TAPAS manual.

    The manual is located in the <code>docs/</code> folder. Open the file <code>docs/index.html</code>

    inside the TAPAS folder with your browser to view it.</p>

    <p>The manual can also be found online, <a href="https://mlell.github.io/tapas"
    rel="nofollow">click here</a>.</p>

    <p>There is also one <strong>example script</strong> which summarises the steps
    of the manual.

    It can be found at <code>manual/example-manual.sh</code>.</p>

    <p>To get help about one specific TAPAS tool, execute the tool with the option

    <code>--help</code>. Each tool prints then an extensive help page which explains
    how

    to use it. Example: <code>TAPAS/scripts/uniform --help</code>, where <code>TAPAS</code>
    is the

    folder you installed TAPAS to, prints the help of the artificial read

    generation tool <code>uniform</code>.</p>

    <h2>

    <a id="user-content-installation" class="anchor" href="#installation" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

    <p>This software package needs the following tools to be installed:</p>

    <ul>

    <li>R &gt;= 3.2</li>

    <li>Python &gt;= 3.4 and Pip, the Python package manager</li>

    <li>Standard GNU tools like <code>head</code>, <code>awk</code>, <code>sort</code>,
    <code>join</code>, <code>sed</code>. These are

    included in all GNU/Linux and Mac distributions. On Windows you can install

    Cygwin to get these programs. However, this software package is not yet

    tested on Windows.</li>

    </ul>

    <p>These are the commands needed to install these dependencies on your

    system. Select those which match your GNU/Linux distribution:</p>

    <p><strong>Ubuntu</strong> and derivatives, like <strong>Scientific Linux</strong>
    and <strong>Linux Mint</strong>:</p>

    <pre><code>sudo apt-get install r python3 python3-pip

    </code></pre>

    <p><strong>CentOS</strong> or <strong>Red Hat Linux</strong>:</p>

    <pre><code>sudo yum --enablerepo=extras install epel-release

    sudo yum install r python3 python3-pip

    </code></pre>

    <p>To install TAPAS, first download it from the

    <a href="https://github.com/mlell/tapas/releases">Releases section</a></p>

    <p>Then, execute the script</p>

    <pre><code>TAPAS/scripts/gen/install_dependencies

    </code></pre>

    <p>where you replace <code>TAPAS</code> by the folder where you installed TAPAS
    into. The

    tool downloads and installs the needed R and Python packages. The packages

    are installed inside the TAPAS folder and do no affect the rest of the system.</p>

    <h3>

    <a id="user-content-alternative-method-use-global-r-and-python-packages" class="anchor"
    href="#alternative-method-use-global-r-and-python-packages" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Alternative method:
    Use global R and Python packages</h3>

    <p>If you want to run TAPAS using R and Python packages which are installed

    globally on your system, instead of the <code>install_dependencies</code> script,
    run</p>

    <pre><code>TAPAS/script/gen/gen-launchers.sh --ext-libs

    </code></pre>

    <p>To check if all dependencies are met, run</p>

    <pre><code>TAPAS/scripts/setup_check_dependencies

    </code></pre>

    <p>on your computer.</p>

    <h2>

    <a id="user-content-the-scripts" class="anchor" href="#the-scripts" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>The scripts</h2>

    <p>All scripts lie in the <code>scripts/</code> folder. Read the manual to get
    an overview.

    Additionally, each script can be executed with the <code>--help</code> switch
    to get

    detailed information about the script''s functionality and how it can be tailored

    to your specific needs.</p>

    '
  stargazers_count: 1
  subscribers_count: 1
  topics: []
  updated_at: 1622395670.0
mvdoc/singularity-def:
  data_format: 2
  description: Singularity definition files for various projects
  filenames:
  - hauntedhouse_freesurfer/Singularity
  - hauntedhouse/Singularity
  - miniconda/Singularity
  full_name: mvdoc/singularity-def
  latest_release: null
  readme: '<h1>

    <a id="user-content-singularity-recipe-files" class="anchor" href="#singularity-recipe-files"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Singularity
    recipe files</h1>

    <p><a href="https://github.com/sylabs/singularity">Singularity</a> containers
    I use the most on HPC clusters.</p>

    '
  stargazers_count: 0
  subscribers_count: 2
  topics: []
  updated_at: 1495630055.0
nickjer/singularity-r:
  data_format: 2
  description: R in a Singularity container
  filenames:
  - Singularity
  - Singularity.3.6.2
  full_name: nickjer/singularity-r
  latest_release: null
  readme: '<h1>

    <a id="user-content-singularity-r" class="anchor" href="#singularity-r" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Singularity R</h1>

    <p><a href="https://travis-ci.org/nickjer/singularity-r" rel="nofollow"><img src="https://camo.githubusercontent.com/67e2d6deb1aeb1e18fbd9d72b2bdb73c7ab12099a81313d76bea0546cdfdb1c6/68747470733a2f2f7472617669732d63692e6f72672f6e69636b6a65722f73696e67756c61726974792d722e7376673f6272616e63683d6d6173746572"
    alt="Build Status" data-canonical-src="https://travis-ci.org/nickjer/singularity-r.svg?branch=master"
    style="max-width:100%;"></a>

    <a href="https://singularity-hub.org/collections/462" rel="nofollow"><img src="https://camo.githubusercontent.com/a07b23d4880320ac89cdc93bbbb603fa84c215d135e05dd227ba8633a9ff34be/68747470733a2f2f7777772e73696e67756c61726974792d6875622e6f72672f7374617469632f696d672f686f737465642d73696e67756c61726974792d2d6875622d2532336533323932392e737667"
    alt="Singularity Hub" data-canonical-src="https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg"
    style="max-width:100%;"></a>

    <a href="https://opensource.org/licenses/MIT" rel="nofollow"><img src="https://camo.githubusercontent.com/45b4ffbd594af47fe09a3432f9f8e122c6518aa6352b4ce453a1a2563da2905c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d677265656e2e737667"
    alt="GitHub License" data-canonical-src="https://img.shields.io/badge/license-MIT-green.svg"
    style="max-width:100%;"></a></p>

    <p>Singularity image for <a href="https://www.r-project.org/" rel="nofollow">R</a>.</p>

    <p>This is still a work in progress.</p>

    <h2>

    <a id="user-content-build" class="anchor" href="#build" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Build</h2>

    <p>You can build a local Singularity image named <code>singularity-r.simg</code>
    with:</p>

    <div class="highlight highlight-source-shell"><pre>sudo singularity build singularity-r.simg
    Singularity</pre></div>

    <h2>

    <a id="user-content-deploy" class="anchor" href="#deploy" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Deploy</h2>

    <p>Instead of building it yourself you can download the pre-built image from

    <a href="https://www.singularity-hub.org" rel="nofollow">Singularity Hub</a> with:</p>

    <div class="highlight highlight-source-shell"><pre>singularity pull --name singularity-r.simg
    shub://nickjer/singularity-r</pre></div>

    <h2>

    <a id="user-content-run" class="anchor" href="#run" aria-hidden="true"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>Run</h2>

    <h3>

    <a id="user-content-r" class="anchor" href="#r" aria-hidden="true"><span aria-hidden="true"
    class="octicon octicon-link"></span></a>R</h3>

    <p>The <code>R</code> command is launched using the default run command:</p>

    <div class="highlight highlight-source-shell"><pre>singularity run singularity-r.simg</pre></div>

    <p>or as an explicit app:</p>

    <div class="highlight highlight-source-shell"><pre>singularity run --app R singularity-r.simg</pre></div>

    <p>Example:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">singularity
    run --app R singularity-r.simg --version</span>

    <span class="pl-c1">R version 3.4.3 (2017-11-30) -- "Kite-Eating Tree"</span>

    <span class="pl-c1">Copyright (C) 2017 The R Foundation for Statistical Computing</span>

    <span class="pl-c1">Platform: x86_64-pc-linux-gnu (64-bit)</span>


    <span class="pl-c1">R is free software and comes with ABSOLUTELY NO WARRANTY.</span>

    <span class="pl-c1">You are welcome to redistribute it under the terms of the</span>

    <span class="pl-c1">GNU General Public License versions 2 or 3.</span>

    <span class="pl-c1">For more information about these matters see</span>

    <span class="pl-c1">http://www.gnu.org/licenses/.</span></pre></div>

    <h3>

    <a id="user-content-rscript" class="anchor" href="#rscript" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Rscript</h3>

    <p>The <code>Rscript</code> command is launched as an explicit app:</p>

    <div class="highlight highlight-source-shell"><pre>singularity run --app Rscript
    singularity-r.simg</pre></div>

    <p>Example:</p>

    <div class="highlight highlight-text-shell-session"><pre>$ <span class="pl-s1">singularity
    run --app Rscript singularity-r.simg --version</span>

    <span class="pl-c1">R scripting front-end version 3.4.3 (2017-11-30)</span></pre></div>

    <h2>

    <a id="user-content-contributing" class="anchor" href="#contributing" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Contributing</h2>

    <p>Bug reports and pull requests are welcome on GitHub at

    <a href="https://github.com/nickjer/singularity-r">https://github.com/nickjer/singularity-r</a>.</p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p>The code is available as open source under the terms of the <a href="http://opensource.org/licenses/MIT"
    rel="nofollow">MIT License</a>.</p>

    '
  stargazers_count: 12
  subscribers_count: 2
  topics:
  - r
  - singularity-image
  updated_at: 1617151072.0
oogasawa/singularity_ubuntu20:
  data_format: 2
  description: null
  filenames:
  - Singularity
  full_name: oogasawa/singularity_ubuntu20
  latest_release: null
  readme: '<h1>

    <a id="user-content-singularity-ubuntu20" class="anchor" href="#singularity-ubuntu20"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>singularity-ubuntu20</h1>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1622347084.0
perambluate/singularity-definition-files-for-HPC:
  data_format: 2
  description: To build hpc benchmark and mpi with cuda support sif
  filenames:
  - hpcc_intel.def
  - bert.def
  - hpc_mpi_cuda.def
  - hpl_intel_cuda.def
  full_name: perambluate/singularity-definition-files-for-HPC
  latest_release: null
  readme: '<h1>

    <a id="user-content-hpc_mpi_cuda_singu_def_file" class="anchor" href="#hpc_mpi_cuda_singu_def_file"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>hpc_mpi_cuda_singu_def_file</h1>

    <p>A collect of definition files to build images for singularity containers, which
    includes hpc benchmarks and mpis with cuda support.</p>

    <p><a href="https://singularity-hub.org/collections/4181" rel="nofollow"><img
    src="https://camo.githubusercontent.com/a07b23d4880320ac89cdc93bbbb603fa84c215d135e05dd227ba8633a9ff34be/68747470733a2f2f7777772e73696e67756c61726974792d6875622e6f72672f7374617469632f696d672f686f737465642d73696e67756c61726974792d2d6875622d2532336533323932392e737667"
    alt="https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg"
    data-canonical-src="https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg"
    style="max-width:100%;"></a></p>

    '
  stargazers_count: 1
  subscribers_count: 0
  topics: []
  updated_at: 1588998487.0
peter-jansson/appnuc:
  data_format: 2
  description: Applied nuclear physics relevant software, containerized.
  filenames:
  - Singularity
  full_name: peter-jansson/appnuc
  latest_release: v0.2.0.0
  readme: '<h1>

    <a id="user-content-appnuc" class="anchor" href="#appnuc" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>appnuc</h1>

    <p>Applied nuclear physics relevant software.</p>

    <p><a href="https://camo.githubusercontent.com/f400597fcdcb66eeb5702e037732d66d7eecdf94f4f363a2dde0da21c4ba9ec4/68747470733a2f2f7777772e676e752e6f72672f67726170686963732f6c67706c76332d776974682d746578742d3135347836382e706e67"
    target="_blank" rel="nofollow"><img src="https://camo.githubusercontent.com/f400597fcdcb66eeb5702e037732d66d7eecdf94f4f363a2dde0da21c4ba9ec4/68747470733a2f2f7777772e676e752e6f72672f67726170686963732f6c67706c76332d776974682d746578742d3135347836382e706e67"
    alt="LGPL-3" data-canonical-src="https://www.gnu.org/graphics/lgplv3-with-text-154x68.png"
    style="max-width:100%;"></a></p>

    <p>An Ubuntu based image/container with a bunch of standard programs that are
    useful for scientific work in the field of applied nuclear physics. In addition,
    the following list of relevant software is installed.</p>

    <ul>

    <li>

    <a href="https://geant4.web.cern.ch/" rel="nofollow">Geant4</a> monte carlo framework</li>

    <li>

    <a href="https://root.cern.ch/" rel="nofollow">Root</a> data analysis framework</li>

    <li>

    <a href="https://dx.doi.org/10.18434/T48G6X" rel="nofollow">XCOM</a> program from
    NIST</li>

    </ul>

    <h2>

    <a id="user-content-docker" class="anchor" href="#docker" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Docker</h2>

    <p>Docker hub contains the <a href="https://hub.docker.com/r/jansson/appnuc" rel="nofollow">image</a>
    built using the Dockerfile, which can pulled into the local Docker registry by
    the command <code>docker pull jansson/appnuc</code>.</p>

    <p>The image can be started in a container by, e.g., the command <code>docker
    run --rm -it jansson/appnuc bash -l</code>. Significantly more information on
    how to mount a local file system to the container as well as other command line
    options is available in the <a href="https://docs.docker.com/engine/reference/commandline/cli/"
    rel="nofollow">Docker documentation</a>.</p>

    <h2>

    <a id="user-content-singularity" class="anchor" href="#singularity" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Singularity</h2>

    <p>A <a href="https://sylabs.io/" rel="nofollow">Singularity</a> file containing
    the same containerized Ubuntu and software can be built using the Singularity
    definition file, named <code>Singularity</code>. E.g. using the command <code>sudo
    singularity build appnuc.sif Singularity</code> to build <code>appnuc.sif</code>.</p>

    <p>See the <a href="https://sylabs.io/guides/3.7/user-guide/" rel="nofollow">Singularity
    user guide</a> for more information.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - applied-nuclear-physics
  - dockerfile
  - singularity
  updated_at: 1621832060.0
pmitev/Teoroo-singularity:
  data_format: 2
  description: Singularity images and recipes
  filenames:
  - clease/Singularity.clease
  - deal.II/Singularity.deal
  - graphics/Singularity.gnuplot_5.4a
  - graphics/Singularity.gnuplot_4.6a
  - graphics/Singularity.gnuplot_5.4
  - graphics/Singularity.gnuplot_4.6
  - graphics/Singularity.graphics
  - graphics/Singularity.gnuplot_alpine
  - Atom/Singularity.atom
  - xcrysden/Singularity.xcrysden_1.5.60
  - xcrysden/Singularity.xcrysden
  - ase-twistd/Singularity.ase-twistd
  - gromacs/Singularity.gromacs
  - jupyter/Singularity.jupyter
  - gdis/Singularity.gdis
  - rstudio-server/Singularity.rstudio-server
  - mongodb/Singularity.mongodb
  - MD2-lab/Singularity.md2-lab
  - pp/Singularity.pp2
  - tools/Singularity.vim
  - tools/Singularity.mc
  - tools/Singularity.gawk
  - tools/Singularity.gnuplot
  - tools/Singularity.meld
  - jmol/Singularity.jmol
  - ubuntu/Singularity.2004
  - ubuntu/Singularity.1804
  - texlive/Singularity.texlive
  - AMPE/Singularity.ampe
  - kmos/Singularity.kmos
  - kmos/Singularity.kmos3_9
  - lammps/Singularity.lammps
  - lammps/Singularity.lammps_ase
  - lammps/Singularity.lammps_prophet
  - lammps/Singularity.lammps_ase_kim
  - cuda/Singularity.u18.04_cuda9.2
  - VESTA/Singularity.vesta
  - obabel/Singularity.obabel
  - acroread/Singularity.acroread
  full_name: pmitev/Teoroo-singularity
  latest_release: null
  readme: '<p><a href="https://singularity-hub.org/collections/2338" rel="nofollow"><img
    src="https://camo.githubusercontent.com/a07b23d4880320ac89cdc93bbbb603fa84c215d135e05dd227ba8633a9ff34be/68747470733a2f2f7777772e73696e67756c61726974792d6875622e6f72672f7374617469632f696d672f686f737465642d73696e67756c61726974792d2d6875622d2532336533323932392e737667"
    alt="https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg"
    data-canonical-src="https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg"
    style="max-width:100%;"></a></p>

    <h1>

    <a id="user-content-teoroo-singularity" class="anchor" href="#teoroo-singularity"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Teoroo-singularity</h1>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - singularity
  - singularity-containers
  updated_at: 1622443199.0
pmitev/UPPMAX-Singularity:
  data_format: 2
  description: UPPMAX Singularity builds
  filenames:
  - MitoZ/Singularity.v2.3-pm
  - gapseq/Singularity.gapseq
  - UniteM/Singularity.UniteM
  - bonito/Singularity.bonito
  - metaWRAP/Singularity.metaWRAP-deps-only-ubuntu
  - metaWRAP/Singularity.metaWRAP
  - metaWRAP/Singularity.metaWRAP-deps-only
  full_name: pmitev/UPPMAX-Singularity
  latest_release: null
  readme: '<h1>

    <a id="user-content-uppmax-singularity" class="anchor" href="#uppmax-singularity"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>UPPMAX-Singularity</h1>

    <p>UPPMAX Singularity builds</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1622469290.0
powerPlant/bonito-srf:
  data_format: 2
  description: Singularity recipe files for bonito (https://github.com/nanoporetech/bonito)
  filenames:
  - Singularity.0.4.0
  - Singularity
  - Singularity.0.3.6
  full_name: powerPlant/bonito-srf
  latest_release: null
  readme: '<p>Singularity recipe files for bonito, a PyTorch Basecaller for Oxford
    Nanopore Reads

    <a href="https://github.com/nanoporetech/bonito">https://github.com/nanoporetech/bonito</a></p>

    '
  stargazers_count: 0
  subscribers_count: 0
  topics: []
  updated_at: 1622513483.0
powerPlant/dvc-srf:
  data_format: 2
  description: Singularity recipe files for dvc (https://github.com/iterative/dvc)
  filenames:
  - Singularity.2.1.0
  - Singularity
  - Singularity.1.6.1
  full_name: powerPlant/dvc-srf
  latest_release: null
  readme: '<p>Singularity recipe files for the DVC tool for Data Version Control</p>

    '
  stargazers_count: 0
  subscribers_count: 0
  topics: []
  updated_at: 1621917326.0
refitt/refitt:
  data_format: 2
  description: The Recommender Engine for Intelligent Transient Tracking
  filenames:
  - Singularity
  full_name: refitt/refitt
  latest_release: 0.16.5
  readme: '<h1>

    <a id="user-content-singularity-ubuntu20" class="anchor" href="#singularity-ubuntu20"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>singularity-ubuntu20</h1>

    '
  stargazers_count: 4
  subscribers_count: 1
  topics:
  - science
  - astronomy
  - distributed-systems
  - machine-learning
  - citizen-science
  - open-source
  - python
  updated_at: 1622312948.0
rickstaa/COR-robotics-lab-reference:
  data_format: 2
  description: A quick reference repository for using the robots in the COR lab
  filenames:
  - containers/singularity/Singularity.ros_melodic-bionic
  - containers/singularity/Singularity.ros_noetic-focal
  - real_panda_moveit_control/containers/singularity/Singularity.ros_noetic-focal
  full_name: rickstaa/COR-robotics-lab-reference
  latest_release: null
  readme: "<h1>\n<a id=\"user-content-cor-robotics-lab-reference\" class=\"anchor\"\
    \ href=\"#cor-robotics-lab-reference\" aria-hidden=\"true\"><span aria-hidden=\"\
    true\" class=\"octicon octicon-link\"></span></a>COR-robotics-lab-reference</h1>\n\
    <p>A quick reference repository for using the robots in the COR lab. This repository\
    \ contains several code examples, a <a href=\"https://github.com/rickstaa/COR-robotics-lab-reference/discussions\"\
    >discussion forum</a> with FAQ that you might have while working with the robot\
    \ and a <a href=\"https://github.com/rickstaa/COR-robotics-lab-reference/wiki\"\
    >wiki</a> with several helpfull documents</p>\n<h2>\n<a id=\"user-content-how-to-reserve-the-robots\"\
    \ class=\"anchor\" href=\"#how-to-reserve-the-robots\" aria-hidden=\"true\"><span\
    \ aria-hidden=\"true\" class=\"octicon octicon-link\"></span></a>How to reserve\
    \ the robots</h2>\n<p>Please check the <g-emoji class=\"g-emoji\" alias=\"spiral_calendar\"\
    \ fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f5d3.png\"\
    >\U0001F5D3\uFE0F</g-emoji> <a href=\"https://github.com/rickstaa/COR-robotics-lab-reference/wiki/%F0%9F%97%93%EF%B8%8F-Robot-reservation-forum\"\
    >robot reservation form</a> wiki page for more information.</p>\n<h2>\n<a id=\"\
    user-content-how-to-work-with-the-robots\" class=\"anchor\" href=\"#how-to-work-with-the-robots\"\
    \ aria-hidden=\"true\"><span aria-hidden=\"true\" class=\"octicon octicon-link\"\
    ></span></a>How to work with the robots</h2>\n<p>Please check <g-emoji class=\"\
    g-emoji\" alias=\"safety_vest\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f9ba.png\"\
    >\U0001F9BA</g-emoji> <a href=\"https://github.com/rickstaa/COR-robotics-lab-reference/wiki/Panda-safety-guidelines\"\
    >safety-guidelines</a> in the wiki before working with the robot.</p>\n"
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1622205744.0
rickstaa/real-panda-control-examples:
  data_format: 2
  description: A small example repository that contains examples for controlling the
    real Panda robot.
  filenames:
  - real_panda_moveit_control/containers/singularity/Singularity.ros_noetic-focal
  full_name: rickstaa/real-panda-control-examples
  latest_release: null
  readme: '<h1>

    <a id="user-content-real-panda-control-examples" class="anchor" href="#real-panda-control-examples"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Real
    panda control examples</h1>

    <p>This repository contains several examples for controlling the real panda robot.
    It was created as a supliment to the official <a href="https://frankaemika.github.io/docs/installation_linux.html"
    rel="nofollow">panda documentation</a>. Further it serves as a storage place for
    several problems I encountered while working with the panda robot (see the <a
    href="https://github.com/rickstaa/real-panda-control-examples/discussions">discussions
    section</a>).</p>

    <h2>

    <a id="user-content-clone-instructions" class="anchor" href="#clone-instructions"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Clone
    instructions</h2>

    <p>To clone the respository use the following command:</p>

    <div class="highlight highlight-source-shell"><pre>mkdir real_catkin_ws

    <span class="pl-c1">cd</span> real_catkin_ws

    git clone --recurse-submodules https://github.com/rickstaa/real_panda_moveit_control.git
    src</pre></div>

    <h2>

    <a id="user-content-build-instructions" class="anchor" href="#build-instructions"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Build
    instructions</h2>

    <p>Install the ROS package dependencies using the following command:</p>

    <div class="highlight highlight-source-shell"><pre>rosdep install --from-paths
    src --ignore-src --rosdistro melodic -y</pre></div>

    <p>The catkin package can be build by executing one of the following commands:</p>

    <div class="highlight highlight-source-shell"><pre>catkin build -j4 -DCMAKE_BUILD_TYPE=Release
    -DFranka_DIR:PATH=<span class="pl-k">~</span>/libfranka/build</pre></div>

    <h2>

    <a id="user-content-franka-ros-examples" class="anchor" href="#franka-ros-examples"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Franka
    ros examples</h2>

    <p>Please see <a href="https://github.com/rickstaa/real-panda-control-examples/discussions/4">this
    discussion post</a> that explains how to run the example launch files provided
    by Emika Franka.</p>

    <h2>

    <a id="user-content-moveit-example-launch-instructions" class="anchor" href="#moveit-example-launch-instructions"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Moveit
    example launch instructions</h2>

    <p>To test out Moveit control, after you build and sourced the catkin workspace,
    you can launch the example included in the <code>panda_moveit_config</code> using
    the following command:</p>

    <div class="highlight highlight-source-shell"><pre>roslaunch panda_moveit_config
    panda_control_moveit_rviz.launch load_gripper:=true robot_ip:=172.16.0.2</pre></div>

    <p>Additionally the <code>real_panda_moveit_control</code> contains a slightly
    modified version of this example:</p>

    <div class="highlight highlight-source-shell"><pre>roslaunch real_panda_moveit_control
    real_panda_moveit_control.launch</pre></div>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics:
  - franka-emika
  - control
  - moveit
  updated_at: 1622116155.0
rohitfarmer/singularity-defs:
  data_format: 2
  description: Definition (recipe) files for singularity containers.
  filenames:
  - diffnets/diffnets.def
  - H5N1/Singularity.def
  - H5N1/Singularity_R_3.6.def
  - H5N1/h5n1day100.def
  - cite-seq/Singularity_xenial.def
  - cite-seq/Singularity_publish.def
  - cite-seq/Singularity_rocker.def
  - cite-seq/Singularity_3.def
  - generic/Singularity.def
  - bittersweet/Singularity.def
  - cytof-workflow-v3/Singularity.def
  - comet/Singularity.def
  - comet/chemlab-comet.def
  - cytof-deep-cnn/Singularity.def
  full_name: rohitfarmer/singularity-defs
  latest_release: null
  readme: '<h1>

    <a id="user-content-definitionrecipe-files-for-singularity-containers" class="anchor"
    href="#definitionrecipe-files-for-singularity-containers" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Definition/Recipe Files
    for Singularity Containers</h1>

    <p>Some of the containers are available to download from <a href="https://cloud.sylabs.io/library/rohitfarmer"
    rel="nofollow">https://cloud.sylabs.io/library/rohitfarmer</a></p>

    <p>For feedback and collaboration write to me at <a href="mailto:rohit.farmer@gmail.com">rohit.farmer@gmail.com</a></p>

    <h1>

    <a id="user-content-install-singularity-on-linux" class="anchor" href="#install-singularity-on-linux"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Install
    Singularity on Linux</h1>

    <h2>

    <a id="user-content-singularity-version-34" class="anchor" href="#singularity-version-34"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Singularity
    Version 3.4</h2>

    <p>Follow the instructions on <a href="https://sylabs.io/guides/3.4/user-guide/quick_start.html#quick-installation-steps"
    rel="nofollow">https://sylabs.io/guides/3.4/user-guide/quick_start.html#quick-installation-steps</a></p>

    <h1>

    <a id="user-content-building-a-singularity-container" class="anchor" href="#building-a-singularity-container"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    a Singularity Container</h1>

    <h2>

    <a id="user-content-readonly-container" class="anchor" href="#readonly-container"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Readonly
    Container</h2>

    <p>To build a read-only SquashFS Singularity container on a local machine using
    a recipe/definition file.</p>

    <p><code>sudo singularity build &lt;container-name.sif&gt; &lt;Singularity.def&gt;</code></p>

    <h2>

    <a id="user-content-writable-sandbox" class="anchor" href="#writable-sandbox"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Writable
    Sandbox</h2>

    <p>To build a writable sandbox (essentially a folder) on a local machine using
    a recipe/definition file.</p>

    <p><code>sudo singularity build --sandbox  &lt;sandbox-folder-name/&gt; &lt;Singularity.def&gt;</code></p>

    <p><em>Note: The advantage of building a writable sandbox is that it can be used
    to install and configure packages as you go, and once you are satisfied with the
    requirements, the sandbox can be converted into a read-only SquashFS container.
    To build a sandbox quickly, it''s better to install a minimal set of packages
    via the definition file.</em></p>

    <h3>

    <a id="user-content-installconfigure-packages-in-a-writable-sandbox" class="anchor"
    href="#installconfigure-packages-in-a-writable-sandbox" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Install/Configure Packages
    in a Writable Sandbox</h3>

    <p>Once a writable sandbox is created to execute it to invoke the shell of the
    operating installed in the container in the "writable" mode. If the shell is not
    invoked in the "writable" mode, all the changes will be lost once you exit from
    the container environment.</p>

    <p><code>sudo singularity shell --writable &lt;sandbox-folder-name/&gt;</code></p>

    <p>Install packages as you would, for example, in Ubuntu from the command line.</p>

    <h2>

    <a id="user-content-convert-a-writable-sandbox-to-a-readonly-container" class="anchor"
    href="#convert-a-writable-sandbox-to-a-readonly-container" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Convert a Writable
    Sandbox to a Readonly Container</h2>

    <p><code>sudo singularity build &lt;container-name.sif&gt; &lt;sandbox-folder-name/&gt;</code></p>

    <h1>

    <a id="user-content-execute-a-container" class="anchor" href="#execute-a-container"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Execute
    a Container</h1>

    <h2>

    <a id="user-content-invoke-a-shell" class="anchor" href="#invoke-a-shell" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Invoke a shell</h2>

    <p>The command below can be used for both read-only/writable containers/sandbox.</p>

    <p><code>singularity shell &lt;container-name.sif&gt;</code></p>

    <p><em>Note: By default, Singularity binds to your current working and home directory.
    Therefore, you do not need to do anything else to execute a script that is in
    your current working directory. It can also pull, for example, Vim settings from
    the .vimrc file in your home directory. Therefore, if Vim installed in the container,
    it can be used with the same settings from inside the container as it would from
    outside.</em></p>

    <h2>

    <a id="user-content-execute-a-command-via-container" class="anchor" href="#execute-a-command-via-container"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Execute
    a Command via Container</h2>

    <p><code>singularity exec &lt;container-name.sif&gt; &lt;command&gt;</code></p>

    <p>For example: <code>singularity exec &lt;container-name.sif&gt; Rscript --vanilla
    hello.R</code></p>

    <h1>

    <a id="user-content-running-jupyter-notebooks-from-within-a-container" class="anchor"
    href="#running-jupyter-notebooks-from-within-a-container" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Running Jupyter Notebooks
    from Within a Container</h1>

    <p>This section is for containers that have Jupyter notebook installed (e.g. cite-seq).</p>

    <p>A generic command that should work on a personal computer. <code>singularity
    exec container-name.sif jupyter notebook --no-browser --ip=127.0.0.1 --port=8888</code><br>

    <em>Note: The IP address and the port number mentioned in the command are the
    jupyter defaults. They can be changed as per need.</em><br>

    Copy the URL generated by jupyter daemon and paste it in your browser; this should
    open Jupyter with the list of the files in your current working directory on the
    host computer.</p>

    <h2>

    <a id="user-content-running-with-r-as-a-kernel" class="anchor" href="#running-with-r-as-a-kernel"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running
    with R as a Kernel</h2>

    <p>Sometimes if you already have an R kernel installed in your home directory,
    it conflicts with what you have inside the container. Therefore, it would require
    you to re-install the kernel specs in your home directory via the container.</p>

    <pre><code>singularity exec container-name.sif R --quiet --slave -e ''IRkernel::installspec()''


    # Screen log.

    # [InstallKernelSpec] Removing existing kernelspec in /home/user/.local/share/jupyter/kernels/ir

    # [InstallKernelSpec] Installed kernelspec ir in /home/user/.local/share/jupyter/kernels/ir

    </code></pre>

    <h2>

    <a id="user-content-running-on-an-hpc" class="anchor" href="#running-on-an-hpc"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Running
    on an HPC</h2>

    <ol>

    <li>SSH to the HPC.</li>

    <li>Claim an interactive node.</li>

    <li>Navigate to your project directory. Singularity container should be in your
    project directory.</li>

    <li><code>singularity exec container-name.sif jupyter notebook --no-browser --ip=''0.0.0.0''</code></li>

    <li>Keep the SSH session and Jupyter notebook session running. Copy the URL on
    your local browser.</li>

    </ol>

    <p><em>Note: On some HPCs, you may have to initiate an additional SSH tunnel connecting
    your local machine to the interactive node on the HPC. In that case, follow some
    generic instructions here <a href="https://rohitfarmer.github.io/docs/docs/HPC/jupyter/"
    rel="nofollow">https://rohitfarmer.github.io/docs/docs/HPC/jupyter/</a> or ask
    your system administrator.</em></p>

    '
  stargazers_count: 0
  subscribers_count: 0
  topics: []
  updated_at: 1598393438.0
sc-eQTLgen-consortium/WG1-pipeline-QC:
  data_format: 2
  description: Part of the sc-eQTLgen consortium pipeline. Step 1, where the QC is
    done.
  filenames:
  - Singularity.Imputation
  - Singularity.WGpipeline
  full_name: sc-eQTLgen-consortium/WG1-pipeline-QC
  latest_release: null
  readme: '<h1>

    <a id="user-content-wg1-pipeline-qc" class="anchor" href="#wg1-pipeline-qc" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>WG1-pipeline-QC</h1>

    <p><a href="https://user-images.githubusercontent.com/44268007/89252548-35b96f80-d659-11ea-97e9-4b4176df5f08.png"
    target="_blank" rel="nofollow"><img src="https://user-images.githubusercontent.com/44268007/89252548-35b96f80-d659-11ea-97e9-4b4176df5f08.png"
    width="300" height="140" style="max-width:100%;"></a></p>

    <p>Part of the sceQTL-Gen consortium pipeline. Step 1, where the QC is done.</p>

    <p>Please see the <a href="https://github.com/sc-eQTLgen-consortium/WG1-pipeline-QC/wiki">Wiki</a>
    for information on running the QC pipeline.</p>

    '
  stargazers_count: 2
  subscribers_count: 1
  topics: []
  updated_at: 1622436472.0
sguizard/TAMA-singularity:
  data_format: 2
  description: A definition file for building TAMA singularity container
  filenames:
  - Singularity
  full_name: sguizard/TAMA-singularity
  latest_release: v1.0
  readme: '<h1>

    <a id="user-content-tama-singularity" class="anchor" href="#tama-singularity"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>TAMA-singularity</h1>

    <p>A definition file for building TAMA singularity container</p>

    <h2>

    <a id="user-content-building-container" class="anchor" href="#building-container"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Building
    container</h2>

    <pre><code>sudo singularity build TAMA.{sif, def}

    </code></pre>

    <h2>

    <a id="user-content-using-tama" class="anchor" href="#using-tama" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Using TAMA</h2>

    <p>There are two main Python scripts in TAMA:</p>

    <ul>

    <li>tama_collapse.py</li>

    <li>tama_merge.py</li>

    </ul>

    <p>They can be run as follows:</p>

    <h3>

    <a id="user-content-tama_collapsepy" class="anchor" href="#tama_collapsepy" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a><a href="https://github.com/GenomeRIK/tama/wiki/Tama-Collapse">tama_collapse.py</a>

    </h3>

    <pre><code>singularity exec TAMA.sif tama_collapse.py -h

    </code></pre>

    <h3>

    <a id="user-content-tama_mergepy" class="anchor" href="#tama_mergepy" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a><a href="https://github.com/GenomeRIK/tama/wiki/Tama-Merge">tama_merge.py</a>

    </h3>

    <pre><code>singularity exec TAMA.sif tama_merge.py -h

    </code></pre>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1622110219.0
slhogle/singularity_def_files:
  data_format: 2
  description: Singularity definition files for building various software to run on
    HPC systems
  filenames:
  - checkm.def
  - instrain.def
  - octopus.def
  - torstyverse.def
  full_name: slhogle/singularity_def_files
  latest_release: null
  readme: '<h1>

    <a id="user-content-singularity-definition-files" class="anchor" href="#singularity-definition-files"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Singularity
    definition files</h1>

    <p>Collection of def files for building some bioinformatics software I commonly
    use.</p>

    <h2>

    <a id="user-content-instrain-v1214" class="anchor" href="#instrain-v1214" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>inStrain v1.2.14</h2>

    <p><a href="https://github.com/MrOlm/inStrain">https://github.com/MrOlm/inStrain</a></p>

    <p>Also contains these functioning binaries:</p>

    <ul>

    <li><a href="https://github.com/samtools/samtools">samtools v1.10</a></li>

    <li><a href="https://github.com/hyattpd/Prodigal">prodigal v2.6.3</a></li>

    <li><a href="https://github.com/lh3/bwa">bwa v0.7.17-r1198-dirty</a></li>

    <li><a href="https://github.com/lh3/minimap2">minimap2 v2.17 (r941)</a></li>

    <li><a href="https://github.com/dnbaker/dashing">Dashing v0.4.8-1-g47e6</a></li>

    <li><a href="https://github.com/ParBLiSS/FastANI">FastANI v1.3</a></li>

    <li><a href="https://github.com/wwood/CoverM">CoverM v0.4.0</a></li>

    </ul>

    <p><a href="https://cloud.sylabs.io/library/slhogle/base/instrain" rel="nofollow">Image
    at Sylabs</a></p>

    <p>Download with:<br>

    <code>singularity pull library://slhogle/base/instrain</code></p>

    <h2>

    <a id="user-content-octopus-development-branch-version-v070-develop-2bde0433"
    class="anchor" href="#octopus-development-branch-version-v070-develop-2bde0433"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Octopus
    development branch version v0.7.0 (develop 2bde0433)</h2>

    <p><a href="https://github.com/luntergroup/octopus">https://github.com/luntergroup/octopus</a></p>

    <p>Built with:</p>

    <ul>

    <li>patchelf v0.10</li>

    <li>openssl v1.1.1g</li>

    <li>pkg-config v0.29.2</li>

    <li>gpatch v2.7.6</li>

    <li>ncurses v6.2</li>

    <li>cmake v3.17.3</li>

    <li>htslib v1.10</li>

    <li>boost v1.72.0</li>

    <li>GNU C/C++ compiler v9.3.0</li>

    </ul>

    <p>Target: x86_64 Linux 5.3.0-7642-generic<br>

    SIMD extension: AVX2</p>

    <p><a href="https://cloud.sylabs.io/library/slhogle/base/octopus" rel="nofollow">Image
    at Sylabs</a></p>

    <p>Download with:<br>

    <code>singularity pull library://slhogle/base/octopus</code></p>

    <h2>

    <a id="user-content-torstyverse" class="anchor" href="#torstyverse" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Torstyverse</h2>

    <p>Bundle of useful packages from <a href="https://github.com/tseemann">Torsten
    Seeman</a></p>

    <ul>

    <li><a href="https://github.com/tseemann/samclip">sampclip v0.4.0</a></li>

    <li><a href="https://github.com/tseemann/any2fasta">any2fasta v0.4.2</a></li>

    <li><a href="https://github.com/tseemann/barrnap">barrnap v0.9</a></li>

    <li><a href="https://github.com/tseemann/prokka">prokka v1.14.6</a></li>

    <li><a href="https://github.com/tseemann/shovill">shovill v1.1.0</a></li>

    <li><a href="https://github.com/tseemann/abricate">abricate v1.0.1</a></li>

    <li><a href="https://github.com/tseemann/snippy">snippy v4.6.0</a></li>

    </ul>

    <p><a href="https://cloud.sylabs.io/library/slhogle/base/torstyverse" rel="nofollow">Image
    at Sylabs</a></p>

    <p>Download with:<br>

    <code>singularity pull library://slhogle/base/torstyverse</code></p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1614942669.0
sylabs/singularity:
  data_format: 2
  description: SingularityCE is the Community Edition of Singularity, an open source
    container platform designed to be simple, fast, and secure.
  filenames:
  - examples/legacy/2.2/arch.def
  - examples/legacy/2.2/scientific.def
  - examples/legacy/2.2/busybox.def
  - examples/legacy/2.2/ubuntu.def
  - examples/legacy/2.2/debian.def
  - examples/legacy/2.2/docker.def
  - examples/legacy/2.2/centos.def
  - examples/legacy/2.2/contrib/ubuntu-bio.def
  - examples/legacy/2.2/contrib/debian85-tensorflow-0.10.def
  - examples/legacy/2.2/contrib/linuxbrew_and_non-root_software_example.def
  - examples/legacy/2.2/contrib/ubuntu16-tensorflow-0.12.1.def
  - examples/legacy/2.2/contrib/ubuntu-openfoam.def
  - examples/legacy/2.2/contrib/centos7-ompi_master.def
  - examples/legacy/2.2/contrib/centos-minimal.def
  - examples/legacy/2.2/contrib/r_python_julia.def
  - examples/legacy/2.2/contrib/centos7-ompi_cuda.def
  - examples/legacy/2.2/contrib/ubuntu16-tensorflow-0.12.1-gpu.def
  - examples/legacy/2.2/contrib/ubuntu-root.def
  - examples/legacy/2.2/contrib/fedora.def
  - examples/legacy/2.3/contrib/raspbian.def
  - examples/build-singularity/build-singularity.def
  - e2e/testdata/inspecter_container.def
  - e2e/testdata/Docker_registry.def
  - e2e/testdata/sshfs.def
  - e2e/testdata/regressions/issue_5315.def
  - e2e/testdata/regressions/issue_4203.def
  - e2e/testdata/regressions/issue_4583.def
  - e2e/testdata/regressions/issue_4969.def
  - e2e/testdata/regressions/issue_5399.def
  - e2e/testdata/regressions/issue_5250.def
  - e2e/testdata/regressions/issue_4820.def
  - e2e/testdata/regressions/issue_4967.def
  full_name: sylabs/singularity
  latest_release: v3.8.0
  readme: '<h1>

    <a id="user-content-singularityce" class="anchor" href="#singularityce" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>SingularityCE</h1>

    <p><a href="https://circleci.com/gh/sylabs/singularity/tree/master" rel="nofollow"><img
    src="https://camo.githubusercontent.com/ff56e7dd170e08e53c09fda12031315bb91f5b4220f2d3cfaf46044700f32fa1/68747470733a2f2f636972636c6563692e636f6d2f67682f73796c6162732f73696e67756c61726974792f747265652f6d61737465722e7376673f7374796c653d737667"
    alt="CircleCI" data-canonical-src="https://circleci.com/gh/sylabs/singularity/tree/master.svg?style=svg"
    style="max-width:100%;"></a></p>

    <ul>

    <li><a href="CONTRIBUTING.md">Guidelines for Contributing</a></li>

    <li><a href=".github/PULL_REQUEST_TEMPLATE.md">Pull Request Template</a></li>

    <li><a href="LICENSE.md">Project License</a></li>

    <li><a href="https://www.sylabs.io/docs/" rel="nofollow">Documentation</a></li>

    <li><a href="#support">Support</a></li>

    <li><a href="#citing-singularity">Citation</a></li>

    </ul>

    <p>SingularityCE is the Community Edition of Singularity, an open source container

    platform designed to be simple, fast, and secure. Singularity is optimized

    for compute focused enterprise and HPC workloads, allowing untrusted users

    to run untrusted containers in a trusted way.</p>

    <p>Check out <a href="https://www.sylabs.io/videos" rel="nofollow">talks about
    Singularity</a> and some <a href="https://sylabs.io/case-studies" rel="nofollow">use

    cases of Singularity</a> on our website.</p>

    <h2>

    <a id="user-content-getting-started-with-singularityce" class="anchor" href="#getting-started-with-singularityce"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Getting
    Started with SingularityCE</h2>

    <p>To install SingularityCE from source, see the <a href="INSTALL.md">installation

    instructions</a>. For other installation options, see <a href="https://www.sylabs.io/guides/latest/admin-guide/"
    rel="nofollow">our

    guide</a>.</p>

    <p>System administrators can learn how to configure SingularityCE, and get an

    overview of its architecture and security features in the <a href="https://www.sylabs.io/guides/latest/admin-guide/"
    rel="nofollow">administrator

    guide</a>.</p>

    <p>For users, see the <a href="https://www.sylabs.io/guides/latest/user-guide/"
    rel="nofollow">user

    guide</a> for details on how to use

    and build Singularity containers.</p>

    <h2>

    <a id="user-content-contributing-to-singularityce" class="anchor" href="#contributing-to-singularityce"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Contributing
    to SingularityCE</h2>

    <p>Community contributions are always greatly appreciated. To start developing

    SingularityCE, check out the <a href="CONTRIBUTING.md">guidelines for contributing</a>.</p>

    <p>We also welcome contributions to our <a href="https://github.com/sylabs/singularity-userdocs">user

    guide</a> and <a href="https://github.com/sylabs/singularity-admindocs">admin

    guide</a>.</p>

    <h2>

    <a id="user-content-support" class="anchor" href="#support" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>Support</h2>

    <p>To get help with SingularityCE, check out the community spaces

    detailed at our <a href="https://www.sylabs.io/singularity/community/" rel="nofollow">Community

    Portal</a>.</p>

    <p>See also our <a href="SUPPORT.md">Support Guidelines</a> for further

    information about the best place, and how, to raise different kinds of

    issues and questions.</p>

    <p>For additional support, <a href="https://www.sylabs.io/contact/" rel="nofollow">contact
    us</a> to receive

    more information.</p>

    <h2>

    <a id="user-content-citing-singularity" class="anchor" href="#citing-singularity"
    aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Citing
    Singularity</h2>

    <pre><code>Kurtzer GM, Sochat V, Bauer MW (2017) Singularity: Scientific containers
    for mobility of compute. PLoS ONE 12(5): e0177459. https://doi.org/10.1371/journal.pone.0177459

    </code></pre>

    <p>We also have a Zenodo citation:</p>

    <pre><code>Kurtzer, Gregory M. et. al. Singularity - Linux application and environment

    containers for science. 10.5281/zenodo.1310023

    </code></pre>

    <p><a href="https://doi.org/10.5281/zenodo.1310023" rel="nofollow">https://doi.org/10.5281/zenodo.1310023</a></p>

    <p>This is an ''all versions'' DOI. Follow the link to Zenodo to obtain a DOI
    specific

    to a particular version of Singularity.</p>

    <h2>

    <a id="user-content-license" class="anchor" href="#license" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

    <p><em>Unless otherwise noted, this project is licensed under a 3-clause BSD license

    found in the <a href="LICENSE.md">license file</a>.</em></p>

    '
  stargazers_count: 30
  subscribers_count: 7
  topics:
  - containers
  - hpc
  - linux
  updated_at: 1622458275.0
uf-icbr-bioinformatics/biocontainers:
  data_format: 2
  description: null
  filenames:
  - Singularity_fastqc
  - Singularity_multiqc
  - Singularity_trimmomatic
  full_name: uf-icbr-bioinformatics/biocontainers
  latest_release: null
  readme: '<h1>

    <a id="user-content-biocontainers" class="anchor" href="#biocontainers" aria-hidden="true"><span
    aria-hidden="true" class="octicon octicon-link"></span></a>biocontainers</h1>

    <p>This repository contains recipes for containers used to perform QC, summary
    statistics, and pre-processing on NGS datasets.</p>

    <p>In the future, we may provide the containers themselves. Stay tuned. Work in
    progress.</p>

    '
  stargazers_count: 0
  subscribers_count: 1
  topics: []
  updated_at: 1622239073.0
